var documenterSearchIndex = {"docs":
[{"location":"examples/n-monitoring/#N-Monitoring","page":"N-Monitoring","title":"N-Monitoring","text":"","category":"section"},{"location":"examples/n-monitoring/#Description","page":"N-Monitoring","title":"Description","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The N-monitoring problem is described in [1], sections 4.1 and 6.1.","category":"page"},{"location":"examples/n-monitoring/#Influence-Diagram","page":"N-Monitoring","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"(Image: )","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The influence diagram of the generalized N-monitoring problem where N1 and indices k=1N The nodes are associated with states as follows. Load state L=high low denotes the load on a structure, report states R_k=high low report the load state to the action states A_k=yes no which represent different decisions to fortify the structure. The failure state F=failure success represents whether or not the (fortified) structure fails under the load L. Finally, the utility at target T depends on the fortification costs and whether F fails.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We begin by choosing N and defining our fortification cost function. We draw the cost of fortification c_kU(01) from a uniform distribution, and the magnitude of fortification is directly proportional to the cost. Fortification is defined as","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=yes) = c_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=no) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"using Random\nusing JuMP, HiGHS\nusing DecisionProgramming\n\nconst N = 4\n\nRandom.seed!(13)\nconst c_k = rand(N)\nconst b = 0.03\nfortification(k, a) = [c_k[k], 0][a]","category":"page"},{"location":"examples/n-monitoring/#Initialising-the-influence-diagram","page":"N-Monitoring","title":"Initialising the influence diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We initialise the influence diagram before adding nodes to it.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"diagram = InfluenceDiagram()","category":"page"},{"location":"examples/n-monitoring/#Adding-nodes","page":"N-Monitoring","title":"Adding nodes","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Add node L which represents the load on the structure. This node is the root node and thus, has an empty information set. Its states describe the state of the load, they are high and low.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"add_node!(diagram, ChanceNode(\"L\", [], [\"high\", \"low\"]))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The report nodes R_k and action nodes A_k are easily added with a for-loop. The report nodes have node L in their information sets and their states are high and low. The actions are made based on these reports, which is represented by the action nodes A_k having the report nodes R_k in their information sets. The action nodes have states yes and no, which represents decisions whether to fortify the structure or not.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for i in 1:N\n    add_node!(diagram, ChanceNode(\"R$i\", [\"L\"], [\"high\", \"low\"]))\n    add_node!(diagram, DecisionNode(\"A$i\", [\"R$i\"], [\"yes\", \"no\"]))\nend","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The failure node F has the load node L and all of the action nodes A_k in its information set. The failure node has states failure and success.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"add_node!(diagram, ChanceNode(\"F\", [\"L\", [\"A$i\" for i in 1:N]...], [\"failure\", \"success\"]))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The value node T is added as follows.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"add_node!(diagram, ValueNode(\"T\", [\"F\", [\"A$i\" for i in 1:N]...]))","category":"page"},{"location":"examples/n-monitoring/#Generating-arcs","page":"N-Monitoring","title":"Generating arcs","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Now that all of the nodes have been added to the influence diagram we generate the arcs between the nodes. This step automatically orders the nodes, gives them indices and reorganises the information into the appropriate form.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"generate_arcs!(diagram)","category":"page"},{"location":"examples/n-monitoring/#Load-State-Probabilities","page":"N-Monitoring","title":"Load State Probabilities","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"After generating the arcs, the probabilities and utilities can be added. The probability that the load is high, â„™(L=high), is drawn from a uniform distribution. For different syntax options for adding probabilities and utilities, see the usage page.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"â„™(L=high)U(01)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"X_L = [rand(), 0]\nX_L[2] = 1.0 - X_L[1]\nadd_probabilities!(diagram, \"L\", X_L)","category":"page"},{"location":"examples/n-monitoring/#Reporting-Probabilities","page":"N-Monitoring","title":"Reporting Probabilities","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of the report states correspond to the load state. We draw the values xU(01) and yU(01) from uniform distributions.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"â„™(R_k=highL=high)=maxx1-x","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"â„™(R_k=lowL=low)=maxy1-y","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability of a correct report is thus in the range [0.5,1]. (This reflects the fact that a probability under 50% would not even make sense, since we would notice that if the test suggests a high load, the load is more likely to be low, resulting in that a low report \"turns into\" a high report and vice versa.)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"In Decision Programming we add these probabilities by declaring probabilty matrices for nodes R_k. The probability matrix of a report node R_k has dimensions (2,2), where the rows correspond to the states high and low of its predecessor node L and the columns to its own states high andÂ low.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for i in 1:N\n    x_R, y_R = rand(2)\n    X_R = ProbabilityMatrix(diagram, \"R$i\")\n    X_R[\"high\", \"high\"] = max(x_R, 1-x_R)\n    X_R[\"high\", \"low\"] = 1 - max(x_R, 1-x_R)\n    X_R[\"low\", \"low\"] = max(y_R, 1-y_R)\n    X_R[\"low\", \"high\"] = 1-max(y_R, 1-y_R)\n    add_probabilities!(diagram, \"R$i\", X_R)\nend","category":"page"},{"location":"examples/n-monitoring/#Probability-of-Failure","page":"N-Monitoring","title":"Probability of Failure","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability of failure is decresead by fortification actions. We draw the values xU(01) and yU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"â„™(F=failureA_NA_1L=high)=fracmaxx 1-xexp(b _k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"â„™(F=failureA_NA_1L=low)=fracminy 1-yexp(b _k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"First we initialise the probability matrix for node F.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"X_F = ProbabilityMatrix(diagram, \"F\")","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"This matrix has dimensions (2 textcolororange2 2 2 2 2) because node L and nodes A_k, which form the information set of F, all have 2 states and node F itself also has 2 states. The orange colored dimensions correspond to the states of the action nodes A_k.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"To set the probabilities we have to iterate over the information states. Here it helps to know that in Decision Programming the states of each node are mapped to numbers in the back-end. For instance, the load states high and low are referred to as 1 and 2. The same applies for the action states yes and no, they are states 1 and 2. The paths function allows us to iterate over the subpaths of specific nodes. In these paths, the states are referred to by their indices. Using this information, we can easily iterate over the information states using the paths function and enter the probability values into the probability matrix.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"x_F, y_F = rand(2)\nfor s in paths([State(2) for i in 1:N])\n    denominator = exp(b * sum(fortification(k, a) for (k, a) in enumerate(s)))\n    X_F[1, s..., 1] = max(x_F, 1-x_F) / denominator\n    X_F[1, s..., 2] = 1.0 - X_F[1, s..., 1]\n    X_F[2, s..., 1] = min(y_F, 1-y_F) / denominator\n    X_F[2, s..., 2] = 1.0 - X_F[2, s..., 1]\nend","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"After declaring the probability matrix, we add it to the influence diagram.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"add_probabilities!(diagram, \"F\", X_F)","category":"page"},{"location":"examples/n-monitoring/#Utility","page":"N-Monitoring","title":"Utility","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The utility from the different scenarios of the failure state at target T are","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"g(F=failure) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"g(F=success) = 100","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utilities from the action states A_k  at target T are","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=yes) = c_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=no) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The total cost is thus","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y(F A_N  A_1) = g(F) + (-f(A_N)) +  + (-f(A_1))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We first declare the utility matrix for node T.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y_T = UtilityMatrix(diagram, \"T\")","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"This matrix has dimensions (2 textcolororange2 2 2 2), where the dimensions correspond to the numbers of states the nodes in the information set have. Similarly as before, the first dimension corresponds to the states of node F and the other 4 dimensions (in orange) correspond to the states of the A_k nodes. The utilities are set and added similarly to how the probabilities were added above.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for s in paths([State(2) for i in 1:N])\n    cost = sum(-fortification(k, a) for (k, a) in enumerate(s))\n    Y_T[1, s...] = 0 + cost\n    Y_T[2, s...] = 100 + cost\nend\nadd_utilities!(diagram, \"T\", Y_T)","category":"page"},{"location":"examples/n-monitoring/#Generate-Influence-Diagram","page":"N-Monitoring","title":"Generate Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The full influence diagram can now be generated. We use the default path probabilities and utilities, which are the default setting in this function. In the Contingent Portfolio Programming example, we show how to use a user-defined custom path utility function.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"In this particular problem, some of the path utilities are negative. In this case, we choose to use the positive path utility transformation, which translates the path utilities to positive values. This allows us to exclude the probability cut in the next section.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"generate_diagram!(diagram, positive_path_utility = true)","category":"page"},{"location":"examples/n-monitoring/#Decision-Model","page":"N-Monitoring","title":"Decision Model","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We initialise the JuMP model and declare the decision and path compatibility variables. Since we applied an affine transformation to the utility function, the probability cut can be excluded from the model formulation.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"model = Model()\nz = DecisionVariables(model, diagram)\nx_s = PathCompatibilityVariables(model, diagram, z, probability_cut = false)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The expected utility is used as the objective and the problem is solved using Gurobi.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"EV = expected_value(model, diagram, x_s)\n@objective(model, Max, EV)\n\n\noptimizer = optimizer_with_attributes(\n    () -> HiGHS.Optimizer()\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/n-monitoring/#Analyzing-Results","page":"N-Monitoring","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We obtain the decision strategy, state probabilities and utility distribution from the solution. Julia version 1.10.3 was used in random number generation (the version used might affect the results).","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Z = DecisionStrategy(diagram, z)\nU_distribution = UtilityDistribution(diagram, Z)\nS_probabilities = StateProbabilities(diagram, Z)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The decision strategy shows us that the optimal strategy is to make all four fortifications regardless of the reports.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_decision_strategy(diagram, Z, S_probabilities)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of R1 â”‚ Decision in A1 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ high           â”‚ yes            â”‚\nâ”‚ low            â”‚ no             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of R2 â”‚ Decision in A2 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ high           â”‚ yes            â”‚\nâ”‚ low            â”‚ no             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of R3 â”‚ Decision in A3 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ high           â”‚ yes            â”‚\nâ”‚ low            â”‚ yes            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of R4 â”‚ Decision in A4 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ high           â”‚ yes            â”‚\nâ”‚ low            â”‚ no             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The state probabilities for strategy Z are also obtained. These tell the probability of each state in each node, given strategy Z.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_state_probabilities(diagram, S_probabilities, [\"L\"])\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Node â”‚     high â”‚      low â”‚ Fixed state â”‚\nâ”‚ String â”‚  Float64 â”‚  Float64 â”‚      String â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚      L â”‚ 0.586000 â”‚ 0.414000 â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\njulia> print_state_probabilities(diagram, S_probabilities, [[\"R$i\" for i in 1:N]...])\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Node â”‚     high â”‚      low â”‚ Fixed state â”‚\nâ”‚ String â”‚  Float64 â”‚  Float64 â”‚      String â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     R1 â”‚ 0.737028 â”‚ 0.262972 â”‚             â”‚\nâ”‚     R2 â”‚ 0.501345 â”‚ 0.498655 â”‚             â”‚\nâ”‚     R3 â”‚ 0.449940 â”‚ 0.550060 â”‚             â”‚\nâ”‚     R4 â”‚ 0.462002 â”‚ 0.537998 â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\njulia> print_state_probabilities(diagram, S_probabilities, [[\"A$i\" for i in 1:N]...])\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Node â”‚      yes â”‚       no â”‚ Fixed state â”‚\nâ”‚ String â”‚  Float64 â”‚  Float64 â”‚      String â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     A1 â”‚ 0.737028 â”‚ 0.262972 â”‚             â”‚\nâ”‚     A2 â”‚ 0.501345 â”‚ 0.498655 â”‚             â”‚\nâ”‚     A3 â”‚ 1.000000 â”‚ 0.000000 â”‚             â”‚\nâ”‚     A4 â”‚ 0.462002 â”‚ 0.537998 â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\njulia> print_state_probabilities(diagram, S_probabilities, [\"F\"])\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Node â”‚  failure â”‚  success â”‚ Fixed state â”‚\nâ”‚ String â”‚  Float64 â”‚  Float64 â”‚      String â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚      F â”‚ 0.395566 â”‚ 0.604434 â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We can also print the utility distribution for the optimal strategy and some basic statistics for the distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_utility_distribution(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Utility â”‚ Probability â”‚\nâ”‚   Float64 â”‚     Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ -1.806271 â”‚    0.164580 â”‚\nâ”‚ -1.715238 â”‚    0.104478 â”‚\nâ”‚ -1.654847 â”‚    0.009397 â”‚\nâ”‚ -1.563813 â”‚    0.006952 â”‚\nâ”‚ -0.924416 â”‚    0.045627 â”‚\nâ”‚ -0.833383 â”‚    0.038920 â”‚\nâ”‚ -0.772991 â”‚    0.007659 â”‚\nâ”‚ -0.681958 â”‚    0.017953 â”‚\nâ”‚ 98.193726 â”‚    0.112766 â”‚\nâ”‚ 98.284760 â”‚    0.077866 â”‚\nâ”‚ 98.345154 â”‚    0.009793 â”‚\nâ”‚ 98.436188 â”‚    0.015513 â”‚\nâ”‚ 99.075584 â”‚    0.063066 â”‚\nâ”‚ 99.166618 â”‚    0.129725 â”‚\nâ”‚ 99.227005 â”‚    0.049114 â”‚\nâ”‚ 99.318039 â”‚    0.146591 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_statistics(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Name â”‚ Statistics â”‚\nâ”‚   String â”‚    Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     Mean â”‚  59.165647 â”‚\nâ”‚      Std â”‚  49.083835 â”‚\nâ”‚ Skewness â”‚  -0.427074 â”‚\nâ”‚ Kurtosis â”‚  -1.817258 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/n-monitoring/#References","page":"N-Monitoring","title":"References","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1â€“35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/paths/#paths","page":"Paths","title":"Paths","text":"","category":"section"},{"location":"decision-programming/paths/#Effective-Paths","page":"Paths","title":"Effective Paths","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"(Image: )","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"It is possible for some combinations of chance or decision states to be unrealizable. We refer to such subpaths as ineffective. For example, the above tree represents the generation of paths where subpaths ğ’_12^=(22), ğ’_123^=(112) (121) are ineffective.","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Formally, the path ğ¬ is ineffective if and only if ğ¬_Ağ’_A^ given ineffective subpaths ğ’_A^ğ’_A for nodes ACD Then, effective paths is a subset of all paths without ineffective paths","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’^=ğ¬ğ’ğ¬_Ağ’_A^ğ’","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"The Decision Model size depends on the number of effective paths, rather than the number of paths or size of the influence diagram directly.","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"In Decision Programming, one can declare certain subpaths to be ineffective using the fixed path and forbidden paths sets.","category":"page"},{"location":"decision-programming/paths/#Fixed-Path","page":"Paths","title":"Fixed Path","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Fixed path refers to a subpath which must be realized. If the fixed path is s_Y = S_Y^f for all nodes YCD, then the effective paths in the model are","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’^=ğ¬ğ’s_Y = S_Y^f forall  Y ","category":"page"},{"location":"decision-programming/paths/#Forbidden-Paths","page":"Paths","title":"Forbidden Paths","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Forbidden paths are a way to declare ineffective subpaths. If ğ¬_Xğ’_X^ are forbidden subpaths for nodes XCD, then the effective paths in the model are","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’^=ğ¬ğ’ğ¬_X  ğ’_X^","category":"page"},{"location":"decision-programming/paths/#Active-Paths","page":"Paths","title":"Active Paths","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"If the upper bound of path probability is zero, its probability is zero, and it does not affect the solution. Therefore, we can consider only the paths with a positive upper bound of path probability. We refer to these paths as active paths. Formally, we define an active path as a path ğ¬ if all of its chance states are active","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"beginaligned\nX(ğ¬)(p(ğ¬)0)  _jC (â„™(X_j=ğ¬_jX_I(j)=ğ¬_I(j))0)\nendaligned","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Otherwise, it is an inactive path. We denote the set of active paths as","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’(X)=ğ¬ğ’  X(ğ¬)","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"The number of active paths is","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’(X)ğ’","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Effective paths are related to active paths, such that, for all jC we have ineffective subpaths","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’_I(j)j^=ğ¬_I(j)jğ’_I(j)j  â„™(X_j=s_jX_I(j)=ğ¬_I(j))=0","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Generally, the effective paths is a subset of the active paths, that is","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’^  ğ’(X)","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"If there are no other ineffective subpaths, we have","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’^ = ğ’(X)","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Notice that, the number of active paths affects the size of the Decision Model because it depends on the number of effective paths.","category":"page"},{"location":"decision-programming/paths/#Compatible-Paths","page":"Paths","title":"Compatible Paths","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Each decision strategy Zâ„¤ determines a set of compatible paths. We use the shorthand Z(s)  (q(ğ¬ mid Z) = 1), where q is as defined in Path Probability. Formally, we denote the set of compatible paths as","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’(Z)=ğ¬ğ’  Z(ğ¬)","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Since each local decision strategy Z_jZ is deterministic, it can choose only one state s_j for each information state ğ¬_I(j). Thus, the number of compatible paths is","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’(Z)=ğ’ğ’_D=ğ’_C","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"The compatible paths of all distinct pairs of decision strategies are disjoint. Formally, for all ZZ^â„¤ where ZZ^, we have","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’(Z)ğ’(Z^)=ğ¬ğ’Z(ğ¬)Z^(ğ¬)=","category":"page"},{"location":"decision-programming/paths/#Locally-Compatible-Paths","page":"Paths","title":"Locally Compatible Paths","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Locally compatible paths refers to a subset of paths that include the subpath (ğ¬_I(j) s_j) and thus, represent the local decision strategy Z_j(ğ¬_I(j)) = s_j for decision node j in D. Formally, the locally compatible paths for node j in D, state s_j in S_j and information state ğ¬_I(j) in ğ’_I(j) includes the paths","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’_s_j mid s_I(j) =  ğ¬ in ğ’ mid (ğ¬_I(j) s_j)  ğ¬","category":"page"},{"location":"decision-programming/paths/#Symmetry","page":"Paths","title":"Symmetry","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"We define the set of active and compatible paths as","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’(X)ğ’(Z)=ğ¬ğ’X(ğ¬)Z(ğ¬)","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"An influence diagram is symmetric if the number of active and compatible paths is a constant. Formally, if for all ZZ^â„¤ where ZZ^ we have","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"ğ’(X)ğ’(Z)=ğ’(X)ğ’(Z^)","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"For example, if all paths are active, we have ğ’(X)ğ’(Z)=ğ’(Z) which is a constant. Otherwise, the influence diagram is asymmetric. The figures below demonstrate symmetric and asymmetric influence diagrams.","category":"page"},{"location":"decision-programming/paths/#Example-1","page":"Paths","title":"Example 1","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"(Image: )","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Consider the influence diagram with two nodes. The first is a decision node with two states, and the second is a chance node with three states.","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"(Image: )","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"If there are no inactive chance states, all paths are possible. That is, for all sS we have p(s)0 In this case, the influence diagram is symmetric.","category":"page"},{"location":"decision-programming/paths/#Example-2","page":"Paths","title":"Example 2","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"(Image: )","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"However, if there are inactive chance states, such as â„™(s_2=2s_1=2)=0, we can remove (22) from the paths, visualized by a dashed shape. Therefore, there is a varying number of possible paths depending on whether the decision-maker chooses state s_1=1 or s_1=2 in the first node, and the influence diagram is asymmetric.","category":"page"},{"location":"decision-programming/paths/#Example-3","page":"Paths","title":"Example 3","text":"","category":"section"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"(Image: )","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Let us add one chance node with two states to the influence diagram.","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"(Image: )","category":"page"},{"location":"decision-programming/paths/","page":"Paths","title":"Paths","text":"Now, given inactive chance states such that we remove the dashed paths, we have a symmetric influence diagram. Both decisions will have an equal number of possible paths. However, there are only eight possible paths instead of twelve if there were no inactive chance states.","category":"page"},{"location":"examples/pig-breeding/#pig-breeding","page":"Pig Breeding","title":"Pig Breeding","text":"","category":"section"},{"location":"examples/pig-breeding/#Description","page":"Pig Breeding","title":"Description","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The pig breeding problem as described in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"A pig breeder is growing pigs for a period of four months and subsequently selling them. During this period the pig may or may not develop a certain disease. If the pig has the disease at the time it must be sold, the pig must be sold for slaughtering, and its expected market price is then 300 DKK (Danish kroner). If it is disease free, its expected market price as a breeding animal is 1000 DKKOnce a month, a veterinary doctor sees the pig and makes a test for presence of the disease. If the pig is ill, the test will indicate this with probability 0.80, and if the pig is healthy, the test will indicate this with probability 0.90. At each monthly visit, the doctor may or may not treat the pig for the disease by injecting a certain drug. The cost of an injection is 100 DKK.A pig has the disease in the first month with probability 0.10. A healthy pig develops the disease in the subsequent month with probability 0.20 without injection, whereas a healthy and treated pig develops the disease with probability 0.10, so the injection has some preventive effect. An untreated pig that is unhealthy will remain so in the subsequent month with probability 0.90, whereas the similar probability is 0.50 for an unhealthy pig that is treated. Thus spontaneous cure is possible, but treatment is beneficial on average.","category":"page"},{"location":"examples/pig-breeding/#Influence-diagram","page":"Pig Breeding","title":"Influence diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"(Image: )","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The influence diagram for the generalized N-month pig breeding problem. The nodes are associated with the following states. Health states h_k=illhealthy represent the health of the pig at month k=1N. Test states t_k=positivenegative represent the result from testing the pig at month k=1N-1. Treatment states d_k=treat pass represent the decision to treat the pig with an injection at month k=1N-1.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The dashed arcs represent the no-forgetting principle. The no-forgetting assumption does not hold without them and they are tnot included in the following model. They could be included by changing the information sets of nodes.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In this example, we solve the 4 month pig breeding problem and thus, declare N = 4.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"using JuMP, HiGHS\nusing DecisionProgramming\n\nconst N = 4","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In Decision Programming, we start by initialising an empty influence diagram. Then we define the nodes with their information sets and states and add them to the influence diagram.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"diagram = InfluenceDiagram()","category":"page"},{"location":"examples/pig-breeding/#Health-at-first-month","page":"Pig Breeding","title":"Health at first month","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"As seen in the influence diagram, the node h_1 has no arcs into it making it a root node. Therefore, the information set I(h_1) is empty. The states of this node are ill and healthy.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"add_node!(diagram, ChanceNode(\"H1\", [], [\"ill\", \"healthy\"]))","category":"page"},{"location":"examples/pig-breeding/#Health,-test-results-and-treatment-decisions-at-subsequent-months","page":"Pig Breeding","title":"Health, test results and treatment decisions at subsequent months","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The chance and decision nodes representing the health, test results, treatment decisions for the following months can be added easily using a for-loop. The value node representing the treatment costs in each month is also added. Each node is given a name, its information set and states. Remember that value nodes do not have states. Notice that we do not assume the no-forgetting principle and thus, the information sets of the treatment decisions only contain the previous test result.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for i in 1:N-1\n    # Testing result\n    add_node!(diagram, ChanceNode(\"T$i\", [\"H$i\"], [\"positive\", \"negative\"]))\n    # Decision to treat\n    add_node!(diagram, DecisionNode(\"D$i\", [\"T$i\"], [\"treat\", \"pass\"]))\n    # Cost of treatment\n    add_node!(diagram, ValueNode(\"V$i\", [\"D$i\"]))\n    # Health of next period\n    add_node!(diagram, ChanceNode(\"H$(i+1)\", [\"H$(i)\", \"D$(i)\"], [\"ill\", \"healthy\"]))\nend","category":"page"},{"location":"examples/pig-breeding/#Market-price","page":"Pig Breeding","title":"Market price","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The final value node, representing the market price, is added. It has the final health node h_N as its information set.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"add_node!(diagram, ValueNode(\"V4\", [\"H$N\"]))","category":"page"},{"location":"examples/pig-breeding/#Generate-arcs","page":"Pig Breeding","title":"Generate arcs","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Now that all of the nodes have been added to the influence diagram, we generate the arcs between the nodes. This step automatically orders the nodes, gives them indices and reorganises the information into the correct form.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"generate_arcs!(diagram)","category":"page"},{"location":"examples/pig-breeding/#Probabilities","page":"Pig Breeding","title":"Probabilities","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We define probability distributions for all chance nodes. For the first health node, the probability distribution is defined over its two states ill and healthy. The probability that the pig is ill in the first month is","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"â„™(h_1 = ill)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We obtain the complement probabilities for binary states by subtracting from one","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"â„™(h_1 = healthy)=1-â„™(h_1 = ill)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In Decision Programming, we add these probabilities for node h_1 as follows. Notice, that the probability vector is ordered according to the order that the states were given in when defining node h_1. More information on the syntax of adding probabilities is found on the usage page.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"add_probabilities!(diagram, \"H1\", [0.1, 0.9])","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability distributions for the other health nodes are identical. Thus, we define one probability matrix and use it for all the subsequent months' health nodes. The probability that the pig is ill in the subsequent months k=2N depends on the treatment decision and state of health in the previous month k-1. The nodes h_k-1 and d_k-1 are thus in the information set I(h_k), meaning that the probability distribution of h_k is conditional on these nodes:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"â„™(h_k = ill  h_k-1 = healthy  d_k-1 = pass)=02","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"â„™(h_k = ill  h_k-1 = healthy  d_k-1 = treat)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"â„™(h_k = ill  h_k-1 = ill  d_k-1 = pass)=09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"â„™(h_k = ill  h_k-1 = ill  d_k-1 = treat)=05","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In Decision Programming, the probability matrix is defined in the following way. Notice, that the ordering of the information state corresponds to the order in which the information set was defined when adding the health nodes.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"X_H = ProbabilityMatrix(diagram, \"H2\")\nX_H[\"healthy\", \"pass\", :] = [0.2, 0.8]\nX_H[\"healthy\", \"treat\", :] = [0.1, 0.9]\nX_H[\"ill\", \"pass\", :] = [0.9, 0.1]\nX_H[\"ill\", \"treat\", :] = [0.5, 0.5]","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Next we define the probability matrix for the test results. Here again, we note that the probability distributions for all test results are identical, and thus we only define the probability matrix once. For the probabilities that the test indicates a pig's health correctly at month k=1N-1, we have","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"â„™(t_k = positive  h_k = ill) = 08","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"â„™(t_k = negative  h_k = healthy) = 09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In Decision Programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"X_T = ProbabilityMatrix(diagram, \"T1\")\nX_T[\"ill\", \"positive\"] = 0.8\nX_T[\"ill\", \"negative\"] = 0.2\nX_T[\"healthy\", \"negative\"] = 0.9\nX_T[\"healthy\", \"positive\"] = 0.1","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We add the probability matrices into the influence diagram using a for-loop.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for i in 1:N-1\n    add_probabilities!(diagram, \"T$i\", X_T)\n    add_probabilities!(diagram, \"H$(i+1)\", X_H)\nend","category":"page"},{"location":"examples/pig-breeding/#Utilities","page":"Pig Breeding","title":"Utilities","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The cost incurred by the treatment decision at month k=1N-1 is","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=treat) = -100","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=pass) = 0","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In Decision Programming the utility values are added using utility matrices. Notice that the utility values in the matrix are given in the same order as the states of node h_N were defined when node h_N was added.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for i in 1:N-1\n    add_utilities!(diagram, \"V$i\", [-100.0, 0.0])\nend","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The market price of the pig given its health at month N is","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=ill) = 300","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=healthy) = 1000","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In Decision Programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"add_utilities!(diagram, \"V4\", [300.0, 1000.0])","category":"page"},{"location":"examples/pig-breeding/#Generate-influence-diagram","page":"Pig Breeding","title":"Generate influence diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"After adding nodes, generating arcs and defining probability and utility values, we generate the full influence diagram. By default this function uses the default path probabilities and utilities, which are defined as the joint probability of all chance events in the diagram and the sum of utilities in value nodes, respectively. In the Contingent Portfolio Programming example, we show how to use a user-defined custom path utility function.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In the pig breeding problem, when the N is large some of the path utilities become negative. In this case, we choose to use the positive path utility transformation, which allows us to exclude the probability cut in the next section.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"generate_diagram!(diagram, positive_path_utility = true)","category":"page"},{"location":"examples/pig-breeding/#Decision-model","page":"Pig Breeding","title":"Decision model","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Next we initialise the JuMP model and add the decision variables. DecisionVariables has an optional argument names, which will name variables according to node names with state indices if set as true and just as simple indices if set as false. The latter might bring some performance improvements for very large models. The default value is true, which is generally preferable due to more clear naming of variables. ","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Then we add the path compatibility variables. Since we applied an affine transformation to the utility function, making all path utilities positive, the probability cut can be excluded from the model. The purpose of this is discussed in the theoretical section of this documentation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"model = Model()\nz = DecisionVariables(model, diagram, names=true)\nx_s = PathCompatibilityVariables(model, diagram, z, probability_cut = false)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We create the objective function","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"EV = expected_value(model, diagram, x_s)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"and set up the solver.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"optimizer = optimizer_with_attributes(\n    () -> HiGHS.Optimizer()\n)\nset_optimizer(model, optimizer)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Finally, we use the single policy update heuristic to obtain an initial solution and then solve the problem.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"spu = singlePolicyUpdate(diagram, model, z, x_s)\noptimize!(model)","category":"page"},{"location":"examples/pig-breeding/#Analyzing-results","page":"Pig Breeding","title":"Analyzing results","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Once the model is solved, we extract the results. The results are the decision strategy, state probabilities and utility distribution.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Z = DecisionStrategy(diagram, z)\nS_probabilities = StateProbabilities(diagram, Z)\nU_distribution = UtilityDistribution(diagram, Z)","category":"page"},{"location":"examples/pig-breeding/#Decision-strategy","page":"Pig Breeding","title":"Decision strategy","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The optimal decision strategy is:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_decision_strategy(diagram, Z, S_probabilities)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of T1 â”‚ Decision in D1 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ positive       â”‚ pass           â”‚\nâ”‚ negative       â”‚ pass           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of T2 â”‚ Decision in D2 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ positive       â”‚ treat          â”‚\nâ”‚ negative       â”‚ pass           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of T3 â”‚ Decision in D3 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ positive       â”‚ treat          â”‚\nâ”‚ negative       â”‚ pass           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The optimal strategy is to not treat the pig in the first month regardless of if it is sick or not. In the two subsequent months, the pig should be treated if the test result is positive.","category":"page"},{"location":"examples/pig-breeding/#State-probabilities","page":"Pig Breeding","title":"State probabilities","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The state probabilities for strategy Z tell the probability of each state in each node, given strategy Z.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia>  health_nodes = [[\"H$i\" for i in 1:N]...]\njulia> print_state_probabilities(diagram, S_probabilities, health_nodes)\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Node â”‚      ill â”‚  healthy â”‚ Fixed state â”‚\nâ”‚ String â”‚  Float64 â”‚  Float64 â”‚      String â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     H1 â”‚ 0.100000 â”‚ 0.900000 â”‚             â”‚\nâ”‚     H2 â”‚ 0.270000 â”‚ 0.730000 â”‚             â”‚\nâ”‚     H3 â”‚ 0.295300 â”‚ 0.704700 â”‚             â”‚\nâ”‚     H4 â”‚ 0.305167 â”‚ 0.694833 â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\njulia> test_nodes = [[\"T$i\" for i in 1:N-1]...]\njulia> print_state_probabilities(diagram, S_probabilities, test_nodes)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Node â”‚ positive â”‚ negative â”‚ Fixed state â”‚\nâ”‚ String â”‚  Float64 â”‚  Float64 â”‚      String â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     T1 â”‚ 0.170000 â”‚ 0.830000 â”‚             â”‚\nâ”‚     T2 â”‚ 0.289000 â”‚ 0.711000 â”‚             â”‚\nâ”‚     T3 â”‚ 0.306710 â”‚ 0.693290 â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\njulia> treatment_nodes = [[\"D$i\" for i in 1:N-1]...]\njulia> print_state_probabilities(diagram, S_probabilities, treatment_nodes)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Node â”‚    treat â”‚     pass â”‚ Fixed state â”‚\nâ”‚ String â”‚  Float64 â”‚  Float64 â”‚      String â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     D1 â”‚ 0.000000 â”‚ 1.000000 â”‚             â”‚\nâ”‚     D2 â”‚ 0.289000 â”‚ 0.711000 â”‚             â”‚\nâ”‚     D3 â”‚ 0.306710 â”‚ 0.693290 â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/pig-breeding/#Utility-distribution","page":"Pig Breeding","title":"Utility distribution","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We can also print the utility distribution for the optimal strategy. The selling prices for a healthy and an ill pig are 1000DKK and 300DKK, respectively, while the cost of treatment is 100DKK. We can see that the probability of the pig being ill in the end is the sum of three first probabilities, approximately 30.5%. This matches the probability of state ill in the last node h_4 in the state probabilities shown above.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_utility_distribution(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Utility â”‚ Probability â”‚\nâ”‚     Float64 â”‚     Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  100.000000 â”‚    0.047857 â”‚\nâ”‚  200.000000 â”‚    0.129330 â”‚\nâ”‚  300.000000 â”‚    0.127980 â”‚\nâ”‚  800.000000 â”‚    0.061753 â”‚\nâ”‚  900.000000 â”‚    0.247160 â”‚\nâ”‚ 1000.000000 â”‚    0.385920 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Finally, we print some statistics for the utility distribution. The expected value of the utility is 727DKK, the same as in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_statistics(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Name â”‚ Statistics â”‚\nâ”‚   String â”‚    Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     Mean â”‚ 726.812100 â”‚\nâ”‚      Std â”‚ 338.460723 â”‚\nâ”‚ Skewness â”‚  -0.811628 â”‚\nâ”‚ Kurtosis â”‚  -1.173465 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/pig-breeding/#References","page":"Pig Breeding","title":"References","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"[1]: Lauritzen, S. L., & Nilsson, D. (2001). Representing and solving decision problems with limited information. Management Science, 47(9), 1235â€“1251. https://doi.org/10.1287/mnsc.47.9.1235.9779","category":"page"},{"location":"decision-programming/computational-complexity/#computational-complexity","page":"Computational Complexity","title":"Computational Complexity","text":"","category":"section"},{"location":"decision-programming/computational-complexity/#Introduction","page":"Computational Complexity","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Decision programming relies on mixed-integer linear programming, which is known to be an NP-hard problem. In this section, we analyze how the influence diagram affects the size of the mixed-integer linear model, determining whether it is tractable.","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We use the following inequalities for sum and product of non-negative elements A to derive the lower and upper bounds for the number of paths and the number of decision variables. Sum inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"A left(min_aA aright)  _aA a  A left(max_aA aright)","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Product inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_aA aright)^A  _aA a  left(max_aA aright)^A","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"The following bounds for the number of paths and the number of decision variables show how the number of states, nodes, and arcs affects the size of the model.","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Paths","page":"Computational Complexity","title":"Number of Paths","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the influence diagram, we know the path length n=CD Then, we have the bounds for the number of paths as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_iCD S_iright)^n  ğ’  left(max_iCD S_iright)^n","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We assume that all nodes iCD are non-trivial. That is, each decision or chance node has at least two states S_i2 Then, the number of paths is exponential to the path length n","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Decision-Variables","page":"Computational Complexity","title":"Number of Decision Variables","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We define the number of decision variables as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"_iDğ’_I(i)i = _iD _jI(i)iS_j","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the information set, for all iD we have I(i)iCD with size 1I(i)i=I(i)+1mn where m denotes the upper bound of influence other nodes have on any decision node. Also, we have the number of decision nodes 0Dn Thus, we have the bounds","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"0  _iDğ’_I(i)i  D left(max_iCD S_jright)^m","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"In the worst case, m=n, a decision node is influenced by every other chance and decision node. However, in most practical cases, we have m  n where decision nodes are influenced only by a limited number of other chance and decision nodes, making models easier to solve.","category":"page"},{"location":"decision-programming/computational-complexity/#Numerical-challenges","page":"Computational Complexity","title":"Numerical challenges","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"As has become evident above, in Decision Programming the size of the Decision Model may become large if the influence diagram has a large number of nodes or nodes with a large number of states. In practice, this results in having a large number of path compatibility and decision variables. This may result in numerical challenges.","category":"page"},{"location":"decision-programming/computational-complexity/#Probability-Scaling-Factor","page":"Computational Complexity","title":"Probability Scaling Factor","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"If an influence diagram has a large number of nodes or some nodes have a large set of states, the path probabilities p(ğ¬) become increasingly small. This may cause numerical issues with the solver, even prevent it from finding a solution. This issue is showcased in the CHD preventative care example.","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"The issue may be helped by multiplying the path probabilities with a scaling factor gamma  0. For example, the objective function becomes","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"operatornameE(Z) = _ğ¬ğ’ x(ğ¬)  p(ğ¬)  gamma  mathcalU(ğ¬)","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"The path probabilities should also be scaled in other objective functions or constraints, including the conditional value-at-risk function and the probability cut constraint _ğ¬ğ’x(ğ¬) p(ğ¬) = 1.","category":"page"},{"location":"examples/CHD_preventative_care/#CHD-preventative-care-allocation","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"","category":"section"},{"location":"examples/CHD_preventative_care/#Description","page":"CHD preventative care allocation","title":"Description","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The goal in this optimisation problem is to determine an optimal decision strategy for the testing and treatment decisions involved in providing preventative care for coronary heart disease (CHD). The optimality is evaluated from the perspective of the national health care system and is measured in quality-adjusted life-years (QALY). The tests available in this model are the traditional risk score (TRS) and the genetic risk score (GRS) and the form of preventative care is statin treatment. The description of the CHD preventative care allocation problem is below. This description is from [1] from section 3.2.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The problem setting is such that the patient is assumed to have a prior risk estimate. A risk estimate is a prediction of the patientâ€™s chance of having a CHD event in the next ten years. The risk estimates are grouped into risk levels, which range from 0% to 100%. The first testing decision is made based on the prior risk estimate. The first testing decision entails deciding whether TRS or GRS should be performed or if no testing is needed. If a test is conducted, the risk estimate is updated and based on the new information, the second testing decision is made. The second testing decision entails deciding whether further testing should be conducted or not. The second testing decision is constrained so that the same test which was conducted in the first stage cannot be repeated. If a second test is conducted, the risk estimate is updated again. The treatment decision â€“ dictating whether the patient receives statin therapy or not â€“ is made based on the resulting risk estimate of this testing process. Note that if no tests are conducted, the treatment decision is made based on the prior risk estimate.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"In this example, we will showcase the subproblem, which optimises the decision strategy given a single prior risk level. The chosen risk level in this example is 12%. The solution to the main problem is found in [1].","category":"page"},{"location":"examples/CHD_preventative_care/#Influence-diagram","page":"CHD preventative care allocation","title":"Influence diagram","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"(Image: )","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The influence diagram representation of the problem is seen above. The chance nodes R represent the patient's risk estimate â€“ the prior risk estimate being R0. The risk estimate nodes R0, R1 and R2 have 101 states R = 0 1  100, which are the discretised risk levels for the risk estimates.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The risk estimate is updated according to the first and second testing decisions, which are represented by decision nodes T1 and T2. These nodes have states T = textTRS GRS no test. The health of the patient, represented by chance node H, also affects the update of the risk estimate. In this model, the health of the patient indicates whether they will have a CHD event in the next ten years or not. Thus, the node has states H = textCHD no CHD. The treatment decision is represented by node TD and it has states TD = texttreatment no treatment.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The prior risk estimate represented by node R0 influences the health node H, because in the model we make the assumption that the prior risk estimate accurately describes the probability of having a CHD event.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The value nodes in the model are TC and HB. Node TC represents the testing costs incurred due to the testing decisions T1 and T2. Node HB represents the health benefits achieved. The testing costs and health benefits are measured in QALYs. These parameter values were evaluated in the study [2].","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We begin by declaring the chosen prior risk level and reading the conditional probability data for the tests. Note that the sample data in this repository is dummy data due to distribution restrictions on the real data. We also define functions update_risk_distribution and state_probabilities. These functions will be discussed in the following sections.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"using JuMP, HiGHS\nusing DecisionProgramming\nusing CSV, DataFrames, PrettyTables\n\n\nconst chosen_risk_level = 12%\nconst data = CSV.read(\"risk_prediction_data.csv\", DataFrame)\n\nfunction update_risk_distribution(prior::Int64, t::Int64)...\nend\n\nfunction state_probabilities(risk_p::Array{Float64}, t::Int64, h::Int64, prior::Int64)...\nend","category":"page"},{"location":"examples/CHD_preventative_care/#Initialise-influence-diagram","page":"CHD preventative care allocation","title":"Initialise influence diagram","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We start defining the Decision Programming model by initialising the influence diagram.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"diagram = InfluenceDiagram()","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"For brevity in the next sections, we define the states of the nodes to be readily available. Notice, that R_states is a vector with values 0 1 100.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"const H_states = [\"CHD\", \"no CHD\"]\nconst T_states = [\"TRS\", \"GRS\", \"no test\"]\nconst TD_states = [\"treatment\", \"no treatment\"]\nconst R_states = [string(x) * \"%\" for x in [0:1:100;]]","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We then add the nodes. The chance and decision nodes are identified by their names. When declaring the nodes, they are also given information sets and states. Notice that nodes R0 and H are root nodes, meaning that their information sets are empty. In Decision Programming, we add the chance and decision nodes in the follwoing way.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"add_node!(diagram, ChanceNode(\"R0\", [], R_states))\nadd_node!(diagram, ChanceNode(\"R1\", [\"R0\", \"H\", \"T1\"], R_states))\nadd_node!(diagram, ChanceNode(\"R2\", [\"R1\", \"H\", \"T2\"], R_states))\nadd_node!(diagram, ChanceNode(\"H\", [\"R0\"], H_states))\n\nadd_node!(diagram, DecisionNode(\"T1\", [\"R0\"], T_states))\nadd_node!(diagram, DecisionNode(\"T2\", [\"R1\"], T_states))\nadd_node!(diagram, DecisionNode(\"TD\", [\"R2\"], TD_states))","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The value nodes are added in a similar fashion. However, value nodes do not have states because they map their information states to utility values instead.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"add_node!(diagram, ValueNode(\"TC\", [\"T1\", \"T2\"]))\nadd_node!(diagram, ValueNode(\"HB\", [\"H\", \"TD\"]))","category":"page"},{"location":"examples/CHD_preventative_care/#Generate-arcs","page":"CHD preventative care allocation","title":"Generate arcs","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Now that all of the nodes have been added to the influence diagram we generate the arcs between the nodes. This step automatically orders the nodes, gives them indices and reorganises the information into the appropriate form.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"generate_arcs!(diagram)","category":"page"},{"location":"examples/CHD_preventative_care/#Probabilities-of-the-prior-risk-estimate-and-health-of-the-patient","page":"CHD preventative care allocation","title":"Probabilities of the prior risk estimate and health of the patient","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"In this subproblem, the prior risk estimate is given and therefore the node R0 is in effect a deterministic node. In Decision Programming a deterministic node is added as a chance node for which the probability of one state is set to one and the probabilities of the rest of the states are set to zero. In this case","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"â„™(R0 = 12)=1","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"and $â„™(R0 \\neq 12\\%)= 0. $","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The probability matrix of node R0 is added in the following way. Remember that the ProbabilityMatrix function initialises the matrix with zeros.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"X_R0 = ProbabilityMatrix(diagram, \"R0\")\nX_R0[chosen_risk_level] = 1\nadd_probabilities!(diagram, \"R0\", X_R0)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Next we add the state probabilities of node H. For modeling purposes, we define the information set of node H to include the prior risk node R0. We set the probability that the patient experiences a CHD event in the next ten years according to the prior risk level such that","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"â„™(H = textCHD  R0 = alpha) = alpha","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We set the probability that the patient does not experience a CHD event in the next ten years as the complement event.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"â„™(H = textno CHD  R0 = alpha) = 1 - alpha","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Since node R0 is deterministic and the health node H is defined in this way, in our model the patient has a 12% chance of experiencing a CHD event and 88% chance of remaining healthy.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"In this Decision Programming model, the probability matrix of node H has dimensions (101, 2) because its information set consisting of node R0 has 101 states and node H has 2 states. We first set the column related to the state CHD with values from data.risk_levels which are 000 001  099 100 and the other column as its complement event.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"X_H = ProbabilityMatrix(diagram, \"H\")\nX_H[:, \"CHD\"] = data.risk_levels\nX_H[:, \"no CHD\"] = 1 .- data.risk_levels\nadd_probabilities!(diagram, \"H\", X_H)","category":"page"},{"location":"examples/CHD_preventative_care/#Probabilities-of-the-updated-the-risk-estimates","page":"CHD preventative care allocation","title":"Probabilities of the updated the risk estimates","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"For node R1, the probabilities of the states are calculated by aggregating the updated risk estimates into the risk levels after a test is performed. The updated risk estimates are calculated using the function update_risk_distribution, which calculates the posterior probability distribution for a given health state, test and prior risk estimate.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"textitrisk estimate = P(textCHD mid texttest result) = fracP(texttest result mid textCHD)P(textCHD)P(texttest result)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The probabilities P(texttest result mid textCHD) are test specific and these are read from the CSV data file. The updated risk estimates are aggregated according to the risk levels. These aggregated probabilities are then the state probabilities of node R1. The aggregating is done using function state_probabilities.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"In Decision Programming the probability distribution over the states of node R1 is defined into a probability matrix with dimensions (10123101). This is because its information set consists of nodes R0 H and, T which have 101, 2 and 3 states respectively and the node R1 itself has 101 states. Here, one must know that in Decision Programming the states of the nodes are mapped to numbers in the back-end. For instance, the health states textCHD and textno CHD  are indexed 1 and 2. The testing decision states TRS, GRS and no test are 1, 2 and 3. The order of the states is determined by the order in which they are defined when adding the nodes. Knowing this, we can set the probability values into the probability matrix using a very compact syntax. Notice that we add 101 probability values at a time into the matrix.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"X_R = ProbabilityMatrix(diagram, \"R1\")\nfor s_R0 = 1:101, s_H = 1:2, s_T1 = 1:3\n    X_R[s_R0, s_H,  s_T1, :] =  state_probabilities(update_risk_distribution(s_R0, s_T1), s_T1, s_H, s_R0)\nend\nadd_probabilities!(diagram, \"R1\", X_R)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We notice that the probability distrubtion is identical in R1 and R2 because their information states are identical. Therefore we can simply add the same matrix from above as the probability matrix of node R2.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"add_probabilities!(diagram, \"R2\", X_R)","category":"page"},{"location":"examples/CHD_preventative_care/#Utilities-of-testing-costs-and-health-benefits","page":"CHD preventative care allocation","title":"Utilities of testing costs and health benefits","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We define a utility matrix for node TC, which maps all its information states to testing costs. The unit in which the testing costs are added is quality-adjusted life-year (QALYs). The utility matrix is defined and added in the following way.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"cost_TRS = -0.0034645\ncost_GRS = -0.004\nforbidden = 0     #the cost of forbidden test combinations is negligible\n\nY_TC = UtilityMatrix(diagram, \"TC\")\nY_TC[\"TRS\", \"TRS\"] = forbidden\nY_TC[\"TRS\", \"GRS\"] = cost_TRS + cost_GRS\nY_TC[\"TRS\", \"no test\"] = cost_TRS\nY_TC[\"GRS\", \"TRS\"] = cost_TRS + cost_GRS\nY_TC[\"GRS\", \"GRS\"] = forbidden\nY_TC[\"GRS\", \"no test\"] = cost_GRS\nY_TC[\"no test\", \"TRS\"] = cost_TRS\nY_TC[\"no test\", \"GRS\"] = cost_GRS\nY_TC[\"no test\", \"no test\"] = 0\nadd_utilities!(diagram, \"TC\", Y_TC)\n","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The health benefits that are achieved are determined by whether treatment is administered and by the health of the patient. We add the final utility matrix to the model.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Y_HB = UtilityMatrix(diagram, \"HB\")\nY_HB[\"CHD\", \"treatment\"] = 6.89713671259061\nY_HB[\"CHD\", \"no treatment\"] = 6.65436854256236\nY_HB[\"no CHD\", \"treatment\"] = 7.64528451705134\nY_HB[\"no CHD\", \"no treatment\"] = 7.70088349200034\nadd_utilities!(diagram, \"HB\", Y_HB)","category":"page"},{"location":"examples/CHD_preventative_care/#Generate-influence-diagram","page":"CHD preventative care allocation","title":"Generate influence diagram","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Finally, we generate the full influence diagram before defining the decision model. By default this function uses the default path probabilities and utilities, which are defined as the joint probability of all chance events in the diagram and the sum of utilities in value nodes, respectively. In the Contingent Portfolio Programming example, we show how to use a user-defined custom path utility function.","category":"page"},{"location":"examples/CHD_preventative_care/#Decision-Model","page":"CHD preventative care allocation","title":"Decision Model","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We define the JuMP model and declare the decision variables.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"model = Model()\nz = DecisionVariables(model, diagram)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"In this problem, we want to forbid the model from choosing paths where the same test is repeated twice and where the first testing decision is not to perform a test but the second testing decision is to perform a test. We forbid the paths by declaring these combinations of states as forbidden paths.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"forbidden_tests = ForbiddenPath(diagram, [\"T1\",\"T2\"], [(\"TRS\", \"TRS\"),(\"GRS\", \"GRS\"),(\"no test\", \"TRS\"), (\"no test\", \"GRS\")])","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We fix the state of the deterministic R0 node by declaring it as a fixed path. Fixing the state of node R0 is not necessary because of how the probabilities were defined. However, the fixed state reduces the need for some computation in the back-end.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"fixed_R0 = FixedPath(diagram, Dict(\"R0\" => chosen_risk_level))","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We also choose a scale factor of 10000, which will be used to scale the path probabilities. The probabilities need to be scaled because in this specific problem they are very small since the R nodes have a large number of states. Scaling the probabilities helps the solver find an optimal solution.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We then declare the path compatibility variables. We fix the state of the deterministic R0 node , forbid the unwanted testing strategies and scale the probabilities by giving them as parameters in the function call.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"scale_factor = 10000.0\nx_s = PathCompatibilityVariables(model, diagram, z; fixed = fixed_R0, forbidden_paths = [forbidden_tests], probability_cut=false)\n\n","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We define the objective function as the expected value.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"EV = expected_value(model, diagram, x_s, probability_scale_factor = scale_factor)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We set up the solver for the problem and optimise it.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"optimizer = optimizer_with_attributes(\n    () -> HiGHS.Optimizer()\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/CHD_preventative_care/#Analyzing-results","page":"CHD preventative care allocation","title":"Analyzing results","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We extract the results in the following way.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Z = DecisionStrategy(z)\nS_probabilities = StateProbabilities(diagram, Z)\nU_distribution = UtilityDistribution(diagram, Z)\n","category":"page"},{"location":"examples/CHD_preventative_care/#Decision-strategy","page":"CHD preventative care allocation","title":"Decision strategy","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We inspect the decision strategy. From the printout, we can see that when the prior risk level is 12% the optimal decision strategy is to first perform TRS testing. At the second decision stage, GRS should be conducted if the updated risk estimate is between 16% and 28% and otherwise no further testing should be conducted. Treatment should be provided to those who have a final risk estimate greater than 18%. Notice that the incompatible states are not included in the printout. The incompatible states are those that have a state probability of zero, which means that given this data it is impossible for the patient to have their risk estimate updated to those risk levels.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"julia> print_decision_strategy(diagram, Z, S_probabilities)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of R0 â”‚ Decision in T1 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 12%            â”‚ TRS            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of R1 â”‚ Decision in T2 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 0%             â”‚ no test        â”‚\nâ”‚ 1%             â”‚ no test        â”‚\nâ”‚ 3%             â”‚ no test        â”‚\nâ”‚ 6%             â”‚ no test        â”‚\nâ”‚ 7%             â”‚ no test        â”‚\nâ”‚ 10%            â”‚ no test        â”‚\nâ”‚ 11%            â”‚ no test        â”‚\nâ”‚ 13%            â”‚ no test        â”‚\nâ”‚ 14%            â”‚ no test        â”‚\nâ”‚ 16%            â”‚ GRS            â”‚\nâ”‚ 17%            â”‚ GRS            â”‚\nâ”‚ 18%            â”‚ GRS            â”‚\nâ”‚ 21%            â”‚ GRS            â”‚\nâ”‚ 22%            â”‚ GRS            â”‚\nâ”‚ 23%            â”‚ GRS            â”‚\nâ”‚ 28%            â”‚ no test        â”‚\nâ”‚ 29%            â”‚ no test        â”‚\nâ”‚ 31%            â”‚ no test        â”‚\nâ”‚ 34%            â”‚ no test        â”‚\nâ”‚  â‹®             â”‚    â‹®            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                rows omitted\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of R2 â”‚ Decision in TD â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 0%             â”‚ no treatment   â”‚\nâ”‚ 1%             â”‚ no treatment   â”‚\nâ”‚ 2%             â”‚ no treatment   â”‚\nâ”‚ 3%             â”‚ no treatment   â”‚\nâ”‚ 6%             â”‚ no treatment   â”‚\nâ”‚ 7%             â”‚ no treatment   â”‚\nâ”‚ 8%             â”‚ no treatment   â”‚\nâ”‚ 9%             â”‚ no treatment   â”‚\nâ”‚ 10%            â”‚ no treatment   â”‚\nâ”‚ 11%            â”‚ no treatment   â”‚\nâ”‚ 12%            â”‚ no treatment   â”‚\nâ”‚ 13%            â”‚ no treatment   â”‚\nâ”‚ 14%            â”‚ no treatment   â”‚\nâ”‚ 15%            â”‚ no treatment   â”‚\nâ”‚ 16%            â”‚ no treatment   â”‚\nâ”‚ 17%            â”‚ no treatment   â”‚\nâ”‚ 18%            â”‚ treatment      â”‚\nâ”‚ 19%            â”‚ treatment      â”‚\nâ”‚ 20%            â”‚ treatment      â”‚\nâ”‚  â‹®             â”‚    â‹®            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                rows omitted","category":"page"},{"location":"examples/CHD_preventative_care/#Utility-distribution","page":"CHD preventative care allocation","title":"Utility distribution","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We can also print the utility distribution for the optimal strategy and some basic statistics for the distribution.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"julia> print_utility_distribution(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Utility â”‚ Probability â”‚\nâ”‚  Float64 â”‚     Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 6.646904 â”‚    0.005318 â”‚\nâ”‚ 6.650904 â”‚    0.038707 â”‚\nâ”‚ 6.889672 â”‚    0.011602 â”‚\nâ”‚ 6.893672 â”‚    0.064374 â”‚\nâ”‚ 7.637820 â”‚    0.034188 â”‚\nâ”‚ 7.641820 â”‚    0.073974 â”‚\nâ”‚ 7.693419 â”‚    0.035266 â”‚\nâ”‚ 7.697419 â”‚    0.736573 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"julia> print_statistics(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Name â”‚ Statistics â”‚\nâ”‚   String â”‚    Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     Mean â”‚   7.583923 â”‚\nâ”‚      Std â”‚   0.291350 â”‚\nâ”‚ Skewness â”‚  -2.414877 â”‚\nâ”‚ Kurtosis â”‚   4.059711 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/CHD_preventative_care/#References","page":"CHD preventative care allocation","title":"References","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"[1]: Hankimaa H. (2021). Optimising the use of genetic testing in prevention of CHD using Decision Programming. http://urn.fi/URN:NBN:fi:aalto-202103302644","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"[2]: Hynninen Y. (2019). Value of genetic testing in the prevention of coronary heart disease events. PLOS ONE, 14(1):1â€“16. https://doi.org/10.1371/journal.pone.0210010","category":"page"},{"location":"examples/contingent-portfolio-programming/#Contingent-Portfolio-Programming","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"warning: Warning\nThis example discusses adding constraints and decision variables to the Decision Programming formulation, as well as custom path utility calculation. Because of this, it is quite advanced compared to the earlier ones. ","category":"page"},{"location":"examples/contingent-portfolio-programming/#Description","page":"Contingent Portfolio Programming","title":"Description","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"[1], section 4.2","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"For instance, assume that the first-stage decisions specify which technology development projects will be started to generate patent-based intellectual property ( P ) for a platform. This intellectual property contributes subject to some uncertainties to the technical competitiveness ( T ) of the platform. In the second stage, it is possible to carry out application ( A ) development projects which, when completed, yield cash flows that depend on the market share of the platform. This market share ( M ) depends on the competitiveness of the platform and the number of developed applications. The aim is to maximize the cash flows from application projects less the cost of technology and application development projects.","category":"page"},{"location":"examples/contingent-portfolio-programming/#Influence-Diagram:-Projects","page":"Contingent Portfolio Programming","title":"Influence Diagram: Projects","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"(Image: )","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"The influence diagram of the contingent portfolio programming (CPP) problem.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"There are n_T technology development projects and n_A application development projects.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision states to develop patents","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"d_i^PD_i^P=q_1^P q_2^P) q_2^P q_3^P)  q_D^P^P q_D^P+1^P)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Chance states of technical competitiveness c_j^TC_j^T","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision states to develop applications","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"d_k^AD^A=q_1^A q_2^A) q_2^A q_3^A)  q_D^A^A q_D^A+1^A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Chance states of market size c_l^MC_l^M","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"using Random\nusing JuMP, HiGHS\nusing DecisionProgramming\n\nRandom.seed!(42)\n\ndiagram = InfluenceDiagram()\n\nadd_node!(diagram, DecisionNode(\"DP\", [], [\"0-3 patents\", \"3-6 patents\", \"6-9 patents\"]))\nadd_node!(diagram, ChanceNode(\"CT\", [\"DP\"], [\"low\", \"medium\", \"high\"]))\nadd_node!(diagram, DecisionNode(\"DA\", [\"DP\", \"CT\"], [\"0-5 applications\", \"5-10 applications\", \"10-15 applications\"]))\nadd_node!(diagram, ChanceNode(\"CM\", [\"CT\", \"DA\"], [\"low\", \"medium\", \"high\"]))\n\ngenerate_arcs!(diagram)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Technical-competitiveness-probability","page":"Contingent Portfolio Programming","title":"Technical competitiveness probability","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Probability of technical competitiveness c_j^T given the range d_i^P: â„™(c_j^Td_i^P)01. A high number of patents increases probability of high competitiveness and a low number correspondingly increases the probability of low competitiveness.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"X_CT = ProbabilityMatrix(diagram, \"CT\")\nX_CT[1, :] = [1/2, 1/3, 1/6]\nX_CT[2, :] = [1/3, 1/3, 1/3]\nX_CT[3, :] = [1/6, 1/3, 1/2]\nadd_probabilities!(diagram, \"CT\", X_CT)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Market-share-probability","page":"Contingent Portfolio Programming","title":"Market share probability","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Probability of market share c_l^M given the technical competitiveness c_j^T and range d_k^A: â„™(c_l^Mc_j^Td_k^A)01. Higher competitiveness and number of application projects both increase the probability of high market share.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"X_CM = ProbabilityMatrix(diagram, \"CM\")\nX_CM[1, 1, :] = [2/3, 1/4, 1/12]\nX_CM[1, 2, :] = [1/2, 1/3, 1/6]\nX_CM[1, 3, :] = [1/3, 1/3, 1/3]\nX_CM[2, 1, :] = [1/2, 1/3, 1/6]\nX_CM[2, 2, :] = [1/3, 1/3, 1/3]\nX_CM[2, 3, :] = [1/6, 1/3, 1/2]\nX_CM[3, 1, :] = [1/3, 1/3, 1/3]\nX_CM[3, 2, :] = [1/6, 1/3, 1/2]\nX_CM[3, 3, :] = [1/12, 1/4, 2/3]\nadd_probabilities!(diagram, \"CM\", X_CM)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Generating-the-Influence-Diagram","page":"Contingent Portfolio Programming","title":"Generating the Influence Diagram","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We are going to be using a custom objective function, and don't need the default path utilities for that.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"generate_diagram!(diagram, default_utility=false)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Decision-Model:-Portfolio-Selection","page":"Contingent Portfolio Programming","title":"Decision Model: Portfolio Selection","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We create the decision variables z(s_js_I(j)) and notice that the activation of paths that are compatible with the decision strategy is handled by the problem specific variables and constraints together with the custom objective function, eliminating the need for separate variables representing path activation.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"model = Model()\nz = DecisionVariables(model, diagram)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Creating-problem-specific-variables","page":"Contingent Portfolio Programming","title":"Creating problem specific variables","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We recommend reading Section 4.2. in [1] for motivation and details of the formulation.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Technology project t costs I_tâ„^+ and generates O_tâ„• patents.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Application project a costs I_aâ„^+ and generates O_aâ„• applications. If completed, provides cash flow V(ac_l^M)â„^+","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"\n# Number of states in each node\nn_DP = num_states(diagram, \"DP\")\nn_CT = num_states(diagram, \"CT\")\nn_DA = num_states(diagram, \"DA\")\nn_CM = num_states(diagram, \"CM\")\n\nn_T = 5                     # number of technology projects\nn_A = 5                     # number of application projects\nI_t = rand(n_T)*0.1         # costs of technology projects\nO_t = rand(1:3,n_T)         # number of patents for each tech project\nI_a = rand(n_T)*2           # costs of application projects\nO_a = rand(2:4,n_T)         # number of applications for each appl. project\n\nV_A = rand(n_CM, n_A).+0.5 # Value of an application\nV_A[1, :] .+= -0.5          # Low market share: less value\nV_A[3, :] .+= 0.5           # High market share: more value","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision variables x^T(t)0 1 indicate which technologies are selected.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision variables x^A(ad_i^Pc_j^T)0 1 indicate which applications are selected.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"function variables(model::Model, dims::AbstractVector{Int}; binary::Bool=false)\n    v = Array{VariableRef}(undef, dims...)\n    for i in eachindex(v)\n        v[i] = @variable(model, binary=binary)\n    end\n    return v\nend\n\nx_T = variables(model, [n_DP, n_T]; binary=true)\nx_A = variables(model, [n_DP, n_CT, n_DA, n_A]; binary=true)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Number of patents x^T(t) = _i x_i^T(t) z(d_i^P)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Number of applications x^A(ad_i^Pc_j^T) = _k x_k^A(ad_i^Pc_j^T) z(d_k^Ad_i^Pc_j^T)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Helpful variables:","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Large constant M (e.g. frac32textmaxsum_t O_tsum_a O_a)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Small constant varepsilon = frac12textminO_t O_a","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"M = 20                      # a large constant\nÎµ = 0.5*minimum([O_t O_a])  # a helper variable, allows using â‰¤ instead of < in constraints (28b) and (29b)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Limits q_i^P and q_k^A of the intervals","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_P = [0, 3, 6, 9]          # limits of the technology intervals\nq_A = [0, 5, 10, 15]        # limits of the application intervals","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Shorthand for the decision variables z","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"z_dP = z[\"DP\"].z\nz_dA = z[\"DA\"].z","category":"page"},{"location":"examples/contingent-portfolio-programming/#Creating-problem-specific-constraints","page":"Contingent Portfolio Programming","title":"Creating problem specific constraints","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_t x_i^T(t) le z(d_i^P)n_T quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:n_DP],\n    sum(x_T[i,t] for t in 1:n_T) <= z_dP[i]*n_T)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_a x_k^A(ad_i^Pc_j^T) le z(d_i^P)n_A quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA],\n    sum(x_A[i,j,k,a] for a in 1:n_A) <= z_dP[i]*n_A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_a x_k^A(ad_i^Pc_j^T) le z(d_k^Ad_i^Pc_j^T)n_A quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA],\n    sum(x_A[i,j,k,a] for a in 1:n_A) <= z_dA[i,j,k]*n_A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_i^P - (1-z(d_i^P))M le sum_t x_i^T(t)O_t le q_i+1^P + (1-z(d_i^P))M - varepsilon quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:n_DP],\n    q_P[i] - (1 - z_dP[i])*M <= sum(x_T[i,t]*O_t[t] for t in 1:n_T))\n@constraint(model, [i=1:n_DP],\n    sum(x_T[i,t]*O_t[t] for t in 1:n_T) <= q_P[i+1] + (1 - z_dP[i])*M - Îµ)\n","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_k^A - (1-z(d_k^Ad_i^Pc_j^T))M le sum_a x_k^A(ad_i^Pc_j^T)O_a le q_k+1^A + (1-z(d_k^Ad_i^Pc_j^T))M - varepsilon quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA],\n    q_A[k] - (1 - z_dA[i,j,k])*M <= sum(x_A[i,j,k,a]*O_a[a] for a in 1:n_A))\n@constraint(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA],\n    sum(x_A[i,j,k,a]*O_a[a] for a in 1:n_A) <= q_A[k+1] + (1 - z_dA[i,j,k])*M - Îµ)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We can also model dependencies between the technology and application projects, e.g. application project a can be completed only if technology project t has been completed. This is done by adding constraints","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_k^A(ad_i^Pc_j^T) le x_i^T(t) quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"As an example, we state that application projects 1 and 2 require technology project 1, and application project 2 also requires technology project 2.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA], x_A[i,j,k,1] <= x_T[i,1])\n@constraint(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA], x_A[i,j,k,2] <= x_T[i,1])\n@constraint(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA], x_A[i,j,k,2] <= x_T[i,2])","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_i^T(t)0 1 quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_k^A(ad_i^Pc_j^T)0 1 quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/#Objective-function","page":"Contingent Portfolio Programming","title":"Objective function","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"The path utility can be calculated as mathcalU(s) = sum_a x_k^A(ad_i^Pc_j^T) (V(ac_l^M) - I_a) - _t x_i^T(t) I_t","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"However, using the expected value objective would lead to a quadratic objective function as the path utility formulation now contains decision variables. In order to keep the problem completely linear, we can use the objective formulation presented in [1]:","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"sum_i left sum_jkl p(c_j^T mid d_i^P) p(c_l^M mid c_j^T d_k^A) leftsum_a x_k^A(a mid d_i^Pc_j^T) (V(a mid c_l^M) - I_a)right - sum_t x_i^T(t) I_t right","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"patent_investment_cost = @expression(model, [i=1:n_DP], sum(x_T[i, t] * I_t[t] for t in 1:n_T))\napplication_investment_cost = @expression(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA], sum(x_A[i, j, k, a] * I_a[a] for a in 1:n_A))\napplication_value = @expression(model, [i=1:n_DP, j=1:n_CT, k=1:n_DA, l=1:n_CM], sum(x_A[i, j, k, a] * V_A[l, a] for a in 1:n_A))\n@objective(model, Max, sum( sum( diagram.P(convert.(State, (i,j,k,l))) * (application_value[i,j,k,l] - application_investment_cost[i,j,k]) for j in 1:n_CT, k in 1:n_DA, l in 1:n_CM ) - patent_investment_cost[i] for i in 1:n_DP ))\n\n","category":"page"},{"location":"examples/contingent-portfolio-programming/#Solving-the-Model","page":"Contingent Portfolio Programming","title":"Solving the Model","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"optimizer = optimizer_with_attributes(\n    () -> HiGHS.Optimizer()\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Analyzing-results","page":"Contingent Portfolio Programming","title":"Analyzing results","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"The optimal decision strategy and the utility distribution are printed. The strategy is to make 6-9 patents (state 3 in node 1) and 10-15 applications. The expected utility for this strategy is 1.08. Julia version 1.10.3 was used in random number generation (the version used might affect the results).","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Z = DecisionStrategy(diagram, z)\nS_probabilities = StateProbabilities(diagram, Z)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_decision_strategy(diagram, Z, S_probabilities)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Decision in DP â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 6-9 patents    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of DP, CT  â”‚ Decision in DA     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 6-9 patents, low    â”‚ 10-15 applications â”‚\nâ”‚ 6-9 patents, medium â”‚ 10-15 applications â”‚\nâ”‚ 6-9 patents, high   â”‚ 10-15 applications â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We use a custom path utility function to obtain the utility distribution.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"struct PathUtility <: AbstractPathUtility\n    data::Array{AffExpr}\nend\nBase.getindex(U::PathUtility, i::State) = getindex(U.data, i)\nBase.getindex(U::PathUtility, I::Vararg{State,N}) where N = getindex(U.data, I...)\n(U::PathUtility)(s::Path) = value.(U[s...])\n\npath_utility = [@expression(model,\n    sum(x_A[s[diagram.Nodes[\"DP\"].index], s[diagram.Nodes[\"CT\"].index], s[diagram.Nodes[\"DA\"].index], a] * (V_A[s[diagram.Nodes[\"CM\"].index], a] - I_a[a]) for a in 1:n_A) -\n    sum(x_T[s[diagram.Nodes[\"DP\"].index], t] * I_t[t] for t in 1:n_T)) for s in paths(get_values(diagram.S))]\ndiagram.U = PathUtility(path_utility)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"U_distribution = UtilityDistribution(diagram, Z)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_utility_distribution(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Utility â”‚ Probability â”‚\nâ”‚   Float64 â”‚     Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ -2.338179 â”‚    0.152778 â”‚\nâ”‚ -0.130143 â”‚    0.291667 â”‚\nâ”‚  2.650091 â”‚    0.555556 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_statistics(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Name â”‚ Statistics â”‚\nâ”‚   String â”‚    Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     Mean â”‚   1.077093 â”‚\nâ”‚      Std â”‚   1.892543 â”‚\nâ”‚ Skewness â”‚  -0.654557 â”‚\nâ”‚ Kurtosis â”‚  -1.066341 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/contingent-portfolio-programming/#References","page":"Contingent Portfolio Programming","title":"References","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1â€“35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#analyzing-decision-strategies","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/#Introduction","page":"Analyzing Decision Strategies","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"This section focuses on how we can analyze fixed decision strategies Z on an influence diagram G, such as ones obtained by solving the Decision Programming model described in the previous section. We can rule out all incompatible and inactive paths from the analysis because they do not influence the outcomes of the strategy. This means that we only consider paths ğ¬ that are compatible and active ğ¬ in ğ’(X) cap ğ’(Z).","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Generating-Compatible-Paths","page":"Analyzing Decision Strategies","title":"Generating Compatible Paths","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generate compatible paths ğ¬ğ’(Z) as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Initialize path ğ¬ of length n with undefined values.\nFill path with chance states s_jS_j for all jC\nIn increasing order of decision nodes jD, fill decision states by computing decision strategy s_j=Z_j(ğ¬_I(j))","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Utility-Distribution","page":"Analyzing Decision Strategies","title":"Utility Distribution","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We define unique path utility values as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"mathcalU^=mathcalU(ğ¬)ğ¬ğ’(Z)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability mass function of the utility distribution associates each unique path utility to a probability as follows","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"â„™(X=u)=_ğ¬ğ’(Z)mathcalU(ğ¬)=u p(ğ¬)quad umathcalU^","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"From the utility distribution, we can calculate the cumulative distribution, statistics, and risk measures. The relevant statistics are expected value, standard deviation, skewness and kurtosis. Risk measures focus on the conditional value-at-risk (CVaR), also known as expected shortfall.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Measuring-Risk","page":"Analyzing Decision Strategies","title":"Measuring Risk","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"(Image: )","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We have a discrete probability distribution f(x)=â„™(X=x)0 1 over the domain xÎ© with _xÎ©â„™(X=x)=1 and its cumulative distribution function F(x) = _x^Î©x^xf(x^) We define the expected value as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"E(X)=_xÎ© x  f(x)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We present the concept of conditional value-at-risk, a risk measure of the conditional expected value of the tail of a probability distribution for a given probability level of Î±0 1 First, we define the value-at-risk as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_Î±(X) = x_Î± = minxÎ©  F(x)  Î±","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"It is the smallest value x such that the cumulative probability is equal or above Î± Then, we define the conditional value-at-risk as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameCVaR_Î±(X)=textcolordarkorangefrac1Î± left(textcolordarkred_xx_Î± x  f(x) textcolordarkblue- left(_xx_Î± f(x) - Î±right) x_Î± right)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The red part measures the conditional expected value of the tail distribution. The blue part corrects the expected value by subtracting the amount of expected value that is between probability level Î± and F(x_Î±) and orange part divides by the total probability.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Value-at-risk and conditional value-at-risk are monotonically increasing functions. Therefore, the lower bound is the value at Î±=0 and the upper bound is the value at Î±=1 For value-at-risk, we have","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_0(X) = min xÎ©","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_1(X) = max xÎ©","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"For conditional value-at-risk, we have","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"lim_Î±0 operatornameCVaR_Î±(X) = operatornameVaR_0(X)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameCVaR_1(X) = E(X)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The above figure demonstrates these values on a discrete probability distribution.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#State-Probabilities","page":"Analyzing Decision Strategies","title":"State Probabilities","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We use a recursive definition where Ïµ denotes an empty state to denote paths with fixed states.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"beginaligned\nğ’_Ïµ = ğ’(Z) \nğ’_Ïµs_i = ğ¬ğ’_Ïµ  ğ¬_i=s_i \nğ’_Ïµs_is_j = ğ¬ğ’_Ïµs_i  ğ¬_j=s_jquad ji\nendaligned","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability of all paths sums to one","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"â„™(Ïµ) = sum_ğ¬ğ’_Ïµ p(ğ¬) = 1","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"State probabilities for each node iCD and state s_iS_i denote how likely the state occurs given all path probabilities","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"â„™(s_iÏµ) = sum_ğ¬ğ’_Ïµs_i fracp(ğ¬)â„™(Ïµ) = sum_ğ¬ğ’_Ïµs_i p(ğ¬)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"An active state is a state with positive state probability â„™(s_ic)0 given conditions c","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generalize the state probabilities as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state s_i and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"â„™(s_jÏµs_i) = sum_ğ¬ğ’_Ïµs_is_j fracp(ğ¬)â„™(s_iÏµ)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can then repeat this process by choosing an active state from the new conditional state probabilities s_k that is different from previously chosen states kj","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DecisionProgramming.jl API reference.","category":"page"},{"location":"api/#influence_diagram.jl","page":"API Reference","title":"influence_diagram.jl","text":"","category":"section"},{"location":"api/#Nodes","page":"API Reference","title":"Nodes","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Node\nName\nAbstractNode\nChanceNode\nDecisionNode\nValueNode\nState\nStates","category":"page"},{"location":"api/#DecisionProgramming.Node","page":"API Reference","title":"DecisionProgramming.Node","text":"Node = Int16\n\nPrimitive type for node index. Alias for Int16.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.Name","page":"API Reference","title":"DecisionProgramming.Name","text":"Name = String\n\nPrimitive type for node names. Alias for String.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.AbstractNode","page":"API Reference","title":"DecisionProgramming.AbstractNode","text":"abstract type AbstractNode end\n\nNode type for directed, acyclic graph.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ChanceNode","page":"API Reference","title":"DecisionProgramming.ChanceNode","text":"struct ChanceNode <: AbstractNode\n\nA struct for chance nodes, includes the name, information set, states and index of the node\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionNode","page":"API Reference","title":"DecisionProgramming.DecisionNode","text":"struct DecisionNode <: AbstractNode\n\nA struct for decision nodes, includes the name, information set, states and index of the node\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ValueNode","page":"API Reference","title":"DecisionProgramming.ValueNode","text":"struct ValueNode <: AbstractNode\n\nA struct for value nodes, includes the name, information set and index of the node\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.State","page":"API Reference","title":"DecisionProgramming.State","text":"const State = Int16\n\nPrimitive type for the number of states. Alias for Int16.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States","page":"API Reference","title":"DecisionProgramming.States","text":"struct States <: AbstractArray{State, 1}\n\nStates type. Works like Vector{State}.\n\nExamples\n\njulia> S = States(State.([2, 3, 2, 4]))\n4-element States:\n 2\n 3\n 2\n 4\n\n\n\n\n\n","category":"type"},{"location":"api/#Paths","page":"API Reference","title":"Paths","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Path\nForbiddenPath\nFixedPath\npaths(::AbstractVector{State})\npaths(::AbstractVector{State}, ::FixedPath)","category":"page"},{"location":"api/#DecisionProgramming.Path","page":"API Reference","title":"DecisionProgramming.Path","text":"const Path{N} = NTuple{N, State} where N\n\nPath type. Alias for NTuple{N, State} where N.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ForbiddenPath","page":"API Reference","title":"DecisionProgramming.ForbiddenPath","text":"const ForbiddenPath = Tuple{Vector{Node}, Set{Path}}\n\nForbiddenPath type.\n\nExamples\n\njulia> ForbiddenPath(([1, 2], Set([(1, 2)])))\n(Int16[1, 2], Set(Tuple{Vararg{Int16,N}} where N[(1, 2)])\n\njulia> ForbiddenPath[\n    ([1, 2], Set([(1, 2)])),\n    ([3, 4, 5], Set([(1, 2, 3), (3, 4, 5)]))\n]\n2-element Array{Tuple{Array{Int16,1},Set{Tuple{Vararg{Int16,N}} where N}},1}:\n ([1, 2], Set([(1, 2)]))\n ([3, 4, 5], Set([(1, 2, 3), (3, 4, 5)]))\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.FixedPath","page":"API Reference","title":"DecisionProgramming.FixedPath","text":"const FixedPath = Dict{Node, State}\n\nFixedPath type.\n\nExamples\n\njulia> FixedPath(Dict(1=>1, 2=>3))\nDict{Int16,Int16} with 2 entries:\n  2 => 3\n  1 => 1\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.paths-Tuple{AbstractVector{Int16}}","page":"API Reference","title":"DecisionProgramming.paths","text":"function paths(states::AbstractVector{State})\n\nIterate over paths in lexicographical order.\n\nExamples\n\njulia> states = States(State.([2, 3]))\n2-element States:\n 2\n 3\n\njulia> vec(collect(paths(states)))\n6-element Array{Tuple{Int16,Int16},1}:\n (1, 1)\n (2, 1)\n (1, 2)\n (2, 2)\n (1, 3)\n (2, 3)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.paths-Tuple{AbstractVector{Int16}, Dict{Int16, Int16}}","page":"API Reference","title":"DecisionProgramming.paths","text":"function paths(states::AbstractVector{State}, fixed::FixedPath)\n\nIterate over paths with fixed states in lexicographical order.\n\nExamples\n\njulia> states = States(State.([2, 3]))\n2-element States:\n 2\n 3\n\njulia> vec(collect(paths(states, Dict(Node(1) => State(2)))))\n3-element Array{Tuple{Int16,Int16},1}:\n (2, 1)\n (2, 2)\n (2, 3)\n\n\n\n\n\n","category":"method"},{"location":"api/#Probabilities","page":"API Reference","title":"Probabilities","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Probabilities","category":"page"},{"location":"api/#DecisionProgramming.Probabilities","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"struct Probabilities{N} <: AbstractArray{Float64, N}\n\nConstruct and validate stage probabilities (probabilities for a single node).\n\nExamples\n\njulia> data = [0.5 0.5 ; 0.2 0.8]\n2Ã—2 Array{Float64,2}:\n 0.5  0.5\n 0.2  0.8\n\njulia> X = Probabilities(Node(2), data)\n2Ã—2 Probabilities{2}:\n 0.5  0.5\n 0.2  0.8\n\njulia> s = (1, 2)\n(1, 2)\n\njulia> X(s)\n0.5\n\n\n\n\n\n","category":"type"},{"location":"api/#Path-Probability","page":"API Reference","title":"Path Probability","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathProbability\nDefaultPathProbability","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathProbability","page":"API Reference","title":"DecisionProgramming.AbstractPathProbability","text":"abstract type AbstractPathProbability end\n\nAbstract path probability type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathProbability","page":"API Reference","title":"DecisionProgramming.DefaultPathProbability","text":"struct DefaultPathProbability <: AbstractPathProbability\n\nPath probability obtained as a product of the probability values corresponding to path s in each chance node.\n\nExamples\n\njulia> C = [2]\n1-element Array{Int64,1}:\n 2\n\njulia> I_j = [[1]]\n1-element Array{Array{Int64,1},1}:\n [1]\n\njulia> X = [Probabilities(Node(2), [0.5 0.5; 0.2 0.8])]\n1-element Array{Probabilities{2},1}:\n [0.5 0.5; 0.2 0.8]\n\njulia> P = DefaultPathProbability(C, I_j, X)\nDefaultPathProbability(Int16[2], Array{Int16,1}[[1]], Probabilities[[0.5 0.5; 0.2 0.8]])\n\njulia> s = Path((1, 2))\n(1, 2)\n\njulia> P(s)\n0.5\n\n\n\n\n\n","category":"type"},{"location":"api/#Utilities","page":"API Reference","title":"Utilities","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Utility\nUtilities","category":"page"},{"location":"api/#DecisionProgramming.Utility","page":"API Reference","title":"DecisionProgramming.Utility","text":"const Utility = Float32\n\nPrimitive type for utility. Alias for Float32.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.Utilities","page":"API Reference","title":"DecisionProgramming.Utilities","text":"struct Utilities{N} <: AbstractArray{Utility, N}\n\nState utilities.\n\nExamples\n\njulia> vals = Utility.([1.0 -2.0; 3.0 4.0])\n2Ã—2 Array{Float32,2}:\n 1.0  -2.0\n 3.0   4.0\n\njulia> Y = Utilities(Node(3), vals)\n2Ã—2 Utilities{2}:\n 1.0  -2.0\n 3.0   4.0\n\njulia> s = Path((1, 2))\n (1, 2)\n\njulia> Y(s)\n-2.0f0\n\n\n\n\n\n","category":"type"},{"location":"api/#Path-Utility","page":"API Reference","title":"Path Utility","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathUtility\nDefaultPathUtility","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathUtility","page":"API Reference","title":"DecisionProgramming.AbstractPathUtility","text":"abstract type AbstractPathUtility end\n\nAbstract path utility type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathUtility","page":"API Reference","title":"DecisionProgramming.DefaultPathUtility","text":"struct DefaultPathUtility <: AbstractPathUtility\n\nDefault path utility obtained as a sum of the utility values corresponding to path s in each value node.\n\nExamples\n\njulia> vals = Utility.([1.0 -2.0; 3.0 4.0])\n2Ã—2 Array{Float32,2}:\n 1.0  -2.0\n 3.0   4.0\n\njulia> Y = [Utilities(Node(3), vals)]\n1-element Array{Utilities{2},1}:\n [1.0 -2.0; 3.0 4.0]\n\njulia> I_3 = [[1,2]]\n1-element Array{Array{Int64,1},1}:\n [1, 2]\n\njulia> U = DefaultPathUtility(I_3, Y)\nDefaultPathUtility(Array{Int16,1}[[1, 2]], Utilities[[1.0 -2.0; 3.0 4.0]])\n\njulia> s = Path((1, 2))\n(1, 2)\n\njulia> U(s)\n-2.0f0\n\njulia> t = Utility(-100.0)\n\n\njulia> U(s, t)\n-102.0f0\n\n\n\n\n\n","category":"type"},{"location":"api/#InfluenceDiagram","page":"API Reference","title":"InfluenceDiagram","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"InfluenceDiagram\nadd_node!\nProbabilityMatrix\nProbabilityMatrix(::InfluenceDiagram, ::Name)\nadd_probabilities!\nUtilityMatrix\nUtilityMatrix(::InfluenceDiagram, ::Name)\nadd_utilities!\ngenerate_arcs!\ngenerate_diagram!\nindices\nI_j_indices\nindices_in_vector\nget_values\nget_keys\nnum_states","category":"page"},{"location":"api/#DecisionProgramming.InfluenceDiagram","page":"API Reference","title":"DecisionProgramming.InfluenceDiagram","text":"mutable struct InfluenceDiagram\n    Nodes::OrderedDict{Name, AbstractNode}\n    Names::Vector{Name}\n    I_j::OrderedDict{Name, Vector{Name}}\n    States::OrderedDict{Name, Vector{Name}}\n    S::OrderedDict{Name,State}\n\n    C::OrderedDict{Name, ChanceNode}\n    D::OrderedDict{Name, DecisionNode}\n    V::OrderedDict{Name, ValueNode}\n    X::OrderedDict{Name, Probabilities}\n    Y::OrderedDict{Name, Utilities}\n    P::AbstractPathProbability\n    U::AbstractPathUtility\n    translation::Utility\n    function InfluenceDiagram()\n        new(OrderedDict{String, AbstractNode}())\n    end\nend\n\nHold all information related to the influence diagram.\n\nFields\n\nAll OrderedDicts are ordered by vector Names.\n\nNodes::OrderedDict{Name, AbstractNode}: OrderedDict of node names as key\n\nand their respective abstract nodes as values.\n\nNames::Vector{Name}: Names of nodes in order of their indices.\nI_j::OrderedDict{Name, Vector{Name}}: Information sets of nodes by their name.\nStates::OrderedDict{Name, Vector{Name}}: States of each node by their name.\nS::OrderedDict{Name,State}: Number of states of each node.\nC::OrderedDict{Name, ChanceNode}: Chance nodes by their name.\nD::OrderedDict{Name, DecisionNode}: Decision nodes by their name.\nV::OrderedDict{Name, ValueNode}: Values nodes by their name.\nX::OrderedDict{Name, Probabilities}: Probability matrices of chance nodes by their name.\nY::OrderedDict{Name, Utilities}: Utility matrices of value nodes by their name.\nP::AbstractPathProbability: Path probabilities.\nU::AbstractPathUtility: Path utilities.\ntranslation::Utility: Utility translation for storing the positive or negative   utility translation.\n\nExamples\n\ndiagram = InfluenceDiagram()\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.add_node!","page":"API Reference","title":"DecisionProgramming.add_node!","text":"function add_node!(diagram::InfluenceDiagram, node::AbstractNode)\n\nAdd node to influence diagram structure.\n\nExamples\n\njulia> add_node!(diagram, ChanceNode(\"O\", [], [\"lemon\", \"peach\"]))\n1-element Array{AbstractNode,1}:\n ChanceNode(\"O\", String[], [\"lemon\", \"peach\"])\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.ProbabilityMatrix","page":"API Reference","title":"DecisionProgramming.ProbabilityMatrix","text":"struct ProbabilityMatrix{N} <: AbstractArray{Float64, N}\n    nodes::Vector{Name}\n    indices::Vector{Dict{Name, Int}}\n    matrix::Array{Float64, N}\nend\n\nConstruct probability matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ProbabilityMatrix-Tuple{InfluenceDiagram, String}","page":"API Reference","title":"DecisionProgramming.ProbabilityMatrix","text":"function ProbabilityMatrix(diagram::InfluenceDiagram, node::Name)\n\nInitialise a probability matrix for a given chance node. The matrix is initialised with zeros.\n\nExamples\n\njulia> X_O = ProbabilityMatrix(diagram, \"O\")\n2-element ProbabilityMatrix{1}:\n 0.0\n 0.0\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.add_probabilities!","page":"API Reference","title":"DecisionProgramming.add_probabilities!","text":"function add_probabilities!(diagram::InfluenceDiagram, node::Name, probabilities::AbstractArray{Float64, N}) where N\n\nAdd probability matrix to influence diagram, specifically to its X vector.\n\nExamples\n\njulia> X_O = ProbabilityMatrix(diagram, \"O\")\n2-element ProbabilityMatrix{1}:\n 0.0\n 0.0\n\njulia> X_O[\"lemon\"] = 0.2\n0.2\n\njulia> add_probabilities!(diagram, \"O\", X_O)\nERROR: DomainError with Probabilities should sum to one.:\n\njulia> X_O[\"peach\"] = 0.8\n0.2\n\njulia> add_probabilities!(diagram, \"O\", X_O)\n1-element Array{Probabilities,1}:\n [0.2, 0.8]\n\nnote: Note\nThe function generate_arcs! must be called before probabilities or utilities can be added to the influence diagram.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.UtilityMatrix","page":"API Reference","title":"DecisionProgramming.UtilityMatrix","text":"struct UtilityMatrix{N} <: AbstractArray{Utility, N}\n    I_v::Vector{Name}\n    indices::Vector{Dict{Name, Int}}\n    matrix::Array{Utility, N}\nend\n\nConstruct utility matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityMatrix-Tuple{InfluenceDiagram, String}","page":"API Reference","title":"DecisionProgramming.UtilityMatrix","text":"function UtilityMatrix(diagram::InfluenceDiagram, node::Name)\n\nInitialise a utility matrix for a value node. The matrix is initialised with Inf values.\n\nExamples\n\njulia> Y_V3 = UtilityMatrix(diagram, \"V3\")\n2Ã—3 UtilityMatrix{2}:\n Inf  Inf  Inf\n Inf  Inf  Inf\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.add_utilities!","page":"API Reference","title":"DecisionProgramming.add_utilities!","text":"function add_utilities!(diagram::InfluenceDiagram, node::Name, utilities::AbstractArray{T, N}) where {N,T<:Real}\n\nAdd utility matrix to influence diagram, specifically to its Y vector.\n\nExamples\n\njulia> Y_V3 = UtilityMatrix(diagram, \"V3\")\n2Ã—3 UtilityMatrix{2}:\n Inf  Inf  Inf\n Inf  Inf  Inf\n\njulia> Y_V3[\"peach\", :] = [-40, -20, 0]\n3-element Array{Int64,1}:\n -40\n -20\n   0\n\njulia> Y_V3[\"lemon\", :] = [-200, 0, 0]\n3-element Array{Int64,1}:\n -200\n    0\n    0\n\njulia> add_utilities!(diagram, \"V3\", Y_V3)\n1-element Array{Utilities,1}:\n [-200.0 0.0 0.0; -40.0 -20.0 0.0]\n\njulia> add_utilities!(diagram, \"V1\", [0, -25])\n2-element Array{Utilities,1}:\n [-200.0 0.0 0.0; -40.0 -20.0 0.0]\n [0.0, -25.0]\n\nnote: Note\nThe function generate_arcs! must be called before probabilities or utilities can be added to the influence diagram.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.generate_arcs!","page":"API Reference","title":"DecisionProgramming.generate_arcs!","text":"function generate_arcs!(diagram::InfluenceDiagram)\n\nGenerate arc structures using nodes added to influence diagram and storing them to variable diagram.I_j. Also creating variables diagram.States, diagram.S, diagram.C, diagram.D and diagram.V and storing appropriate values to them.\n\nExamples\n\ngenerate_arcs!(diagram)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.generate_diagram!","page":"API Reference","title":"DecisionProgramming.generate_diagram!","text":"function generate_diagram!(diagram::InfluenceDiagram;\ndefault_probability::Bool=true,\ndefault_utility::Bool=true,\npositive_path_utility::Bool=false,\nnegative_path_utility::Bool=false)\n\nGenerate complete influence diagram with probabilities and utilities included.\n\nArguments\n\ndefault_probability::Bool=true: Choice to use default path probabilities.\ndefault_utility::Bool=true: Choice to use default path utilities.\npositive_path_utility::Bool=false: Choice to use a positive path utility translation.\nnegative_path_utility::Bool=false: Choice to use a negative path utility translation.\n\nExamples\n\ngenerate_diagram!(diagram)\n\nnote: Note\nThe influence diagram must be generated after probabilities and utilities are added but before creating the decision model.\n\nnote: Note\nIf the default probabilities and utilities are not used, define AbstractPathProbability and AbstractPathUtility structures and define P(s), U(s) and U(s, t) functions for them. Add the AbstractPathProbability and AbstractPathUtility structures to the influence diagram fields P and U.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.indices","page":"API Reference","title":"DecisionProgramming.indices","text":"function indices(dict)\n\nGet the indices of nodes in values of a Dict or OrderedDict.\n\nExample\n\njulia> D_indices = indices(diagram.D)\n3-element Vector{Int16}:\n 3\n 6\n 9\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.I_j_indices","page":"API Reference","title":"DecisionProgramming.I_j_indices","text":"function I_j_indices(diagram::InfluenceDiagram, dict)\n\nGet the indices of information sets of nodes in values of a Dict or OrderedDict. Returns Vector{Vector{Node}}.\n\nExample\n\njulia> C_I_j_indices = I_j_indices(diagram, diagram.C)\n7-element Vector{Vector{Int16}}:\n []\n [1]\n [1, 3]\n [4]\n [4, 6]\n [7]\n [7, 9]\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.indices_in_vector","page":"API Reference","title":"DecisionProgramming.indices_in_vector","text":"function indices_in_vector(diagram::InfluenceDiagram, nodes::AbstractArray)\n\nGet the indices of an array of nodes and store them in an array.\n\nExample\n\njulia> idcs_T1_H2 = indices_of(diagram, [\"T1\", \"H2\"])\n2-element Vector{Int16}:\n 2\n 4\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.get_values","page":"API Reference","title":"DecisionProgramming.get_values","text":"function get_values(dict::OrderedDict)\n\nGeneric function to get values from an OrderedDict.\n\nExample\n\njulia> D_nodes = get_values(diagram.D)\n3-element Vector{DecisionNode}:\n DecisionNode(\"D1\", [\"T1\"], [\"treat\", \"pass\"], 3)\n DecisionNode(\"D2\", [\"T2\"], [\"treat\", \"pass\"], 6)\n DecisionNode(\"D3\", [\"T3\"], [\"treat\", \"pass\"], 9)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.get_keys","page":"API Reference","title":"DecisionProgramming.get_keys","text":"function get_keys(dict::OrderedDict)\n\nGeneric function to get keys from an OrderedDict.\n\nExample\n\njulia> D_values = get_keys(diagram.D)\n3-element Vector{String}:\n \"D1\"\n \"D2\"\n \"D3\"\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.num_states","page":"API Reference","title":"DecisionProgramming.num_states","text":"function num_states(diagram::InfluenceDiagram, name::Name)\n\nGet the number of states in a given node.\n\nExample\n\njulia> NS_O = num_states(diagram, \"O\")\n2\n\n\n\n\n\n","category":"function"},{"location":"api/#ForbiddenPath-and-FixedPath-outer-construction-functions","page":"API Reference","title":"ForbiddenPath and FixedPath outer construction functions","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"ForbiddenPath(::InfluenceDiagram, ::Vector{Name}, ::Vector{NTuple{N, Name}}) where N FixedPath(::InfluenceDiagram, ::Dict{Name, Name})","category":"page"},{"location":"api/#Decision-Strategy","page":"API Reference","title":"Decision Strategy","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"LocalDecisionStrategy\nLocalDecisionStrategy(::AbstractRNG, ::InfluenceDiagram, ::Name)\nDecisionStrategy","category":"page"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"LocalDecisionStrategy{N} <: AbstractArray{Int, N}\n\nLocal decision strategy type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{AbstractRNG, InfluenceDiagram, String}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"function LocalDecisionStrategy(rng::AbstractRNG, diagram::InfluenceDiagram, d::Node)\n\nGenerate random decision strategy for decision node d.\n\nExamples\n\nrng = MersenneTwister(3)\ndiagram = InfluenceDiagram()\nrandom_diagram!(rng, diagram, 5, 2, 3, 2, 2, rand(rng, [2,3], 5))\nLocalDecisionStrategy(rng, diagram, diagram.D[1])\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.DecisionStrategy","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"DecisionStrategy\n\nDecision strategy type.\n\n\n\n\n\n","category":"type"},{"location":"api/#decision_model.jl","page":"API Reference","title":"decision_model.jl","text":"","category":"section"},{"location":"api/#Decision-Model","page":"API Reference","title":"Decision Model","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DecisionVariables\nPathCompatibilityVariables\nlazy_probability_cut","category":"page"},{"location":"api/#DecisionProgramming.DecisionVariables","page":"API Reference","title":"DecisionProgramming.DecisionVariables","text":"DecisionVariables(model::Model,  diagram::InfluenceDiagram; names::Bool=true)\n\nCreate decision variables and constraints.\n\nArguments\n\nmodel::Model: JuMP model into which variables are added.\ndiagram::InfluenceDiagram: Influence diagram structure.\nnames::Bool: Use names or have JuMP variables be anonymous.\n\nExamples\n\nz = DecisionVariables(model, diagram)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.PathCompatibilityVariables","page":"API Reference","title":"DecisionProgramming.PathCompatibilityVariables","text":"PathCompatibilityVariables(model::Model,\n    diagram::InfluenceDiagram,\n    z::OrderedDict{Name, DecisionVariable};\n    names::Bool=false,\n    name::String=\"x\",\n    forbidden_paths::Vector{ForbiddenPath}=ForbiddenPath[],\n    fixed::FixedPath=Dict{Node, State}(),\n    probability_cut::Bool=true,\n    probability_scale_factor::Float64=1.0)\n\nCreate path compatibility variables and constraints.\n\nArguments\n\nmodel::Model: JuMP model into which variables are added.\ndiagram::InfluenceDiagram: Influence diagram structure.\nz::OrderedDict{Name, DecisionVariable}: Ordered dictionary of decision variables.\nnames::Bool: Use names or have JuMP variables be anonymous.\nname::String: Prefix for predefined decision variable naming convention.\nforbidden_paths::Vector{ForbiddenPath}: The forbidden subpath structures.   Path compatibility variables will not be generated for paths that include   forbidden subpaths.\nfixed::FixedPath: Path compatibility variable will not be generated   for paths which do not include these fixed subpaths.\nprobability_cut Includes probability cut constraint in the optimisation model.\nprobability_scale_factor::Float64: Adjusts conditional value at risk model to  be compatible with the expected value expression if the probabilities were scaled there.\n\nExamples\n\nx_s = PathCompatibilityVariables(model, diagram, z; probability_cut = false)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.lazy_probability_cut","page":"API Reference","title":"DecisionProgramming.lazy_probability_cut","text":"lazy_probability_cut(model::Model, diagram::InfluenceDiagram, x_s::PathCompatibilityVariables)\n\nAdd a probability cut to the model as a lazy constraint.\n\nExamples\n\nlazy_probability_cut(model, diagram, x_s)\n\nnote: Note\nRemember to set lazy constraints on in the solver parameters, unless your solver does this automatically. Note that Gurobi does this automatically.\n\n\n\n\n\n","category":"function"},{"location":"api/#Objective-Functions","page":"API Reference","title":"Objective Functions","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"expected_value(::Model, ::InfluenceDiagram, ::PathCompatibilityVariables)\nconditional_value_at_risk(::Model, ::InfluenceDiagram, ::PathCompatibilityVariables{N}, ::Float64; ::Float64) where N","category":"page"},{"location":"api/#DecisionProgramming.expected_value-Tuple{Model, InfluenceDiagram, PathCompatibilityVariables}","page":"API Reference","title":"DecisionProgramming.expected_value","text":"expected_value(model::Model,\n    diagram::InfluenceDiagram,\n    x_s::PathCompatibilityVariables)\n\nCreate an expected value objective.\n\nArguments\n\nmodel::Model: JuMP model into which variables are added.\ndiagram::InfluenceDiagram: Influence diagram structure.\nx_s::PathCompatibilityVariables: Path compatibility variables.\n\nExamples\n\nEV = expected_value(model, diagram, x_s)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Union{Tuple{N}, Tuple{Model, InfluenceDiagram, PathCompatibilityVariables{N}, Float64}} where N","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"conditional_value_at_risk(model::Model,\n    diagram,\n    x_s::PathCompatibilityVariables{N},\n    Î±::Float64;\n    probability_scale_factor::Float64=1.0) where N\n\nCreate a conditional value-at-risk (CVaR) objective.\n\nArguments\n\nmodel::Model: JuMP model into which variables are added.\ndiagram::InfluenceDiagram: Influence diagram structure.\nx_s::PathCompatibilityVariables: Path compatibility variables.\nÎ±::Float64: Probability level at which conditional value-at-risk is optimised.\nprobability_scale_factor::Float64: Adjusts conditional value at risk model to  be compatible with the expected value expression if the probabilities were scaled there.\n\nExamples\n\nÎ± = 0.05  # Parameter such that 0 â‰¤ Î± â‰¤ 1\nCVaR = conditional_value_at_risk(model, x_s, U, P, Î±)\nCVaR = conditional_value_at_risk(model, x_s, U, P, Î±; probability_scale_factor = 10.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#Decision-Strategy-from-Variables","page":"API Reference","title":"Decision Strategy from Variables","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"LocalDecisionStrategy(::Node, ::Vector{VariableRef})\nDecisionStrategy(::InfluenceDiagram, ::OrderedDict{Name, DecisionProgramming.DecisionVariable})","category":"page"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{Int16, Vector{VariableRef}}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"LocalDecisionStrategy(d::Node, z::Array{VariableRef})\n\nConstruct decision strategy from variable refs.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.DecisionStrategy-Tuple{InfluenceDiagram, OrderedDict{String, DecisionProgramming.DecisionVariable}}","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"DecisionStrategy(diagram::InfluenceDiagram, z::OrderedDict{Name, DecisionVariable})\n\nExtract values for decision variables from solved decision model.\n\nExamples\n\nZ = DecisionStrategy(diagram, z)\n\n\n\n\n\n","category":"method"},{"location":"api/#heuristics.jl","page":"API Reference","title":"heuristics.jl","text":"","category":"section"},{"location":"api/#Single-policy-update","page":"API Reference","title":"Single policy update","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"randomStrategy\nsinglePolicyUpdate","category":"page"},{"location":"api/#DecisionProgramming.randomStrategy","page":"API Reference","title":"DecisionProgramming.randomStrategy","text":"randomStrategy(diagram::InfluenceDiagram)\n\nGenerates a random decision strategy for the problem. Returns the strategy as well as  the expected utility of the strategy and the paths that are compatible with the strategy.\n\nArguments\n\ndiagram::InfluenceDiagram: Influence diagram structure.\n\nwarning: Warning\nThis function does not exclude forbidden paths: the strategy returned by this function might be forbidden if the diagram has forbidden state combinations.\n\nExamples\n\nobjval, Z, S_active = randomStrategy(diagram)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.singlePolicyUpdate","page":"API Reference","title":"DecisionProgramming.singlePolicyUpdate","text":"singlePolicyUpdate(diagram::InfluenceDiagram, model::Model, z::OrderedDict{Name, DecisionVariable}, x_s::PathCompatibilityVariables)\n\nFinds a feasible solution using single policy update and sets the model start values to that solution. Returns a vector of tuples consisting of the value of each improved solution starting from a random policy,  time (in milliseconds) since the function call and the decision strategy that gave the improved value. The purpose of all this output is to allow us to examine how fast the method finds good solutions.\n\nArguments\n\ndiagram::InfluenceDiagram: Influence diagram structure.\nmodel::Model: The decision model, modelled in JuMP\nz::DecisionVariables: The decision variables\nx_s::PathCompatibilityVariables: The path compatibility variables\n\nwarning: Warning\nThis function does not exclude forbidden paths: the strategies explored by this function might be forbidden if the diagram has forbidden state combinations.\n\nExamples\n\nsolutionhistory = singlePolicyUpdate(diagram, model, z, x_s)\n\n\n\n\n\n","category":"function"},{"location":"api/#analysis.jl","page":"API Reference","title":"analysis.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"CompatiblePaths\nCompatiblePaths(::InfluenceDiagram, ::DecisionStrategy, ::FixedPath)\nUtilityDistribution\nUtilityDistribution(::InfluenceDiagram, ::DecisionStrategy)\nStateProbabilities\nStateProbabilities(::InfluenceDiagram, ::DecisionStrategy)\nStateProbabilities(::InfluenceDiagram, ::DecisionStrategy, ::Name, ::Name, ::StateProbabilities)\nvalue_at_risk(::UtilityDistribution, ::Float64)\nconditional_value_at_risk(::UtilityDistribution, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.CompatiblePaths","page":"API Reference","title":"DecisionProgramming.CompatiblePaths","text":"struct CompatiblePaths\n    S::States\n    C::Vector{Node}\n    Z::DecisionStrategy\n    fixed::FixedPath\nend\n\nCompatiblePaths type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.CompatiblePaths-Tuple{InfluenceDiagram, DecisionStrategy, Dict{Int16, Int16}}","page":"API Reference","title":"DecisionProgramming.CompatiblePaths","text":"CompatiblePaths(diagram::InfluenceDiagram, Z::DecisionStrategy, fixed::FixedPath=Dict{Node, State}())\n\nCompatiblePaths outer construction function. Interface for iterating over paths that are compatible and active given influence diagram and decision strategy.\n\nInitialize path s of length n\nFill chance states s[C] by generating subpaths paths(C)\nFill decision states s[D] by decision strategy Z and path s\n\nExamples\n\nfor s in CompatiblePaths(diagram, Z)\n    ...\nend\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.UtilityDistribution","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"struct UtilityDistribution\n    u::Vector{Float64}\n    p::Vector{Float64}\nend\n\nUtilityDistribution type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution-Tuple{InfluenceDiagram, DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"UtilityDistribution(diagram::InfluenceDiagram, Z::DecisionStrategy)\n\nConstruct the probability mass function for path utilities on paths that are compatible with given decision strategy.\n\nExamples\n\nUtilityDistribution(diagram, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"struct StateProbabilities\n    probs::Dict{Node, Vector{Float64}}\n    fixed::FixedPath\nend\n\nStateProbabilities type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{InfluenceDiagram, DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"StateProbabilities(diagram::InfluenceDiagram, Z::DecisionStrategy)\n\nAssociate each node with array of probabilities for each of its states occuring in compatible paths.\n\nExamples\n\nStateProbabilities(diagram, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{InfluenceDiagram, DecisionStrategy, String, String, StateProbabilities}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"StateProbabilities(diagram::InfluenceDiagram, Z::DecisionStrategy, node::Name, state::Name, prior_probabilities::StateProbabilities)\n\nAssociate each node with array of conditional probabilities for each of its states occuring in compatible paths given     fixed states and prior probability. Fix node and state using their names.\n\nExamples\n\n# Prior probabilities\nprior_probabilities = StateProbabilities(diagram, Z)\n\n# Select node and fix its state\nnode = \"R\"\nstate = \"no test\"\nStateProbabilities(diagram, Z, node, state, prior_probabilities)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.value_at_risk-Tuple{UtilityDistribution, Float64}","page":"API Reference","title":"DecisionProgramming.value_at_risk","text":"value_at_risk(U_distribution::UtilityDistribution, Î±::Float64)\n\nCalculate value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{UtilityDistribution, Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"conditional_value_at_risk(U_distribution::UtilityDistribution, Î±::Float64)\n\nCalculate conditional value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#printing.jl","page":"API Reference","title":"printing.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"print_decision_strategy\nprint_utility_distribution\nprint_state_probabilities\nprint_statistics\nprint_risk_measures\nprint_node\nprint_diagram\nmermaid","category":"page"},{"location":"api/#DecisionProgramming.print_decision_strategy","page":"API Reference","title":"DecisionProgramming.print_decision_strategy","text":"print_decision_strategy(diagram::InfluenceDiagram, Z::DecisionStrategy, state_probabilities::StateProbabilities; show_incompatible_states::Bool = false)\n\nPrint decision strategy.\n\nArguments\n\ndiagram::InfluenceDiagram: Influence diagram structure.\nZ::DecisionStrategy: Decision strategy structure with optimal decision strategy.\nstate_probabilities::StateProbabilities: State probabilities structure corresponding to optimal decision strategy.\nshow_incompatible_states::Bool: Choice to print rows also for incompatible states.\n\nExamples\n\nprint_decision_strategy(diagram, Z, S_probabilities)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_utility_distribution","page":"API Reference","title":"DecisionProgramming.print_utility_distribution","text":"print_utility_distribution(U_distribution::UtilityDistribution; util_fmt=\"%f\", prob_fmt=\"%f\")\n\nPrint utility distribution.\n\nExamples\n\nU_distribution = UtilityDistribution(diagram, Z)\nprint_utility_distribution(U_distribution)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_state_probabilities","page":"API Reference","title":"DecisionProgramming.print_state_probabilities","text":"print_state_probabilities(diagram::InfluenceDiagram, state_probabilities::StateProbabilities, nodes::Vector{Name}; prob_fmt=\"%f\")\n\nPrint state probabilities with fixed states.\n\nExamples\n\nS_probabilities = StateProbabilities(diagram, Z)\nprint_state_probabilities(S_probabilities, [\"R\"])\nprint_state_probabilities(S_probabilities, [\"A\"])\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_statistics","page":"API Reference","title":"DecisionProgramming.print_statistics","text":"print_statistics(U_distribution::UtilityDistribution; fmt = \"%f\")\n\nPrint statistics about utility distribution.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_risk_measures","page":"API Reference","title":"DecisionProgramming.print_risk_measures","text":"print_risk_measures(U_distribution::UtilityDistribution, Î±s::Vector{Float64}; fmt = \"%f\")\n\nPrint risk measures.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_node","page":"API Reference","title":"DecisionProgramming.print_node","text":"print_node(node_name::String, diagram::InfluenceDiagram; print_tables::Bool=true)\n\nPrint node information. print_tables determines whether probability and utility tables for the node are printed.\n\nExamples\n\n```julia print_node(\"H2\", diagram)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_diagram","page":"API Reference","title":"DecisionProgramming.print_diagram","text":"print_diagram(diagram::InfluenceDiagram; print_tables::Bool=true)\n\nPrint diagram. print_tables determines whether probability and utility values for the nodes in the diagram are printed.\n\nExamples\n\n```julia print_diagram(diagram)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.mermaid","page":"API Reference","title":"DecisionProgramming.mermaid","text":"mermaid(diagram::InfluenceDiagram, filename::String=\"mermaid_graph.png\")\n\nPrint mermaid graph. NOTE TO USER: Accesses the url mermaid.ink, which is used for graphing.\n\n\n\n\n\n","category":"function"},{"location":"decision-programming/decision-model/#decision-model","page":"Decision Model","title":"Decision Model","text":"","category":"section"},{"location":"decision-programming/decision-model/#Introduction","page":"Decision Model","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision Programming aims to find an optimal decision strategy Z among all decision strategies â„¤ by maximizing an objective function f on the path distribution of an influence diagram","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"undersetZâ„¤textmaximizequad f((â„™(X=ğ¬Z) mathcalU(ğ¬))  ğ¬ğ’) tag1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision model refers to the mixed-integer linear programming formulation of this optimization problem. This page explains how to express decision strategies, compatible paths, path utilities and the objective of the model as a mixed-integer linear program. We present two standard objective functions, including expected value and conditional value-at-risk. The original decision model formulation was described in [1], sections 3 and 5. We base the decision model on an improved formulation described in [2] section 3.3. We recommend reading the references for motivation, details, and proofs of the formulation.","category":"page"},{"location":"decision-programming/decision-model/#Decision-Variables","page":"Decision Model","title":"Decision Variables","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision variables z(s_jğ¬_I(j)) are equivalent to local decision strategies such that Z_j(ğ¬_I(j))=s_j if and only if z(s_jğ¬_I(j))=1 and z(s_j^ğ¬_I(j))=0 for all s_j^S_js_j Constraint (2) defines the decisions to be binary variables and the constraint (3) states that only one decision alternative s_j can be chosen for each information set s_I(j).","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"z(s_jğ¬_I(j))  01quad jD s_jS_j ğ¬_I(j)ğ’_I(j) tag2","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_s_jS_j z(s_jğ¬_I(j))=1quad jD ğ¬_I(j)ğ’_I(j) tag3","category":"page"},{"location":"decision-programming/decision-model/#Path-Compatibility-Variables","page":"Decision Model","title":"Path Compatibility Variables","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Path compatibility variables x(ğ¬) are indicator variables for whether path ğ¬ is compatible with decision strategy Z defined by the decision variables z. These are continous variables but only assume binary values, so that the compatible paths ğ¬  ğ’(Z) take values x(ğ¬) = 1 and other paths ğ¬  ğ’ setminus ğ’(Z) take values x(ğ¬) = 0. Constraint (4) defines the lower and upper bounds for the variables.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"0x(ğ¬)1quad ğ¬ğ’ tag4","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Constraint (5) ensures that only the variables associated with locally compatible paths ğ¬ in ğ’_s_j  ğ¬_I(j)  of the decision strategy can take value x(ğ¬) = 1. The effective locally compatible paths are denoted with  ğ’^*_s_j  ğ¬_I(j). The upper bound of the constraint uses the minimum of the feasible paths upper bound and the theoretical upper bound. The motivation of the feasible paths upper bound is below. For proofs and motivation on the theoretical upper bound see reference [2].","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_ğ¬ in ğ’^*_s_j  ğ¬_I(j)  x(ğ¬) leq min (   ğ’^*_s_j  ğ¬_I(j)  frac ğ’_s_j  ğ¬_I(j) displaystyle  prod_d in D setminus j I(j) ğ’_d  )  z(s_jğ¬_I(j))quad forall j in D s_j in S_j ğ¬_I(j) in ğ’_I(j) tag5","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Constraint (6) is called the probability cut constraint and it defines that the sum of the path probabilities of the compatible paths must equal one.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_ğ¬ğ’x(ğ¬) p(ğ¬) = 1 tag6","category":"page"},{"location":"decision-programming/decision-model/#Feasible-paths-upper-bound","page":"Decision Model","title":"Feasible paths upper bound","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The feasible paths upper bound for the path compatibility variables is","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_ğ¬ in ğ’^*_s_j  ğ¬_I(j)  x(ğ¬) leq   ğ’^*_s_j  ğ¬_I(j)  z(s_jğ¬_I(j))quad forall j in D s_j in S_j ğ¬_I(j) in ğ’_I(j)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"where ğ’^*_s_j  s_I(j) is the set of effective locally compatible paths. This upper bound is motivated by the implementation of the framework in which path compatibility variables x(ğ¬) are only generated for effective paths ğ¬ in ğ’^. The ineffective paths are not generated because they do not influence the objective function and having less variables reduces the size of the model.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Therefore, if the model has ineffective paths ğ¬ in ğ’^, then the number of effective paths is less than the number of all paths.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ğ’^*  ğ’","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Therefore,","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ğ’^*_s_j  ğ¬_I(j)    ğ’_s_j  ğ¬_I(j) ","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The feasible paths upper bound is used in conjunction with the theoretical upper bound as follows.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_ğ¬ in ğ’^*_s_j  ğ¬_I(j)  x(ğ¬) leq min (   ğ’^*_s_j  ğ¬_I(j)  frac ğ’_s_j  ğ¬_I(j) displaystyle  prod_d in D setminus j I(j) ğ’_d  )  z(s_jğ¬_I(j))quad forall j in D s_j in S_j ğ¬_I(j) in ğ’_I(j)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The motivation for using the minimum of these bounds is that it depends on the problem structure which one is tighter. The feasible paths upper bound may be tighter if the set of ineffective paths is large compared to the number of all paths.","category":"page"},{"location":"decision-programming/decision-model/#Lazy-Probability-Cut","page":"Decision Model","title":"Lazy Probability Cut","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Constraint (6) is a complicating constraint involving all path compatibility variables x(s) and thus adding it directly to the model may slow down the overall solution process. It may be beneficial to instead add it as a lazy constraint. In the solver, a lazy constraint is only generated when an incumbent solution violates it. In some instances, this allows the MILP solver to prune nodes of the branch-and-bound tree more efficiently.","category":"page"},{"location":"decision-programming/decision-model/#Single-Policy-Update","page":"Decision Model","title":"Single Policy Update","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"To obtain (hopefully good) starting solutions, the SPU heuristic described in [3] can be used. The heuristic finds a locally optimal strategy in the sense that the strategy cannot be improved by changing any single local strategy. With large problems, the heuristic can quickly provide a solution that would otherwise take very long to obtain.","category":"page"},{"location":"decision-programming/decision-model/#Expected-Value","page":"Decision Model","title":"Expected Value","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The expected value objective is defined using the path compatibility variables x(ğ¬) and their associated path probabilities p(ğ¬) and path utilities mathcalU(ğ¬).","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameE(Z) = _ğ¬ğ’ x(ğ¬)  p(ğ¬)  mathcalU(ğ¬) tag7","category":"page"},{"location":"decision-programming/decision-model/#Positive-and-Negative-Path-Utilities","page":"Decision Model","title":"Positive and Negative Path Utilities","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can omit the probability cut defined in constraint (6) from the model if we are maximising expected value of utility and use a positive path utility function mathcalU^+. Similarly, we can use a negative path utility function mathcalU^- when minimizing expected value. These functions are affine transformations of the path utility function mathcalU which translate all utility values to positive/negative values. As an example of a positive path utility function, we can subtract the minimum of the original utility function and then add one as follows.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"mathcalU^+(ğ¬) = mathcalU(ğ¬) - min_ğ¬ğ’ mathcalU(ğ¬) + 1 tag8","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"mathcalU^-(ğ¬) = mathcalU(ğ¬) - max_ğ¬ğ’ mathcalU(ğ¬) - 1 tag9","category":"page"},{"location":"decision-programming/decision-model/#Conditional-Value-at-Risk","page":"Decision Model","title":"Conditional Value-at-Risk","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The section Measuring Risk explains and visualizes the relationships between the formulation of expected value, value-at-risk and conditional value-at-risk for discrete probability distribution.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Given decision strategy Z we define the cumulative distribution of compatible paths' probabilities as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"F_Z(t) = _ğ¬ğ’mathcalU(ğ¬)t x(ğ¬) p(ğ¬)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Given a probability level Î±(0 1 we define the value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_Î±(Z)=u_Î±=sup mathcalU(ğ¬)ğ¬ğ’ F_Z(mathcalU(ğ¬))Î±","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Then, we have the paths that have path utility less than and equal to the value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ğ’_Î±^=ğ¬ğ’mathcalU(ğ¬)u_Î±","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ğ’_Î±^==ğ¬ğ’mathcalU(ğ¬)=u_Î±","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define conditional value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameCVaR_Î±(Z)=frac1Î±left(_ğ¬ğ’_Î±^ x(ğ¬)  p(ğ¬)  mathcalU(ğ¬) + left(Î± - _ğ¬ğ’_Î±^ x(ğ¬)  p(ğ¬) right) u_Î± right)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can form the conditional value-at-risk as an optimization problem. We have the following pre-computed parameters.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Lower and upper bound of the value-at-risk","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_0(Z)=u^-=minmathcalU(ğ¬)ğ¬ğ’ tag11","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_1(Z)=u^+=maxmathcalU(ğ¬)ğ¬ğ’ tag12","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"A \"large number\", specifically the largest difference between path utilities","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"M=u^+-u^- tag13","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"A \"small number\", specifically half of the smallest positive difference between path utilities","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Ïµ=frac12 minmathcalU(ğ¬)-mathcalU(ğ¬^) mid mathcalU(ğ¬)-mathcalU(ğ¬^)  0 ğ¬ ğ¬^ğ’ tag14","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The objective is to minimize the variable Î· whose optimal value is equal to the value-at-risk, that is, operatornameVaR_Î±(Z)=min Î·","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define the constraints as follows:","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Î·-mathcalU(ğ¬)M Î»(ğ¬)quad ğ¬ğ’ tag14","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Î·-mathcalU(ğ¬)(M+Ïµ) Î»(ğ¬) - Mquad ğ¬ğ’ tag15","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Î·-mathcalU(ğ¬)(M+Ïµ) barÎ»(ğ¬) - Ïµquad ğ¬ğ’ tag16","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Î·-mathcalU(ğ¬)M (barÎ»(ğ¬) - 1)quad ğ¬ğ’ tag17","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barÏ(ğ¬)  barÎ»(ğ¬)quad ğ¬ğ’ tag18","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"x(ğ¬)  p(ğ¬) - (1 - Î»(ğ¬))  Ï(ğ¬)  Î»(ğ¬)quad ğ¬ğ’ tag19","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Ï(ğ¬)  barÏ(ğ¬)  x(ğ¬)  p(ğ¬)quad ğ¬ğ’ tag20","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_ğ¬ğ’barÏ(ğ¬) = Î± tag21","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barÎ»(ğ¬) Î»(ğ¬)0 1quad ğ¬ğ’ tag22","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barÏ(ğ¬)Ï(ğ¬)0 1quad ğ¬ğ’ tag23","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Î·u^- u^+ tag24","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can express the conditional value-at-risk objective as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameCVaR_Î±(Z)=frac1Î±_ğ¬ğ’barÏ(ğ¬) mathcalU(ğ¬)tag25","category":"page"},{"location":"decision-programming/decision-model/#Convex-Combination","page":"Decision Model","title":"Convex Combination","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can combine expected value and conditional value-at-risk using a convex combination at a fixed probability level Î±(0 1 as follows","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"w operatornameE(Z) + (1-w) operatornameCVaR_Î±(Z) tag26","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"where the parameter w0 1 expresses the decision maker's risk tolerance.","category":"page"},{"location":"decision-programming/decision-model/#References","page":"Decision Model","title":"References","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2022). Decision programming for mixed-integer multi-stage optimization under uncertainty. European Journal of Operational Research, 299(2), 550-565.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"[2]: HÃ¶lsÃ¤, O. (2020). Decision Programming Framework for Evaluating Testing Costs of Disease-Prone Pigs. Retrieved from http://urn.fi/URN:NBN:fi:aalto-202009295618","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"[3]: Hankimaa, H., Herrala, O., Oliveira, F., Tollander de Balsch, J. (2023). DecisionProgramming.jl â€“ A framework for modelling decision problems using mathematical programming. Retrieved from https://arxiv.org/abs/2307.13299","category":"page"},{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"On this page, we demonstrate common patterns for expressing influence diagrams and creating decision models using DecisionProgramming.jl. We also discuss the abstraction that is created using the influence diagram structure. We can import the package with the using keyword.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using DecisionProgramming","category":"page"},{"location":"usage/#Adding-nodes","page":"Usage","title":"Adding nodes","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Given the above influence diagram, we express it as a Decision Programming model as follows. We create ChanceNode and DecisionNode instances and add them to the influence diagram. Creating a ChanceNode or DecisionNode requires giving it a unique name, its information set and its states. If the node is a root node, the information set is left empty using square brackets. The order in which nodes are added does not matter.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"diagram = InfluenceDiagram()\nadd_node!(diagram, DecisionNode(\"D1\", [], [\"a\", \"b\"]))\nadd_node!(diagram, ChanceNode(\"C2\", [\"D1\", \"C1\"], [\"v\", \"w\"]))\nadd_node!(diagram, ChanceNode(\"C1\", [], [\"x\", \"y\", \"z\"]))","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Value nodes are added by simply giving it a name and its information set. Value nodes do not have states because their purpose is to map their information state to utility values.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"add_node!(diagram, ValueNode(\"V\", [\"C2\"]))","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Once all the nodes are added, we generate the arcs. This orders the nodes and numbers them such that each node's predecessors have smaller numbers than the node itself. In effect, the chance and decision nodes are numbered such that C cup D = 1n, where n = mid Cmid + mid Dmid. The value nodes are numbered V = n+1 N, where N = mid Cmid + mid Dmid + mid V mid. For more details on influence diagrams see page influence diagram.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"generate_arcs!(diagram)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Now the fields Names, I_j, States, S, C, D and V in the influence diagram structure have been properly filled. The Names field holds the names of all nodes in the order of their numbers. From this we can see that node D1 has been numbered 1, node C1 has been numbered 2 and node C2 has been numbered 3. Field I_j holds the information sets of each node. Notice, that the nodes are identified by their numbers. Field States holds the names of the states of each node and field S holds the number of states each node has. Fields C, D and V contain the chance, decision and value nodes respectively.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> diagram.Names\n4-element Array{String,1}:\n \"D1\"\n \"C1\"\n \"C2\"\n \"V\"\n\njulia> diagram.I_j\n4-element Array{Array{Int16,1},1}:\n []\n []\n [1, 2]\n [3]\n\njulia> diagram.States\n3-element Array{Array{String,1},1}:\n [\"a\", \"b\"]\n [\"x\", \"y\", \"z\"]\n [\"v\", \"w\"]\n\njulia> diagram.S\n3-element States:\n 2\n 3\n 2\n\njulia> diagram.C\n2-element Array{Int16,1}:\n 2\n 3\n\njulia> diagram.D\n1-element Array{Int16,1}:\n 1\n\njulia> diagram.V\n1-element Array{Int16,1}:\n 4","category":"page"},{"location":"usage/#Probability-Matrices","page":"Usage","title":"Probability Matrices","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Each chance node needs a probability matrix which describes the probability distribution over its states given an information state. It holds probability values â„™(X_j=s_jX_I(j)=ğ¬_I(j))","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"for all s_j in S_j and ğ¬_I(j) in ğ’_I(j).","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Thus, the probability matrix of a chance node needs to have dimensions that correspond to the number of states of the nodes in its information set and number of state of the node itself.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"For example, the node C1 in the influence diagram above has an empty information set and three states x y, and z. Therefore its probability matrix needs dimensions (3,1). If the probabilities of events x y, and z occuring are 10 30 and 60, then the probability matrix X_C1 should be 01 quad 03 quad 06. The order of the probability values is determined by the order in which the states are given when the node is added. The states are also stored in this order in the States vector.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"In Decision Programming the probability matrix of node C1 can be added in the following way. Note, that probability matrices can only be added after the arcs have been generated.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"# How C1 was added: add_node!(diagram, ChanceNode(\"C1\", [], [\"x\", \"y\", \"z\"]))\nX_C1 = [0.1, 0.3, 0.6]\nadd_probabilities!(diagram, \"C1\", X_C1)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"The add_probabilities! function adds the probability matrix as a Probabilities structure into the influence diagram's X field.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> diagram.X\n1-element Array{Probabilities,1}:\n [0.1, 0.3, 0.6]","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"As another example, we will add the probability matrix of node C2. It has two nodes in its information set: C1 and D1. These nodes have 3 and 2 states, respectively. Node C2 itself has 2 states. Now, the question is: should the dimensions of the probability matrix be (S_C1  S_D1  S_C2) = (3 2 2) or (S_D1  S_C1  S_C2) = (2 3 2)? The answer is that the dimensions should be in ascending order of the nodes' numbers that they correspond to. This is also the order that the information set is in in the field I_j. In this case the influence diagram looks like this:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> diagram.Names\n4-element Array{String,1}:\n \"D1\"\n \"C1\"\n \"C2\"\n \"V\"\n\n julia> diagram.I_j\n4-element Array{Array{Int16,1},1}:\n []\n []\n [1, 2]\n [3]\n\n julia> diagram.S\n3-element States:\n 2\n 3\n 2","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Therefore, the probability matrix of node C2 should have dimensions (S_D1  S_C1  S_C2) = (2 3 2). The probability matrix can be added by declaring the matrix and then filling in the probability values as shown below.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"X_C2 = zeros(2, 3, 2)\nX_C2[1, 1, 1] = ...\nX_C2[1, 1, 2] = ...\nX_C2[1, 1, 2] = ...\nâ‹®\nadd_probabilities!(diagram, \"C2\", X_C2)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"In order to be able to fill in the probability values, it is crucial to understand what the matrix indices represent. The indices represent a subpath in the influence diagram. The states in the path are referred to with their numbers instead of with their names. The states of a node are numbered according to their positions in the vector of states in field States. The order of the states of each node is seen below. From this, we can deduce that for nodes D1, C1, C2 the subpath (1,1,1) corresponds to subpath (a x v) and subpath (1, 3, 2) corresponds to subpath (a z w). Therefore, the probability value at X_C2[1, 3, 2] should be the probability of the scenario (a z w) occuring.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> diagram.States\n3-element Array{Array{String,1},1}:\n [\"a\", \"b\"]\n [\"x\", \"y\", \"z\"]\n [\"v\", \"w\"]","category":"page"},{"location":"usage/#Helper-Syntax","page":"Usage","title":"Helper Syntax","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Figuring out the dimensions of a probability matrix and adding the probability values is difficult. Therefore, we have implemented an easier syntax.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"A probability matrix can be initialised with the correct dimensions using the ProbabilityMatrix function. It initiliases the probability matrix with zeros.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> X_C2 = ProbabilityMatrix(diagram, \"C2\")\n2Ã—3Ã—2 ProbabilityMatrix{3}:\n[:, :, 1] =\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\n[:, :, 2] =\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\njulia> size(X_C2)\n(2, 3, 2)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"A matrix of type ProbabilityMatrix can be filled using the names of the states. The states must however be given in the correct order, according to the order of the nodes in the information set vector I_j. Notice that if we use the Colon (:) to indicate several elements of the matrix, the probability values have to be given in the correct order of the states in States.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> X_C2[\"a\", \"z\", \"w\"] = 0.25\n0.25\n\njulia> X_C2[\"z\", \"a\", \"v\"] = 0.75\nERROR: DomainError with Node D1 does not have a state called z.:\n\njulia> X_C2[\"a\", \"z\", \"v\"] = 0.75\n0.75\n\njulia> X_C2[\"a\", \"x\", :] = [0.3, 0.7]\n2-element Array{Float64,1}:\n 0.3\n 0.7","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"A matrix of type ProbabilityMatrix can also be filled using the matrix indices if that is more convient. The following achieves the same as what was done above.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> X_C2[1, 3, 2] = 0.25\n0.25\n\njulia> X_C2[1, 3, 1] = 0.75\n0.75\n\njulia> X_C2[1, 1, :] = [0.3, 0.7]\n2-element Array{Float64,1}:\n 0.3\n 0.7","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Now, the probability matrix X_C2 is partially filled.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> X_C2\n2Ã—3Ã—2 ProbabilityMatrix{3}:\n[:, :, 1] =\n 0.3  0.0  0.75\n 0.0  0.0  0.0\n\n[:, :, 2] =\n 0.7  0.0  0.25\n 0.0  0.0  0.0","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"The probability matrix can be added to the influence diagram once it has been filled with probability values. The probability matrix of node C2 is added exactly like before, despite X_C2 now being a matrix of type ProbabilityMatrix.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> add_probabilities!(diagram, \"C2\", X_C2)","category":"page"},{"location":"usage/#Utility-Matrices","page":"Usage","title":"Utility Matrices","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Each value node maps its information states to utility values. In Decision Programming the utility values are passed to the influence diagram using utility matrices. Utility matrices are very similar to probability matrices of chance nodes. There are only two important differences. First, the utility matrices hold utility values instead of probabilities, meaning that they do not need to sum to one. Second, since value nodes do not have states, the cardinality of a utility matrix depends only on the number of states of the nodes in the information set.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"As an example, the utility matrix of node V should have dimensions (2,1) because its information set consists of node C2, which has two states. If state v of node C2 yields a utility of -100 and state w yields utility of 400, then the utility matrix of node V can be added in the following way. Note, that utility matrices can only be added after the arcs have been generated.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> Y_V = zeros(2)\n2-element Array{Float64,1}:\n 0.0\n 0.0\n\njulia> Y_V[1] = -100\n-100\n\njulia> Y_V[2] = 400\n400\n\njulia> add_utilities!(diagram, \"V\", Y_V)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"The other option is to add the utility matrix using the UtilityMatrix type. This is very similar to the ProbabilityMatrix type. The UtilityMatrix function initialises the values to Inf. Using the UtilityMatrix type's functionalities, the utility matrix of node V could also be added like shown below. This achieves the exact same result as we did above with the more abstract syntax.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> Y_V = UtilityMatrix(diagram, \"V\")\n2-element UtilityMatrix{1}:\n Inf\n Inf\n\njulia> Y_V[\"w\"] = 400\n400\n\njulia> Y_V[\"v\"] = -100\n-100\n\njulia> add_utilities!(diagram, \"V\", Y_V)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"The add_utilities! function adds the utility matrix as a Utilities structure into the influence diagram's Y field.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"julia> diagram.Y\n1-element Array{Utilities,1}:\n [-100.0, 400.0]","category":"page"},{"location":"usage/#Generating-the-influence-diagram","page":"Usage","title":"Generating the influence diagram","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"The final part of modeling an influence diagram using the Decision Programming package is generating the full influence diagram. This is done using the generate_diagram! function.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"generate_diagram!(diagram)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"In this function, first, the probability and utility matrices in fields X and Y are sorted according to the chance and value nodes' indices.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Second, the path probability and path utility types are declared and added into fields P and U respectively. These types define how the path probability p(ğ¬) and path utility mathcalU(ğ¬) are defined in the model. By default, the function will set them to default path probability and default path utility. See the influence diagram for more information on default path probability and utility.","category":"page"},{"location":"decision-programming/influence-diagram/#influence-diagram","page":"Influence Diagram","title":"Influence Diagram","text":"","category":"section"},{"location":"decision-programming/influence-diagram/#Introduction","page":"Influence Diagram","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Decision programming uses influence diagrams, a generalization of Bayesian networks, to model multi-stage decision problems under uncertainty. This section defines the influence diagrams and discusses their properties. It is based on the definitions in [1], [2], and [3].","category":"page"},{"location":"decision-programming/influence-diagram/#Definition","page":"Influence Diagram","title":"Definition","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the influence diagram as a directed, acyclic graph G=(CDVAS) We describe the nodes N=CDV with CD=1n and n=C+D as follows:","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Chance nodes C1n (circles) represent uncertain events associated with random variables.\nDecision nodes D1n (squares) correspond to decisions among discrete alternatives.\nValue nodes V=n+1n+V (diamonds) represent consequences that result from the realizations of random variables at chance nodes and the decisions made at decision nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The connections between different nodes (arrows) are called arcs a in A. The arcs represent different dependencies between the nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the information set I of node jN as the set of predecessors of j in the graph:","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"I(j)iCD  (ij) in A ij","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Practically, the information set is a collection of arcs in the reverse direction in the graph. Informally, it tells us which node's information is available to the current node. The conditions enforce that the graph is acyclic, and there are no arcs from value nodes to other nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In an influence diagram, each chance and decision node jCD is associates with a finite number of states S_j that we encode using integers S_j=1S_j from one to number of states S_j1 A node j is trivial if it has only one state, S_j=1 We refer to the collection of all states S=S_1S_n as the state space.","category":"page"},{"location":"decision-programming/influence-diagram/#Root-and-Leaf-Nodes","page":"Influence Diagram","title":"Root and Leaf Nodes","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A chance or decision node is a root node if it is not affected by other chance or decision nodes. Formally, node jCD is a root node if I(j)=","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A chance or decision node is a leaf node if it does not affect other chance or decision nodes. Formally, node jCD is a leaf node if jI(i) for all iCD","category":"page"},{"location":"decision-programming/influence-diagram/#Drawing-Nodes-and-Arcs","page":"Influence Diagram","title":"Drawing Nodes and Arcs","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We use a circle to represent chance nodes, a square to represent decision nodes, and a diamond to represent value nodes. The symbol i represents the node's index and symbol S_i the states of the chance or decision node. We use the following colors and styling:","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Chance nodes: Fill color F5F5F5 and line color 666666.\nDecision nodes: Fill color D5E8D4 and line color 82B366\nValue nodes: Fill color FFE6CC and line color D79B00\nLinewidth 2pt and perimeter 2pt (padding around the node).","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We represent directed arcs using arrows from a source node to a target node, colored with the target node's line color. We recommend diagrams.net for drawing graphs.","category":"page"},{"location":"decision-programming/influence-diagram/#Drawing-Layered-Graph","page":"Influence Diagram","title":"Drawing Layered Graph","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We showed the influence diagram as a linear graph in the Definition section. We can also draw a more concise layered graph, which is better at displaying the influence relationship structure â€” only nodes at smaller depth influence nodes at greater depth. Also, root and leaf nodes are visible from the layered form.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the depth of a node jN as follows. Root nodes have a depth of one","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"operatornamedepth(j)=1quad I(j)=","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Other nodes have a depth of one greater than the maximum depth of its predecessors","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"operatornamedepth(j)=max_iI(j) operatornamedepth(i) + 1quad I(j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We can then draw the layered graph by grouping the nodes by their depth, ordering the groups by increasing depth and increasing indices order within each group.","category":"page"},{"location":"decision-programming/influence-diagram/#Paths","page":"Influence Diagram","title":"Paths","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In influence diagrams, paths represent realizations of states for chance and decision nodes. For example, the above tree represents generating all paths with states S_1=12 and S_2=123","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Formally, a path is a sequence of states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ğ¬=(s_1 s_2 s_n)ğ’","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where a state s_iS_i is defined for all chance and decision nodes iCD We denote the set of paths as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ğ’=_jCD S_j=S_1S_2S_n","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define a subpath of ğ¬ with ACD as a subsequence","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ğ¬_A=(ğ¬_iiA)ğ’_A","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We denote the set of subpaths as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ğ’_A=_iA S_i","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the number of paths as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ğ’_A=_iAS_i","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"As mentioned above, each node jN has an information set I(j). A subpath, which is formed by the states of the nodes in the information set, is referred to as an information state  ğ¬_I(j) of node j. The set of these subpaths is called the information states ğ’_I(j) of node jN","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Also note that ğ’=ğ’_CD and ğ’_i=S_i and ğ¬_i=s_i where iCD is an individual node.","category":"page"},{"location":"decision-programming/influence-diagram/#Probabilities","page":"Influence Diagram","title":"Probabilities","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Each chance node is associated with a set of discrete probability distributions over its states. Each of the probability distributions corresponds to one of the node's information states. Formally, for each chance node jC, we denote the probability of state s_j given information state ğ¬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"â„™(X_j=s_jX_I(j)=ğ¬_I(j))0 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"with","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"_s_jS_j â„™(X_j=s_jX_I(j)=ğ¬_I(j)) = 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A chance state with a given information state is considered active if its probability is nonzero","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"â„™(X_j=s_jX_I(j)=ğ¬_I(j))0","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Otherwise, it is inactive.","category":"page"},{"location":"decision-programming/influence-diagram/#Decision-Strategies","page":"Influence Diagram","title":"Decision Strategies","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Each decision strategy models how the decision maker chooses a state s_jS_j given an information state ğ¬_I(j) at decision node jD A decision node can be seen as a special type of chance node, such that the probability of the chosen state given an information state is fixed to one","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"â„™(X_j=s_jX_I(j)=ğ¬_I(j))=1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"By definition, the probabilities for other states are zero.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Formally, for each decision node jD a local decision strategy is a function that maps an information state ğ¬_I(j) to a state s_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z_jğ’_I(j)S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A decision strategy contains one local decision strategy for each decision node","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z=Z_jjD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The set of all decision strategies is denoted with â„¤","category":"page"},{"location":"decision-programming/influence-diagram/#path-probability-doc","page":"Influence Diagram","title":"Path Probability","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The probability distributions at chance and decision nodes define the probability distribution over all paths ğ¬ğ’ which depends on the decision strategy Zâ„¤ We refer to it as the path probability","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"â„™(X=ğ¬Z) = _jCD â„™(X_j=ğ¬_jX_I(j)=ğ¬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We can decompose the path probability into two parts","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"â„™(X=ğ¬Z) = p(ğ¬) q(ğ¬Z)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The first part consists of the probability contributed by the chance nodes. We refer to it as the upper bound of path probability","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"p(ğ¬) = _jC â„™(X_j=ğ¬_jX_I(j)=ğ¬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The second part consists of the probability contributed by the decision nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"q(ğ¬Z) = _jD â„™(X_j=ğ¬_jX_I(j)=ğ¬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Because the probabilities of decision nodes are defined as one or zero depending on the decision strategy, we can simplify the second part to an indicator function","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"q(ğ¬Z)=begincases\n1  x(ğ¬) = 1 \n0  textotherwise\nendcases","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The binary variable x(ğ¬) indicates whether a decision stategy is compatible with the path ğ¬ that is, if each local decision strategy chooses a state on the path. Using the indicator function I() whose value is 1 if the expression inside is true and 0 otherwise, we have","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"x(ğ¬) = prod_jD I(Z_j(ğ¬_I(j))=ğ¬_j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Now the path probability equals the upper bound if the path is compatible with given decision strategy. Otherwise, the path probability is zero. Formally, we have","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"â„™(ğ¬XZ)=\nbegincases\np(ğ¬)  x(ğ¬) = 1 \n0  textotherwise\nendcases","category":"page"},{"location":"decision-programming/influence-diagram/#Consequences","page":"Influence Diagram","title":"Consequences","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each value node jV, we define the consequence given information state ğ¬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Y_jğ’_I(j)â„‚","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where â„‚ is the set of real-valued consequences.","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Utility","page":"Influence Diagram","title":"Path Utility","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function is a function that maps consequences to real-valued utility","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Uâ„‚^Vâ„","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The path utility is defined as the utility function acting on the consequences of value nodes given their information states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(ğ¬) = U(Y_j(ğ¬_I(j))  jV)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The default path utility is the sum of node utilities U_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(ğ¬) = _jV U_j(Y_j(ğ¬_I(j)))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function affects the objectives discussed on the Decision Model page. We can choose the utility function such that the path utility function either returns:","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"a numerical value, which leads to a mixed-integer linear programming (MILP) formulation or\na linear function with real and integer-valued variables, which leads to a mixed-integer quadratic programming (MIQP) formulation.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Different formulations require a solver capable of solving them.","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Distribution","page":"Influence Diagram","title":"Path Distribution","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A path distribution is a pair","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(â„™(X=ğ¬Z) mathcalU(ğ¬))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"that comprises of a path probability function and a path utility function over paths ğ¬ğ’ conditional to the decision strategy Z","category":"page"},{"location":"decision-programming/influence-diagram/#Other-Properties","page":"Influence Diagram","title":"Other Properties","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In this section, we define more properties for influence diagrams.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Discrete influence diagram refers to a countable state space. Otherwise, the influence diagram is continuous. We can discretize continuous influence diagrams using discrete bins.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Two nodes are sequential if there exists a directed path from one node to the other in the influence diagram. Otherwise, the nodes are parallel. Sequential nodes often model a time dimension.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Repeated subdiagram refers to a recurring pattern within an influence diagram. Often, influence diagrams do not have a unique structure, but they consist of a repeated pattern due to the underlying problem's properties.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Limited-memory influence diagram refers to an influence diagram where the no-forgetting assumption does not hold. In practice, this means that the decision maker does not necessarily remember all previous information. For example, the treatment decisions in the Pig Breeding example are made without full information about the treatment history.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Isolated subdiagrams refer to unconnected diagrams within an influence diagram. That is, there are no undirected connections between the diagrams. Therefore, one isolated subdiagram's decisions affect decisions on the other isolated subdiagrams only through the utility function.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A chance or decision node is redundant if it is a leaf node and not in any value node's information set. Formally, if jCD is a leaf node and there does not exist a value node iV such that jI(i), then node j is redundant.","category":"page"},{"location":"decision-programming/influence-diagram/#References","page":"Influence Diagram","title":"References","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1â€“35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[2]: Howard, R. A., & Matheson, J. E. (2005). Influence diagrams. Decision Analysis, 2(3), 127-143. https://doi.org/10.1287/deca.1050.0020","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[3]: Shachter, R. D. (1986). Evaluating influence diagrams. Operations research, 34(6), 871-882. https://doi.org/10.1287/opre.34.6.871","category":"page"},{"location":"#DecisionProgramming.jl","page":"Home","title":"DecisionProgramming.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is a Julia package for solving multi-stage decision problems under uncertainty, modeled using influence diagrams, and leveraging the power of mixed-integer linear programming. The Decision Programming approach to solving multi-stage decision problems under uncertainty consists of the following three steps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the first step, we model the decision problem using an influence diagram with associated probabilities, consequences, and path utility function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the second step, we create a decision model corresponding to the influence diagram using a suitable objective function. We solve the model to obtain an optimal decision strategy. We can create and solve multiple models with different objectives for the same influence diagram to receive various optimal decision strategies.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the third step, we analyze the resulting decision strategies for the influence diagram. In particular, we are interested in the utility distribution and its associated statistics and risk measures.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl provides the necessary functionality for expressing and solving decision problems but does not explain how to design influence diagrams. The rest of this documentation will describe the mathematical and programmatic details, touch on the computational challenges, and provide concrete examples of solving decision problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The examples start with a rather simple and easily approachable Used Car Buyer problem that can be also solved using more conventional methods such as decision trees. The following two examples illustrate the capabilities of the framework in problems where the no-forgetting assumption does not hold and solving the influence diagram with well-established techniques is thus impossible. In the Pig Breeding problem, only the most recent information is available when making each decision, thus breaking the no-forgetting assumption, while in the N-Monitoring problem, the decisions are made in parallel with no communication between the decision makers, also leading to the assumption not working. The Contingent Portfolio Programming example is a more advanced one, demonstrating the versatility of the framework in adding decision variables and constraints. The CHD Preventative Care example showcases the use of probability scaling and forbidding specific decision strategies.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is developed in the Systems Analysis Laboratory at Aalto University by Ahti Salo,  Fabricio Oliveira, Juho Andelmin, Olli Herrala, Jaan Tollander de Balsch and Helmi Hankimaa.","category":"page"},{"location":"examples/used-car-buyer/#Used-Car-Buyer","page":"Used Car Buyer","title":"Used Car Buyer","text":"","category":"section"},{"location":"examples/used-car-buyer/#Description","page":"Used Car Buyer","title":"Description","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To illustrate the basic functionality of Decision Programming, we implement a version of the used car buyer problem in [1]. In this problem, Joe is buying a used car. The car's price is 1000 USD (US dollars), and its value is 1100 USD. Joe's base profit on the car is thus 100 USD. However, Joe knows that the car is a \"lemon\", meaning that it has defects in 6 major systems, with a 20% probability. With the remaining 80% probability, the car is a \"peach\", and it has a defect in only one of the systems.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The repair costs for a peach are only 40 USD, decreasing Joe's profit to 60  USD. However, the costs for a lemon are 200 USD, resulting in a total loss of 100 USD. We can now formulate an influence diagram of Joe's initial problem. We present the influence diagram in the figure below. In an influence diagram, circle nodes such as O are called chance nodes, representing uncertainty. Node O is a chance node representing the state of the car, lemon or peach. Square nodes such as A are decision nodes, representing decisions. Node A represents the decision to buy or not to buy the car. The diamond-shaped value node V denotes the utility calculation in the problem. For Joe, the utility function is the expected monetary value. The arrows or arcs show connections between nodes. The two arcs in this diagram point to the value node, meaning that the monetary value depends on the state of the car and the purchase decision.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-1})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We can easily determine the optimal strategy for this problem. If Joe decides not to buy the car, his profit is zero. If he buys the car, with 20% probability he loses 100 USD and with an 80% probability he profits 60 USD. Therefore, the expected profit for buying the car is 28 USD, which is higher than the zero profit of not buying. Thus, Joe should buy the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We now add two new features to the problem. A stranger approaches Joe and offers to tell Joe whether the car is a lemon or a peach for 25 USD. Additionally, the car dealer offers a guarantee plan which costs 60 USD and covers 50% of the repair costs. Joe notes that this is not a very good deal, and the dealer includes an anti-lemon feature: if the total repair cost exceeds 100 USD, the guarantee will fully cover the repairs.","category":"page"},{"location":"examples/used-car-buyer/#Influence-diagram","page":"Used Car Buyer","title":"Influence diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-2})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We present the new influence diagram above. The decision node T denotes the decision to accept or decline the stranger's offer, and R is the outcome of the test. We introduce new value nodes V_1 and V_2 to represent the testing costs and the base profit from purchasing the car. Additionally, the decision node A now can choose to buy with a guarantee.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We start by defining the influence diagram structure. The nodes, as well as their information sets and states, are defined in the first block. Next, the influence diagram parameters consisting of the probabilities and utilities are defined.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"using JuMP, HiGHS\nusing DecisionProgramming\ndiagram = InfluenceDiagram()","category":"page"},{"location":"examples/used-car-buyer/#Car's-state","page":"Used Car Buyer","title":"Car's state","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The chance node O is defined by its name, its information set I(O) and its states lemon and peach. As seen in the influence diagram, the information set is empty and the node is a root node.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"add_node!(diagram, ChanceNode(\"O\", [], [\"lemon\", \"peach\"]))","category":"page"},{"location":"examples/used-car-buyer/#Stranger's-offer-decision","page":"Used Car Buyer","title":"Stranger's offer decision","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"A decision node is also defined by its name, its information set and its states.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"add_node!(diagram, DecisionNode(\"T\", [], [\"no test\", \"test\"]))","category":"page"},{"location":"examples/used-car-buyer/#Test's-outcome","page":"Used Car Buyer","title":"Test's outcome","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The second chance node R has nodes O and T in its information set, and three states describing the situations of no test being done, and the test declaring the car to be a lemon or a peach.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"add_node!(diagram, ChanceNode(\"R\", [\"O\", \"T\"], [\"no test\", \"lemon\", \"peach\"]))","category":"page"},{"location":"examples/used-car-buyer/#Purchase-decision","page":"Used Car Buyer","title":"Purchase decision","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The purchase decision represented by node A is added as follows.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"add_node!(diagram, DecisionNode(\"A\", [\"R\"], [\"buy without guarantee\", \"buy with guarantee\", \"don't buy\"]))","category":"page"},{"location":"examples/used-car-buyer/#Testing-fee,-base-profit-and-repair-costs","page":"Used Car Buyer","title":"Testing fee, base profit and repair costs","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Value nodes are defined by only their names and information sets because they do not have states. Instead, value nodes map their information states to utility values which will be added later on.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"add_node!(diagram, ValueNode(\"V1\", [\"T\"]))\nadd_node!(diagram, ValueNode(\"V2\", [\"A\"]))\nadd_node!(diagram, ValueNode(\"V3\", [\"O\", \"A\"]))","category":"page"},{"location":"examples/used-car-buyer/#Generate-arcs","page":"Used Car Buyer","title":"Generate arcs","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Now that all of the nodes have been added to our influence diagram we generate the arcs between the nodes. This step automatically orders the nodes, gives them indices and reorganises the information into the appropriate form in the influence diagram structure.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"generate_arcs!(diagram)","category":"page"},{"location":"examples/used-car-buyer/#Probabilities","page":"Used Car Buyer","title":"Probabilities","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We continue by defining probability distributions for each chance node.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Node O is a root node and has two states thus, its probability distribution is simply defined over the two states. We can use the ProbabilityMatrix structure in creating the probability matrix easily without having to worry about the matrix dimensions. We then set the probability values and add the probabililty matrix to the influence diagram.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"X_O = ProbabilityMatrix(diagram, \"O\")\nX_O[\"peach\"] = 0.8\nX_O[\"lemon\"] = 0.2\nadd_probabilities!(diagram, \"O\", X_O)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Node R has two nodes in its information set and three states. The probabilities P(s_j mid s_I(j)) must thus be defined for all combinations of states in O, T and R. We declare the probability distribution over the states of node R for each information state in the following way. More information on defining probability matrices can be found on the usage page.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"X_R = ProbabilityMatrix(diagram, \"R\")\nX_R[\"lemon\", \"no test\", :] = [1,0,0]\nX_R[\"lemon\", \"test\", :] = [0,1,0]\nX_R[\"peach\", \"no test\", :] = [1,0,0]\nX_R[\"peach\", \"test\", :] = [0,0,1]\nadd_probabilities!(diagram, \"R\", X_R)","category":"page"},{"location":"examples/used-car-buyer/#Utilities","page":"Used Car Buyer","title":"Utilities","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We continue by defining the utilities associated with the information states of the value nodes. The utilities Y_j(ğ¬_I(j)) are defined and added similarly to the probabilities.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Value node V1 has only node T in its information set and node T only has two states. Therefore, the utility matrix of node V1 should hold utility values corresponding to states test and no  test.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Y_V1 = UtilityMatrix(diagram, \"V1\")\nY_V1[\"test\"] = -25\nY_V1[\"no test\"] = 0\nadd_utilities!(diagram, \"V1\", Y_V1)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We then define the utilities associated with the base profit of the purchase in different scenarios.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Y_V2 = UtilityMatrix(diagram, \"V2\")\nY_V2[\"buy without guarantee\"] = 100\nY_V2[\"buy with guarantee\"] = 40\nY_V2[\"don't buy\"] = 0\nadd_utilities!(diagram, \"V2\", Y_V2)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Finally, we define the utilities corresponding to the repair costs. The rows of the utilities matrix Y_V3 correspond to the state of the car, while the columns correspond to the decision made in node A. Notice that the utility values for the second row are added as a vector, in this case it is important to give the utility values in the correct order. The order of the columns is determined by the order in which the states are given when declaring node A. See the usage page for more information on the syntax.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Y_V3 = UtilityMatrix(diagram, \"V3\")\nY_V3[\"lemon\", \"buy without guarantee\"] = -200\nY_V3[\"lemon\", \"buy with guarantee\"] = 0\nY_V3[\"lemon\", \"don't buy\"] = 0\nY_V3[\"peach\", :] = [-40, -20, 0]\nadd_utilities!(diagram, \"V3\", Y_V3)","category":"page"},{"location":"examples/used-car-buyer/#Generate-influence-diagram","page":"Used Car Buyer","title":"Generate influence diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Finally, generate the full influence diagram before defining the decision model. By default this function uses the default path probabilities and utilities, which are defined as the joint probability of all chance events in the diagram and the sum of utilities in value nodes, respectively. In the Contingent Portfolio Programming example, we show how to use a user-defined custom path utility function.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"generate_diagram!(diagram)","category":"page"},{"location":"examples/used-car-buyer/#Decision-model","page":"Used Car Buyer","title":"Decision model","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We then construct the decision model by declaring a JuMP model and adding decision variables and path compatibility variables to the model. We define the objective function to be the expected value.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"model = Model()\nz = DecisionVariables(model, diagram)\nx_s = PathCompatibilityVariables(model, diagram, z)\nEV = expected_value(model, diagram, x_s)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We can perform the optimization using an optimizer such as HiGHS.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"optimizer = optimizer_with_attributes(\n    () -> HiGHS.Optimizer()\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/used-car-buyer/#Analyzing-results","page":"Used Car Buyer","title":"Analyzing results","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Once the model is solved, we extract the results.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Z = DecisionStrategy(diagram, z)\nS_probabilities = StateProbabilities(diagram, Z)\nU_distribution = UtilityDistribution(diagram, Z)","category":"page"},{"location":"examples/used-car-buyer/#Decision-strategy","page":"Used Car Buyer","title":"Decision strategy","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We obtain the following optimal decision strategy:","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_decision_strategy(diagram, Z, S_probabilities)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Decision in T â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ test          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ State(s) of R â”‚ Decision in A         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ lemon         â”‚ buy with guarantee    â”‚\nâ”‚ peach         â”‚ buy without guarantee â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/used-car-buyer/#Utility-distribution","page":"Used Car Buyer","title":"Utility distribution","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_utility_distribution(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Utility â”‚ Probability â”‚\nâ”‚   Float64 â”‚     Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 15.000000 â”‚    0.200000 â”‚\nâ”‚ 35.000000 â”‚    0.800000 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"From the utility distribution, we can see that Joe's profit with this strategy is 15 USD, with a 20% probability (the car is a lemon) and 35 USD with an 80% probability (the car is a peach).","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_statistics(U_distribution)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Name â”‚ Statistics â”‚\nâ”‚   String â”‚    Float64 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚     Mean â”‚  31.000000 â”‚\nâ”‚      Std â”‚   8.000000 â”‚\nâ”‚ Skewness â”‚  -1.500000 â”‚\nâ”‚ Kurtosis â”‚   0.250000 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The expected profit is thus 31 USD.","category":"page"},{"location":"examples/used-car-buyer/#References","page":"Used Car Buyer","title":"References","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"[1]: Howard, R. A. (1977). The used car buyer. Reading in Decision Analysis, 2nd Ed. Stanford Research Institute, Menlo Park, CA.","category":"page"}]
}

<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Path-based model Â· DecisionProgramming.jl</title><meta name="title" content="Path-based model Â· DecisionProgramming.jl"/><meta property="og:title" content="Path-based model Â· DecisionProgramming.jl"/><meta property="twitter:title" content="Path-based model Â· DecisionProgramming.jl"/><meta name="description" content="Documentation for DecisionProgramming.jl."/><meta property="og:description" content="Documentation for DecisionProgramming.jl."/><meta property="twitter:description" content="Documentation for DecisionProgramming.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DecisionProgramming.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li><a class="tocitem" href="../influence-diagram/">Influence Diagram</a></li><li><a class="tocitem" href="../RJT-model/">RJT model</a></li><li class="is-active"><a class="tocitem" href>Path-based model</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Paths"><span>Paths</span></a></li><li><a class="tocitem" href="#Probabilities"><span>Probabilities</span></a></li><li><a class="tocitem" href="#Decision-Strategies"><span>Decision Strategies</span></a></li><li><a class="tocitem" href="#path-probability-doc"><span>Path Probability</span></a></li><li><a class="tocitem" href="#Consequences"><span>Consequences</span></a></li><li><a class="tocitem" href="#Path-Utility"><span>Path Utility</span></a></li><li><a class="tocitem" href="#Path-Distribution"><span>Path Distribution</span></a></li><li><a class="tocitem" href="#Effective-Paths"><span>Effective Paths</span></a></li><li><a class="tocitem" href="#Active-Paths"><span>Active Paths</span></a></li><li><a class="tocitem" href="#Compatible-Paths"><span>Compatible Paths</span></a></li><li><a class="tocitem" href="#Symmetry"><span>Symmetry</span></a></li><li><a class="tocitem" href="#Decision-Model"><span>Decision Model</span></a></li><li><a class="tocitem" href="#Decision-Variables"><span>Decision Variables</span></a></li><li><a class="tocitem" href="#Path-Compatibility-Variables"><span>Path Compatibility Variables</span></a></li><li><a class="tocitem" href="#Lazy-Probability-Cut"><span>Lazy Probability Cut</span></a></li><li><a class="tocitem" href="#Single-Policy-Update"><span>Single Policy Update</span></a></li><li><a class="tocitem" href="#Expected-Value"><span>Expected Value</span></a></li><li><a class="tocitem" href="#Positive-and-Negative-Path-Utilities"><span>Positive and Negative Path Utilities</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../cvar/">Conditional value-at-risk</a></li><li><a class="tocitem" href="../analyzing-decision-strategies/">Analyzing Decision Strategies</a></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><a class="tocitem" href="../../usage/">Usage</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li><li><a class="tocitem" href="../../examples/CHD_preventative_care/">CHD preventative care allocation</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Path-based model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Path-based model</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/gamma-opt/DecisionProgramming.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ï‚›</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/path-based-model.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ï„</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="path-based-model"><a class="docs-heading-anchor" href="#path-based-model">Path-based model</a><a id="path-based-model-1"></a><a class="docs-heading-anchor-permalink" href="#path-based-model" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>This section introduces path variables and how to structure an optimization problem based on them. Generally solution times are slower for path based formulations than for RJT based formulations and thus using <a href="../RJT-model/">RJT formulations</a> is recommended.</p><h2 id="Paths"><a class="docs-heading-anchor" href="#Paths">Paths</a><a id="Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Paths" title="Permalink"></a></h2><p><img src="../figures/paths.svg" alt/></p><p>In influence diagrams, paths represent realizations of states for chance and decision nodes. For example, the above tree represents generating all paths with states <span>$S_1=\{1,2\}$</span> and <span>$S_2=\{1,2,3\}.$</span></p><p>Formally, a <strong>path</strong> is a sequence of states</p><p class="math-container">\[ğ¬=(s_1, s_2, ...,s_n)âˆˆğ’,\]</p><p>where a state <span>$s_iâˆˆS_i$</span> is defined for all chance and decision nodes <span>$iâˆˆCâˆªD.$</span> We denote the set of <strong>paths</strong> as</p><p class="math-container">\[ğ’=âˆ_{jâˆˆCâˆªD} S_j=S_1Ã—S_2Ã—...Ã—S_n.\]</p><p>We define a <strong>subpath</strong> of <span>$ğ¬$</span> with <span>$AâŠ†CâˆªD$</span> as a subsequence</p><p class="math-container">\[ğ¬_A=(ğ¬_{i}âˆ£iâˆˆA)âˆˆğ’_A.\]</p><p>We denote the set of <strong>subpaths</strong> as</p><p class="math-container">\[ğ’_A=âˆ_{iâˆˆA} S_i.\]</p><p>We define the <strong>number of paths</strong> as</p><p class="math-container">\[|ğ’_A|=âˆ_{iâˆˆA}|S_i|.\]</p><p>As mentioned above, each node <span>$jâˆˆN$</span> has an information set <span>$I(j)$</span>. A subpath, which is formed by the states of the nodes in the information set, is referred to as an <strong>information state</strong>  <span>$ğ¬_{I(j)}$</span> of node <span>$j$</span>. The set of these subpaths is called the <strong>information states</strong> <span>$ğ’_{I(j)}$</span> of node <span>$jâˆˆN.$</span></p><p>Also note that <span>$ğ’=ğ’_{CâˆªD},$</span> and <span>$ğ’_{i}=S_i$</span> and <span>$ğ¬_i=s_i$</span> where <span>$iâˆˆCâˆªD$</span> is an individual node.</p><h2 id="Probabilities"><a class="docs-heading-anchor" href="#Probabilities">Probabilities</a><a id="Probabilities-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilities" title="Permalink"></a></h2><p>Each chance node is associated with a set of discrete probability distributions over its states. Each of the probability distributions corresponds to one of the node&#39;s information states. Formally, for each chance node <span>$jâˆˆC$</span>, we denote the <strong>probability</strong> of state <span>$s_j$</span> given information state <span>$ğ¬_{I(j)}$</span> as</p><p class="math-container">\[â„™(X_j=s_jâˆ£X_{I(j)}=ğ¬_{I(j)})âˆˆ[0, 1],\]</p><p>with</p><p class="math-container">\[âˆ‘_{s_jâˆˆS_j} â„™(X_j=s_jâˆ£X_{I(j)}=ğ¬_{I(j)}) = 1.\]</p><p>A chance state with a given information state is considered <strong>active</strong> if its probability is nonzero</p><p class="math-container">\[â„™(X_j=s_jâˆ£X_{I(j)}=ğ¬_{I(j)})&gt;0.\]</p><p>Otherwise, it is <strong>inactive</strong>.</p><h2 id="Decision-Strategies"><a class="docs-heading-anchor" href="#Decision-Strategies">Decision Strategies</a><a id="Decision-Strategies-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Strategies" title="Permalink"></a></h2><p>Each decision strategy models how the decision maker chooses a state <span>$s_jâˆˆS_j$</span> given an information state <span>$ğ¬_{I(j)}$</span> at decision node <span>$jâˆˆD.$</span> A decision node can be seen as a special type of chance node, such that the probability of the chosen state given an information state is fixed to one</p><p class="math-container">\[â„™(X_j=s_jâˆ£X_{I(j)}=ğ¬_{I(j)})=1.\]</p><p>By definition, the probabilities for other states are zero.</p><p>Formally, for each decision node <span>$jâˆˆD,$</span> a <strong>local decision strategy</strong> is a function that maps an information state <span>$ğ¬_{I(j)}$</span> to a state <span>$s_j$</span></p><p class="math-container">\[Z_j:ğ’_{I(j)}â†¦S_j.\]</p><p>A <strong>decision strategy</strong> contains one local decision strategy for each decision node</p><p class="math-container">\[Z=\{Z_jâˆ£jâˆˆD\}.\]</p><p>The set of <strong>all decision strategies</strong> is denoted with <span>$â„¤.$</span></p><h2 id="path-probability-doc"><a class="docs-heading-anchor" href="#path-probability-doc">Path Probability</a><a id="path-probability-doc-1"></a><a class="docs-heading-anchor-permalink" href="#path-probability-doc" title="Permalink"></a></h2><p>The probability distributions at chance and decision nodes define the probability distribution over all paths <span>$ğ¬âˆˆğ’,$</span> which depends on the decision strategy <span>$Zâˆˆâ„¤.$</span> We refer to it as the path probability</p><p class="math-container">\[â„™(X=ğ¬âˆ£Z) = âˆ_{jâˆˆCâˆªD} â„™(X_j=ğ¬_jâˆ£X_{I(j)}=ğ¬_{I(j)}).\]</p><p>We can decompose the path probability into two parts</p><p class="math-container">\[â„™(X=ğ¬âˆ£Z) = p(ğ¬) q(ğ¬âˆ£Z).\]</p><p>The first part consists of the probability contributed by the chance nodes. We refer to it as the <strong>upper bound of path probability</strong></p><p class="math-container">\[p(ğ¬) = âˆ_{jâˆˆC} â„™(X_j=ğ¬_jâˆ£X_{I(j)}=ğ¬_{I(j)}).\]</p><p>The second part consists of the probability contributed by the decision nodes.</p><p class="math-container">\[q(ğ¬âˆ£Z) = âˆ_{jâˆˆD} â„™(X_j=ğ¬_jâˆ£X_{I(j)}=ğ¬_{I(j)}).\]</p><p>Because the probabilities of decision nodes are defined as one or zero depending on the decision strategy, we can simplify the second part to an indicator function</p><p class="math-container">\[q(ğ¬âˆ£Z)=\begin{cases}
1, &amp; x(ğ¬) = 1 \\
0, &amp; \text{otherwise}
\end{cases}.\]</p><p>The binary variable <span>$x(ğ¬)$</span> indicates whether a decision stategy is <strong>compatible</strong> with the path <span>$ğ¬,$</span> that is, if each local decision strategy chooses a state on the path. Using the indicator function <span>$I(.)$</span> whose value is 1 if the expression inside is <em>true</em> and 0 otherwise, we have</p><p class="math-container">\[x(ğ¬) = \prod_{jâˆˆD} I(Z_j(ğ¬_{I(j)})=ğ¬_j).\]</p><p>Now the <strong>path probability</strong> equals the upper bound if the path is compatible with given decision strategy. Otherwise, the path probability is zero. Formally, we have</p><p class="math-container">\[â„™(ğ¬âˆ£X,Z)=
\begin{cases}
p(ğ¬), &amp; x(ğ¬) = 1 \\
0, &amp; \text{otherwise}
\end{cases}.\]</p><h2 id="Consequences"><a class="docs-heading-anchor" href="#Consequences">Consequences</a><a id="Consequences-1"></a><a class="docs-heading-anchor-permalink" href="#Consequences" title="Permalink"></a></h2><p>For each value node <span>$jâˆˆV$</span>, we define the <strong>consequence</strong> given information state <span>$ğ¬_{I(j)}$</span> as</p><p class="math-container">\[Y_j:ğ’_{I(j)}â†¦â„‚,\]</p><p>where <span>$â„‚$</span> is the set of real-valued consequences.</p><h2 id="Path-Utility"><a class="docs-heading-anchor" href="#Path-Utility">Path Utility</a><a id="Path-Utility-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Utility" title="Permalink"></a></h2><p>The <strong>utility function</strong> is a function that maps consequences to real-valued utility</p><p class="math-container">\[U:â„‚^{|V|}â†¦â„.\]</p><p>The <strong>path utility</strong> is defined as the utility function acting on the consequences of value nodes given their information states</p><p class="math-container">\[\mathcal{U}(ğ¬) = U(\{Y_j(ğ¬_{I(j)}) âˆ£ jâˆˆV\}).\]</p><p>The <strong>default path utility</strong> is the sum of node utilities <span>$U_j$</span></p><p class="math-container">\[\mathcal{U}(ğ¬) = âˆ‘_{jâˆˆV} U_j(Y_j(ğ¬_{I(j)})).\]</p><p>The utility function affects the objectives as discussed on the <a href="#Decision-Model">Decision Model</a> page. We can choose the utility function such that the path utility function either returns:</p><ul><li>a numerical value, which leads to a mixed-integer linear programming (MILP) formulation or</li><li>a linear function with real and integer-valued variables, which leads to a mixed-integer quadratic programming (MIQP) formulation.</li></ul><p>Different formulations require a solver capable of solving them.</p><h2 id="Path-Distribution"><a class="docs-heading-anchor" href="#Path-Distribution">Path Distribution</a><a id="Path-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Distribution" title="Permalink"></a></h2><p>A <strong>path distribution</strong> is a pair</p><p class="math-container">\[(â„™(X=ğ¬âˆ£Z), \mathcal{U}(ğ¬))\]</p><p>that comprises of a path probability function and a path utility function over paths <span>$ğ¬âˆˆğ’$</span> conditional to the decision strategy <span>$Z.$</span></p><h2 id="Effective-Paths"><a class="docs-heading-anchor" href="#Effective-Paths">Effective Paths</a><a id="Effective-Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Effective-Paths" title="Permalink"></a></h2><p><img src="../figures/paths_eff.svg" alt/></p><p>It is possible for some combinations of chance or decision states to be unrealizable. We refer to such subpaths as ineffective. For example, the above tree represents the generation of paths where subpaths <span>$ğ’_{\{1,2\}}^â€²=\{(2,2)\}$</span>, <span>$ğ’_{\{1,2,3\}}^â€²=\{(1,1,2), (1,2,1)\}$</span> are ineffective.</p><p>Formally, the path <span>$ğ¬$</span> is <strong>ineffective</strong> if and only if <span>$ğ¬_Aâˆˆğ’_A^â€²$</span> given ineffective subpaths <span>$ğ’_A^â€²âŠ†ğ’_A$</span> for nodes <span>$AâŠ†CâˆªD.$</span> Then, <strong>effective paths</strong> is a subset of all paths without ineffective paths</p><p class="math-container">\[ğ’^âˆ—=\{ğ¬âˆˆğ’âˆ£ğ¬_{A}âˆ‰ğ’_{A}^â€²\}âŠ†ğ’.\]</p><p>The <a href="#Decision-Model">Decision Model</a> size depends on the number of effective paths, rather than the number of paths or size of the influence diagram directly.</p><p>In Decision Programming, one can declare certain subpaths to be ineffective using the <em>fixed path</em> and <em>forbidden paths</em> sets.</p><h3 id="Fixed-Path"><a class="docs-heading-anchor" href="#Fixed-Path">Fixed Path</a><a id="Fixed-Path-1"></a><a class="docs-heading-anchor-permalink" href="#Fixed-Path" title="Permalink"></a></h3><p><strong>Fixed path</strong> refers to a subpath which must be realized. If the fixed path is <span>$s_Y = S_Y^f$</span> for all nodes <span>$YâŠ†CâˆªD$</span>, then the effective paths in the model are</p><p class="math-container">\[ğ’^âˆ—=\{ğ¬âˆˆğ’âˆ£s_{Y} = S_{Y}^f \forall \ Y \}.\]</p><h3 id="Forbidden-Paths"><a class="docs-heading-anchor" href="#Forbidden-Paths">Forbidden Paths</a><a id="Forbidden-Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Forbidden-Paths" title="Permalink"></a></h3><p><strong>Forbidden paths</strong> are a way to declare ineffective subpaths. If <span>$ğ¬_Xâˆˆğ’_X^â€²$</span> are forbidden subpaths for nodes <span>$XâŠ†CâˆªD$</span>, then the effective paths in the model are</p><p class="math-container">\[ğ’^âˆ—=\{ğ¬âˆˆğ’âˆ£ğ¬_{X} âˆ‰ ğ’_{X}^â€²\}.\]</p><h2 id="Active-Paths"><a class="docs-heading-anchor" href="#Active-Paths">Active Paths</a><a id="Active-Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Active-Paths" title="Permalink"></a></h2><p>If the upper bound of path probability is zero, its probability is zero, and it does not affect the solution. Therefore, we can consider only the paths with a positive upper bound of path probability. We refer to these paths as active paths. Formally, we define an <strong>active path</strong> as a path <span>$ğ¬$</span> if all of its chance states are active</p><p class="math-container">\[\begin{aligned}
X(ğ¬)&amp;â†”(p(ğ¬)&gt;0)\\ &amp;â†” â‹€_{jâˆˆC} (â„™(X_j=ğ¬_jâˆ£X_{I(j)}=ğ¬_{I(j)})&gt;0).
\end{aligned}\]</p><p>Otherwise, it is an <strong>inactive path</strong>. We denote the set of <strong>active paths</strong> as</p><p class="math-container">\[ğ’(X)=\{ğ¬âˆˆğ’ âˆ£ X(ğ¬)\}.\]</p><p>The <strong>number of active paths</strong> is</p><p class="math-container">\[|ğ’(X)|â‰¤|ğ’|.\]</p><p>Effective paths are related to active paths, such that, for all <span>$jâˆˆC,$</span> we have ineffective subpaths</p><p class="math-container">\[ğ’_{I(j)âˆªj}^â€²=\{ğ¬_{I(j)âˆªj}âˆˆğ’_{I(j)âˆªj} âˆ£ â„™(X_j=s_jâˆ£X_{I(j)}=ğ¬_{I(j)})=0\}.\]</p><p>Generally, the effective paths is a subset of the active paths, that is</p><p class="math-container">\[ğ’^âˆ— âŠ† ğ’(X).\]</p><p>If there are no other ineffective subpaths, we have</p><p class="math-container">\[ğ’^âˆ— = ğ’(X).\]</p><p>Notice that, the number of active paths affects the size of the <a href="#Decision-Model">Decision Model</a> because it depends on the number of effective paths.</p><h2 id="Compatible-Paths"><a class="docs-heading-anchor" href="#Compatible-Paths">Compatible Paths</a><a id="Compatible-Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Compatible-Paths" title="Permalink"></a></h2><p>Each decision strategy <span>$Zâˆˆâ„¤$</span> determines a set of <strong>compatible paths</strong>. We use the shorthand <span>$Z(s) â†” (q(ğ¬ \mid Z) = 1)$</span>, where q is as defined in <a href="#path-probability-doc">Path Probability</a>. Formally, we denote the set of compatible paths as</p><p class="math-container">\[ğ’(Z)=\{ğ¬âˆˆğ’ âˆ£ Z(ğ¬)\}.\]</p><p>Since each local decision strategy <span>$Z_jâˆˆZ$</span> is deterministic, it can choose only one state <span>$s_j$</span> for each information state <span>$ğ¬_{I(j)}$</span>. Thus, the <strong>number of compatible paths</strong> is</p><p class="math-container">\[|ğ’(Z)|=|ğ’|/|ğ’_D|=|ğ’_C|.\]</p><p>The compatible paths of all distinct pairs of decision strategies are disjoint. Formally, for all <span>$Z,Z^â€²âˆˆâ„¤$</span> where <span>$Zâ‰ Z^â€²$</span>, we have</p><p class="math-container">\[ğ’(Z)âˆ©ğ’(Z^â€²)=\{ğ¬âˆˆğ’âˆ£Z(ğ¬)âˆ§Z^â€²(ğ¬)\}=âˆ….\]</p><h3 id="Locally-Compatible-Paths"><a class="docs-heading-anchor" href="#Locally-Compatible-Paths">Locally Compatible Paths</a><a id="Locally-Compatible-Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Locally-Compatible-Paths" title="Permalink"></a></h3><p><strong>Locally compatible paths</strong> refers to a subset of paths that include the subpath <span>$(ğ¬_{I(j)}, s_j)$</span> and thus, represent the local decision strategy <span>$Z_j(ğ¬_{I(j)}) = s_j$</span> for decision node <span>$j \in D$</span>. Formally, the locally compatible paths for node <span>$j \in D$</span>, state <span>$s_j \in S_j$</span> and information state <span>$ğ¬_{I(j)} \in ğ’_{I(j)}$</span> includes the paths</p><p class="math-container">\[ğ’_{s_j \mid s_{I(j)}} = \{ ğ¬ \in ğ’ \mid (ğ¬_{I(j)}, s_j) âŠ‚ ğ¬\}.\]</p><h2 id="Symmetry"><a class="docs-heading-anchor" href="#Symmetry">Symmetry</a><a id="Symmetry-1"></a><a class="docs-heading-anchor-permalink" href="#Symmetry" title="Permalink"></a></h2><p>We define the set of active and compatible paths as</p><p class="math-container">\[ğ’(X)âˆ©ğ’(Z)=\{ğ¬âˆˆğ’âˆ£X(ğ¬)âˆ§Z(ğ¬)\}.\]</p><p>An influence diagram is <strong>symmetric</strong> if the number of active and compatible paths is a constant. Formally, if for all <span>$Z,Z^â€²âˆˆâ„¤,$</span> where <span>$Zâ‰ Z^â€²,$</span> we have</p><p class="math-container">\[|ğ’(X)âˆ©ğ’(Z)|=|ğ’(X)âˆ©ğ’(Z^â€²)|.\]</p><p>For example, if all paths are active, we have <span>$|ğ’(X)âˆ©ğ’(Z)|=|ğ’(Z)|,$</span> which is a constant. Otherwise, the influence diagram is <strong>asymmetric</strong>. The figures below demonstrate symmetric and asymmetric influence diagrams.</p><h3 id="Example-1"><a class="docs-heading-anchor" href="#Example-1">Example 1</a><a id="Example-1-1"></a><a class="docs-heading-anchor-permalink" href="#Example-1" title="Permalink"></a></h3><p><img src="../figures/id1.svg" alt/></p><p>Consider the influence diagram with two nodes. The first is a decision node with two states, and the second is a chance node with three states.</p><p><img src="../figures/paths1.svg" alt/></p><p>If there are no inactive chance states, all paths are possible. That is, for all <span>$sâˆˆS,$</span> we have <span>$p(s)&gt;0.$</span> In this case, the influence diagram is symmetric.</p><h3 id="Example-2"><a class="docs-heading-anchor" href="#Example-2">Example 2</a><a id="Example-2-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2" title="Permalink"></a></h3><p><img src="../figures/paths2.svg" alt/></p><p>However, if there are inactive chance states, such as <span>$â„™(s_2=2âˆ£s_1=2)=0$</span>, we can remove <span>$(2,2)$</span> from the paths, visualized by a dashed shape. Therefore, there is a varying number of possible paths depending on whether the decision-maker chooses state <span>$s_1=1$</span> or <span>$s_1=2$</span> in the first node, and the influence diagram is asymmetric.</p><h3 id="Example-3"><a class="docs-heading-anchor" href="#Example-3">Example 3</a><a id="Example-3-1"></a><a class="docs-heading-anchor-permalink" href="#Example-3" title="Permalink"></a></h3><p><img src="../figures/id2.svg" alt/></p><p>Let us add one chance node with two states to the influence diagram.</p><p><img src="../figures/paths3.svg" alt/></p><p>Now, given inactive chance states such that we remove the dashed paths, we have a symmetric influence diagram. Both decisions will have an equal number of possible paths. However, there are only eight possible paths instead of twelve if there were no inactive chance states.</p><h2 id="Decision-Model"><a class="docs-heading-anchor" href="#Decision-Model">Decision Model</a><a id="Decision-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Model" title="Permalink"></a></h2><p>We aim to find an optimal decision strategy <span>$Z$</span> among all decision strategies <span>$â„¤$</span> by maximizing an objective function <span>$f$</span> on the path distribution of an influence diagram</p><p class="math-container">\[\underset{Zâˆˆâ„¤}{\text{maximize}}\quad f(\{(â„™(X=ğ¬âˆ£Z), \mathcal{U}(ğ¬)) âˆ£ ğ¬âˆˆğ’\}). \tag{1}\]</p><p><strong>Decision model</strong> refers to the mixed-integer linear programming formulation of this optimization problem. This page explains how to express decision strategies, compatible paths, path utilities and the objective of the model as a mixed-integer linear program. We present two standard objective functions, including expected value and conditional value-at-risk. The original decision model formulation was described in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, sections 3 and 5. We base the decision model on an improved formulation described in <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> section 3.3. We recommend reading the references for motivation, details, and proofs of the formulation.</p><h2 id="Decision-Variables"><a class="docs-heading-anchor" href="#Decision-Variables">Decision Variables</a><a id="Decision-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Variables" title="Permalink"></a></h2><p>Decision variables <span>$z(s_jâˆ£ğ¬_{I(j)})$</span> are equivalent to local decision strategies such that <span>$Z_j(ğ¬_{I(j)})=s_j$</span> if and only if <span>$z(s_jâˆ£ğ¬_{I(j)})=1$</span> and <span>$z(s_{j}^â€²âˆ£ğ¬_{I(j)})=0$</span> for all <span>$s_{j}^â€²âˆˆS_jâˆ–s_j.$</span> Constraint <span>$(2)$</span> defines the decisions to be binary variables and the constraint <span>$(3)$</span> states that only one decision alternative <span>$s_{j}$</span> can be chosen for each information set <span>$s_{I(j)}$</span>.</p><p class="math-container">\[z(s_jâˆ£ğ¬_{I(j)}) âˆˆ \{0,1\},\quad âˆ€jâˆˆD, s_jâˆˆS_j, ğ¬_{I(j)}âˆˆğ’_{I(j)} \tag{2}\]</p><p class="math-container">\[âˆ‘_{s_jâˆˆS_j} z(s_jâˆ£ğ¬_{I(j)})=1,\quad âˆ€jâˆˆD, ğ¬_{I(j)}âˆˆğ’_{I(j)} \tag{3}\]</p><h2 id="Path-Compatibility-Variables"><a class="docs-heading-anchor" href="#Path-Compatibility-Variables">Path Compatibility Variables</a><a id="Path-Compatibility-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Compatibility-Variables" title="Permalink"></a></h2><p>Path compatibility variables <span>$x(ğ¬)$</span> are indicator variables for whether path <span>$ğ¬$</span> is compatible with decision strategy <span>$Z$</span> defined by the decision variables <span>$z$</span>. These are continous variables but only assume binary values, so that the compatible paths <span>$ğ¬ âˆˆ ğ’(Z)$</span> take values <span>$x(ğ¬) = 1$</span> and other paths <span>$ğ¬ âˆˆ ğ’ \setminus ğ’(Z)$</span> take values <span>$x(ğ¬) = 0$</span>. Constraint <span>$(4)$</span> defines the lower and upper bounds for the variables.</p><p class="math-container">\[0â‰¤x(ğ¬)â‰¤1,\quad âˆ€ğ¬âˆˆğ’ \tag{4}\]</p><p>Constraint <span>$(5)$</span> ensures that only the variables associated with locally compatible paths <span>$ğ¬ \in ğ’_{s_j | ğ¬_{I(j)} }$</span> of the decision strategy can take value <span>$x(ğ¬) = 1$</span>. The effective locally compatible paths are denoted with <span>$| ğ’^*_{s_j | ğ¬_{I(j)}}|$</span>. The upper bound of the constraint uses the minimum of the <em>feasible paths</em> upper bound and the <em>theoretical</em> upper bound. The motivation of the feasible paths upper bound is below. For proofs and motivation on the theoretical upper bound see reference <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>.</p><p class="math-container">\[âˆ‘_{ğ¬ \in ğ’^*_{s_j | ğ¬_{I(j)}} } x(ğ¬) \leq \min ( \ | ğ’^*_{s_j | ğ¬_{I(j)}}|, \ \frac{| ğ’_{s_j | ğ¬_{I(j)}}| }{\displaystyle  \prod_{d \in D \setminus \{j, I(j)\}} |ğ’_d|} \ ) \ z(s_jâˆ£ğ¬_{I(j)}),\quad \forall j \in D, s_j \in S_j, ğ¬_{I(j)} \in ğ’_{I(j)} \tag{5}\]</p><p>Constraint <span>$(6)$</span> is called the probability cut constraint and it defines that the sum of the path probabilities of the compatible paths must equal one.</p><p class="math-container">\[âˆ‘_{ğ¬âˆˆğ’}x(ğ¬) p(ğ¬) = 1 \tag{6}\]</p><h3 id="Feasible-paths-upper-bound"><a class="docs-heading-anchor" href="#Feasible-paths-upper-bound">Feasible paths upper bound</a><a id="Feasible-paths-upper-bound-1"></a><a class="docs-heading-anchor-permalink" href="#Feasible-paths-upper-bound" title="Permalink"></a></h3><p>The <em>feasible paths upper bound</em> for the path compatibility variables is</p><p class="math-container">\[âˆ‘_{ğ¬ \in ğ’^*_{s_j | ğ¬_{I(j)}} } x(ğ¬) \leq  | ğ’^*_{s_j | ğ¬_{I(j)}}| \ z(s_jâˆ£ğ¬_{I(j)}),\quad \forall j \in D, s_j \in S_j, ğ¬_{I(j)} \in ğ’_{I(j)}\]</p><p>where <span>$ğ’^*_{s_j | s_{I(j)}}$</span> is the set of effective locally compatible paths. This upper bound is motivated by the implementation of the framework in which path compatibility variables <span>$x(ğ¬)$</span> are only generated for effective paths <span>$ğ¬ \in ğ’^âˆ—$</span>. The ineffective paths are not generated because they do not influence the objective function and having less variables reduces the size of the model.</p><p>Therefore, if the model has ineffective paths <span>$ğ¬ \in ğ’^â€²$</span>, then the number of effective paths is less than the number of all paths.</p><p class="math-container">\[|ğ’^*| &lt; |ğ’|\]</p><p>Therefore,</p><p class="math-container">\[|ğ’^*_{s_j | ğ¬_{I(j)}} | &lt; | ğ’_{s_j | ğ¬_{I(j)}}| .\]</p><p>The feasible paths upper bound is used in conjunction with the <em>theoretical upper bound</em> as follows.</p><p class="math-container">\[âˆ‘_{ğ¬ \in ğ’^*_{s_j | ğ¬_{I(j)}} } x(ğ¬) \leq \min ( \ | ğ’^*_{s_j | ğ¬_{I(j)}}|, \ \frac{| ğ’_{s_j | ğ¬_{I(j)}}| }{\displaystyle  \prod_{d \in D \setminus \{j, I(j)\}} |ğ’_d|} \ ) \ z(s_jâˆ£ğ¬_{I(j)}),\quad \forall j \in D, s_j \in S_j, ğ¬_{I(j)} \in ğ’_{I(j)}\]</p><p>The motivation for using the minimum of these bounds is that it depends on the problem structure which one is tighter. The feasible paths upper bound may be tighter if the set of ineffective paths is large compared to the number of all paths.</p><h2 id="Lazy-Probability-Cut"><a class="docs-heading-anchor" href="#Lazy-Probability-Cut">Lazy Probability Cut</a><a id="Lazy-Probability-Cut-1"></a><a class="docs-heading-anchor-permalink" href="#Lazy-Probability-Cut" title="Permalink"></a></h2><p>Constraint <span>$(6)$</span> is a complicating constraint involving all path compatibility variables <span>$x(s)$</span> and thus adding it directly to the model may slow down the overall solution process. It may be beneficial to instead add it as a <em>lazy constraint</em>. In the solver, a lazy constraint is only generated when an incumbent solution violates it. In some instances, this allows the MILP solver to prune nodes of the branch-and-bound tree more efficiently.</p><h2 id="Single-Policy-Update"><a class="docs-heading-anchor" href="#Single-Policy-Update">Single Policy Update</a><a id="Single-Policy-Update-1"></a><a class="docs-heading-anchor-permalink" href="#Single-Policy-Update" title="Permalink"></a></h2><p>To obtain (hopefully good) starting solutions, the SPU heuristic described in <sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup> can be used. The heuristic finds a locally optimal strategy in the sense that the strategy cannot be improved by changing any single local strategy. With large problems, the heuristic can quickly provide a solution that would otherwise take very long to obtain.</p><h2 id="Expected-Value"><a class="docs-heading-anchor" href="#Expected-Value">Expected Value</a><a id="Expected-Value-1"></a><a class="docs-heading-anchor-permalink" href="#Expected-Value" title="Permalink"></a></h2><p>The <strong>expected value</strong> objective is defined using the path compatibility variables <span>$x(ğ¬)$</span> and their associated path probabilities <span>$p(ğ¬)$</span> and path utilities <span>$\mathcal{U}(ğ¬)$</span>.</p><p class="math-container">\[\operatorname{E}(Z) = âˆ‘_{ğ¬âˆˆğ’} x(ğ¬) \ p(ğ¬) \ \mathcal{U}(ğ¬). \tag{7}\]</p><h2 id="Positive-and-Negative-Path-Utilities"><a class="docs-heading-anchor" href="#Positive-and-Negative-Path-Utilities">Positive and Negative Path Utilities</a><a id="Positive-and-Negative-Path-Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Positive-and-Negative-Path-Utilities" title="Permalink"></a></h2><p>We can omit the probability cut defined in constraint <span>$(6)$</span> from the model if we are maximising expected value of utility and use a <strong>positive path utility</strong> function <span>$\mathcal{U}^+$</span>. Similarly, we can use a <strong>negative path utility</strong> function <span>$\mathcal{U}^-$</span> when minimizing expected value. These functions are affine transformations of the path utility function <span>$\mathcal{U}$</span> which translate all utility values to positive/negative values. As an example of a positive path utility function, we can subtract the minimum of the original utility function and then add one as follows.</p><p class="math-container">\[\mathcal{U}^+(ğ¬) = \mathcal{U}(ğ¬) - \min_{ğ¬âˆˆğ’} \mathcal{U}(ğ¬) + 1. \tag{8}\]</p><p class="math-container">\[\mathcal{U}^-(ğ¬) = \mathcal{U}(ğ¬) - \max_{ğ¬âˆˆğ’} \mathcal{U}(ğ¬) - 1. \tag{9}\]</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Salo, A., Andelmin, J., &amp; Oliveira, F. (2022). Decision programming for mixed-integer multi-stage optimization under uncertainty. European Journal of Operational Research, 299(2), 550-565.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>HÃ¶lsÃ¤, O. (2020). Decision Programming Framework for Evaluating Testing Costs of Disease-Prone Pigs. Retrieved from <a href="http://urn.fi/URN:NBN:fi:aalto-202009295618">http://urn.fi/URN:NBN:fi:aalto-202009295618</a></li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Hankimaa, H., Herrala, O., Oliveira, F., Tollander de Balsch, J. (2023). DecisionProgramming.jl â€“ A framework for modelling decision problems using mathematical programming. Retrieved from <a href="https://arxiv.org/abs/2307.13299">https://arxiv.org/abs/2307.13299</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../RJT-model/">Â« RJT model</a><a class="docs-footer-nextpage" href="../cvar/">Conditional value-at-risk Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.6.0 on <span class="colophon-date" title="Monday 2 September 2024 06:23">Monday 2 September 2024</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

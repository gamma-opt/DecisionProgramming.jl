<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Analyzing Decision Strategies Â· DecisionProgramming.jl</title><meta name="title" content="Analyzing Decision Strategies Â· DecisionProgramming.jl"/><meta property="og:title" content="Analyzing Decision Strategies Â· DecisionProgramming.jl"/><meta property="twitter:title" content="Analyzing Decision Strategies Â· DecisionProgramming.jl"/><meta name="description" content="Documentation for DecisionProgramming.jl."/><meta property="og:description" content="Documentation for DecisionProgramming.jl."/><meta property="twitter:description" content="Documentation for DecisionProgramming.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DecisionProgramming.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li><a class="tocitem" href="../influence-diagram/">Influence Diagram</a></li><li><a class="tocitem" href="../paths/">Paths</a></li><li><a class="tocitem" href="../decision-model/">Decision Model</a></li><li class="is-active"><a class="tocitem" href>Analyzing Decision Strategies</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Generating-Compatible-Paths"><span>Generating Compatible Paths</span></a></li><li><a class="tocitem" href="#Utility-Distribution"><span>Utility Distribution</span></a></li><li><a class="tocitem" href="#Measuring-Risk"><span>Measuring Risk</span></a></li><li><a class="tocitem" href="#State-Probabilities"><span>State Probabilities</span></a></li></ul></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><a class="tocitem" href="../../usage/">Usage</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li><li><a class="tocitem" href="../../examples/CHD_preventative_care/">CHD preventative care allocation</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Analyzing Decision Strategies</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Analyzing Decision Strategies</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/gamma-opt/DecisionProgramming.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ï‚›</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/analyzing-decision-strategies.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ï„</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="analyzing-decision-strategies"><a class="docs-heading-anchor" href="#analyzing-decision-strategies">Analyzing Decision Strategies</a><a id="analyzing-decision-strategies-1"></a><a class="docs-heading-anchor-permalink" href="#analyzing-decision-strategies" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>This section focuses on how we can analyze fixed decision strategies <span>$Z$</span> on an influence diagram <span>$G$</span>, such as ones obtained by solving the Decision Programming model described in <a href="../decision-model/#decision-model">the previous section</a>. We can rule out all incompatible and inactive paths from the analysis because they do not influence the outcomes of the strategy. This means that we only consider paths <span>$ğ¬$</span> that are compatible and active <span>$ğ¬ \in ğ’(X) \cap ğ’(Z)$</span>.</p><h2 id="Generating-Compatible-Paths"><a class="docs-heading-anchor" href="#Generating-Compatible-Paths">Generating Compatible Paths</a><a id="Generating-Compatible-Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-Compatible-Paths" title="Permalink"></a></h2><p>We can generate compatible paths <span>$ğ¬âˆˆğ’(Z)$</span> as follows.</p><ol><li>Initialize path <span>$ğ¬$</span> of length <span>$n$</span> with undefined values.</li><li>Fill path with chance states <span>$s_jâˆˆS_j$</span> for all <span>$jâˆˆC.$</span></li><li>In increasing order of decision nodes <span>$jâˆˆD$</span>, fill decision states by computing decision strategy <span>$s_j=Z_j(ğ¬_{I(j)}).$</span></li></ol><h2 id="Utility-Distribution"><a class="docs-heading-anchor" href="#Utility-Distribution">Utility Distribution</a><a id="Utility-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Utility-Distribution" title="Permalink"></a></h2><p>We define unique path utility values as</p><p class="math-container">\[\mathcal{U}^âˆ—=\{\mathcal{U}(ğ¬)âˆ£ğ¬âˆˆğ’(Z)\}.\]</p><p>The probability mass function of the <strong>utility distribution</strong> associates each unique path utility to a probability as follows</p><p class="math-container">\[â„™(X=u)=âˆ‘_{ğ¬âˆˆğ’(Z)âˆ£\mathcal{U}(ğ¬)=u} p(ğ¬),\quad âˆ€uâˆˆ\mathcal{U}^âˆ—.\]</p><p>From the utility distribution, we can calculate the cumulative distribution, statistics, and risk measures. The relevant statistics are expected value, standard deviation, skewness and kurtosis. Risk measures focus on the conditional value-at-risk (CVaR), also known as expected shortfall.</p><h2 id="Measuring-Risk"><a class="docs-heading-anchor" href="#Measuring-Risk">Measuring Risk</a><a id="Measuring-Risk-1"></a><a class="docs-heading-anchor-permalink" href="#Measuring-Risk" title="Permalink"></a></h2><p><img src="../figures/risk_measures.svg" alt/></p><p>We have a discrete probability distribution <span>$f(x)=â„™(X=x)âˆˆ[0, 1]$</span> over the domain <span>$xâˆˆÎ©$</span> with <span>$âˆ‘_{xâˆˆÎ©}â„™(X=x)=1$</span> and its cumulative distribution function <span>$F(x) = âˆ‘_{x^â€²âˆˆÎ©âˆ£x^â€²â‰¤x}f(x^â€²).$</span> We define the expected value as</p><p class="math-container">\[E(X)=âˆ‘_{xâˆˆÎ©} x â‹… f(x).\]</p><p>We present the concept of conditional value-at-risk, a <em>risk measure</em> of the conditional expected value of the tail of a probability distribution for a given <strong>probability level</strong> of <span>$Î±âˆˆ[0, 1].$</span> First, we define the <strong>value-at-risk</strong> as</p><p class="math-container">\[\operatorname{VaR}_Î±(X) = x_Î± = \min\{xâˆˆÎ© âˆ£ F(x) â‰¥ Î±\}.\]</p><p>It is the smallest value <span>$x$</span> such that the cumulative probability is equal or above <span>$Î±.$</span> Then, we define the <strong>conditional value-at-risk</strong> as</p><p class="math-container">\[\operatorname{CVaR}_Î±(X)=\textcolor{darkorange}{\frac{1}{Î±}} \left(\textcolor{darkred}{âˆ‘_{xâ‰¤x_Î±} x â‹… f(x)} \textcolor{darkblue}{- \left(âˆ‘_{xâ‰¤x_Î±} f(x) - Î±\right) x_Î± }\right).\]</p><p>The red part measures the conditional expected value of the tail distribution. The blue part corrects the expected value by subtracting the amount of expected value that is between probability level <span>$Î±$</span> and <span>$F(x_Î±)$</span> and orange part divides by the total probability.</p><p>Value-at-risk and conditional value-at-risk are monotonically increasing functions. Therefore, the lower bound is the value at <span>$Î±=0$</span> and the upper bound is the value at <span>$Î±=1.$</span> For value-at-risk, we have</p><p class="math-container">\[\operatorname{VaR}_0(X) = \min \{xâˆˆÎ©\},\]</p><p class="math-container">\[\operatorname{VaR}_1(X) = \max \{xâˆˆÎ©\}.\]</p><p>For conditional value-at-risk, we have</p><p class="math-container">\[\lim_{Î±â†’0} \operatorname{CVaR}_Î±(X) = \operatorname{VaR}_0(X),\]</p><p class="math-container">\[\operatorname{CVaR}_1(X) = E(X).\]</p><p>The above figure demonstrates these values on a discrete probability distribution.</p><h2 id="State-Probabilities"><a class="docs-heading-anchor" href="#State-Probabilities">State Probabilities</a><a id="State-Probabilities-1"></a><a class="docs-heading-anchor-permalink" href="#State-Probabilities" title="Permalink"></a></h2><p>We use a recursive definition where <span>$Ïµ$</span> denotes an empty state to denote <strong>paths with fixed states</strong>.</p><p class="math-container">\[\begin{aligned}
ğ’_{Ïµ} &amp;= ğ’(Z) \\
ğ’_{Ïµ,s_i} &amp;= \{ğ¬âˆˆğ’_{Ïµ} âˆ£ ğ¬_i=s_i\} \\
ğ’_{Ïµ,s_i,s_j} &amp;= \{ğ¬âˆˆğ’_{Ïµ,s_i} âˆ£ ğ¬_j=s_j\},\quad jâ‰ i
\end{aligned}\]</p><p>The probability of all paths sums to one</p><p class="math-container">\[â„™(Ïµ) = \sum_{ğ¬âˆˆğ’_Ïµ} p(ğ¬) = 1.\]</p><p><strong>State probabilities</strong> for each node <span>$iâˆˆCâˆªD$</span> and state <span>$s_iâˆˆS_i$</span> denote how likely the state occurs given all path probabilities</p><p class="math-container">\[â„™(s_iâˆ£Ïµ) = \sum_{ğ¬âˆˆğ’_{Ïµ,s_i}} \frac{p(ğ¬)}{â„™(Ïµ)} = \sum_{ğ¬âˆˆğ’_{Ïµ,s_i}} p(ğ¬)\]</p><p>An <strong>active state</strong> is a state with positive state probability <span>$â„™(s_iâˆ£c)&gt;0$</span> given conditions <span>$c.$</span></p><p>We can <strong>generalize the state probabilities</strong> as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state <span>$s_i$</span> and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.</p><p class="math-container">\[â„™(s_jâˆ£Ïµ,s_i) = \sum_{ğ¬âˆˆğ’_{Ïµ,s_i,s_j}} \frac{p(ğ¬)}{â„™(s_iâˆ£Ïµ)}\]</p><p>We can then repeat this process by choosing an active state from the new conditional state probabilities <span>$s_k$</span> that is different from previously chosen states <span>$kâ‰ j.$</span></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../decision-model/">Â« Decision Model</a><a class="docs-footer-nextpage" href="../computational-complexity/">Computational Complexity Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.0 on <span class="colophon-date" title="Tuesday 3 October 2023 12:27">Tuesday 3 October 2023</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

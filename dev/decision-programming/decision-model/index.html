<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Decision Model · DecisionProgramming.jl</title><meta name="title" content="Decision Model · DecisionProgramming.jl"/><meta property="og:title" content="Decision Model · DecisionProgramming.jl"/><meta property="twitter:title" content="Decision Model · DecisionProgramming.jl"/><meta name="description" content="Documentation for DecisionProgramming.jl."/><meta property="og:description" content="Documentation for DecisionProgramming.jl."/><meta property="twitter:description" content="Documentation for DecisionProgramming.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DecisionProgramming.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li><a class="tocitem" href="../influence-diagram/">Influence Diagram</a></li><li><a class="tocitem" href="../paths/">Paths</a></li><li class="is-active"><a class="tocitem" href>Decision Model</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Decision-Variables"><span>Decision Variables</span></a></li><li><a class="tocitem" href="#Path-Compatibility-Variables"><span>Path Compatibility Variables</span></a></li><li><a class="tocitem" href="#Lazy-Probability-Cut"><span>Lazy Probability Cut</span></a></li><li><a class="tocitem" href="#Single-Policy-Update"><span>Single Policy Update</span></a></li><li><a class="tocitem" href="#Expected-Value"><span>Expected Value</span></a></li><li><a class="tocitem" href="#Positive-and-Negative-Path-Utilities"><span>Positive and Negative Path Utilities</span></a></li><li><a class="tocitem" href="#Conditional-Value-at-Risk"><span>Conditional Value-at-Risk</span></a></li><li><a class="tocitem" href="#Convex-Combination"><span>Convex Combination</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../analyzing-decision-strategies/">Analyzing Decision Strategies</a></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><a class="tocitem" href="../../usage/">Usage</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li><li><a class="tocitem" href="../../examples/CHD_preventative_care/">CHD preventative care allocation</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Decision Model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Decision Model</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/gamma-opt/DecisionProgramming.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/decision-model.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="decision-model"><a class="docs-heading-anchor" href="#decision-model">Decision Model</a><a id="decision-model-1"></a><a class="docs-heading-anchor-permalink" href="#decision-model" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p><strong>Decision Programming</strong> aims to find an optimal decision strategy <span>$Z$</span> among all decision strategies <span>$ℤ$</span> by maximizing an objective function <span>$f$</span> on the path distribution of an influence diagram</p><p class="math-container">\[\underset{Z∈ℤ}{\text{maximize}}\quad f(\{(ℙ(X=𝐬∣Z), \mathcal{U}(𝐬)) ∣ 𝐬∈𝐒\}). \tag{1}\]</p><p><strong>Decision model</strong> refers to the mixed-integer linear programming formulation of this optimization problem. This page explains how to express decision strategies, compatible paths, path utilities and the objective of the model as a mixed-integer linear program. We present two standard objective functions, including expected value and conditional value-at-risk. The original decision model formulation was described in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, sections 3 and 5. We base the decision model on an improved formulation described in <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> section 3.3. We recommend reading the references for motivation, details, and proofs of the formulation.</p><h2 id="Decision-Variables"><a class="docs-heading-anchor" href="#Decision-Variables">Decision Variables</a><a id="Decision-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Variables" title="Permalink"></a></h2><p><strong>Decision variables</strong> <span>$z(s_j∣𝐬_{I(j)})$</span> are equivalent to local decision strategies such that <span>$Z_j(𝐬_{I(j)})=s_j$</span> if and only if <span>$z(s_j∣𝐬_{I(j)})=1$</span> and <span>$z(s_{j}^′∣𝐬_{I(j)})=0$</span> for all <span>$s_{j}^′∈S_j∖s_j.$</span> Constraint <span>$(2)$</span> defines the decisions to be binary variables and the constraint <span>$(3)$</span> states that only one decision alternative <span>$s_{j}$</span> can be chosen for each information set <span>$s_{I(j)}$</span>.</p><p class="math-container">\[z(s_j∣𝐬_{I(j)}) ∈ \{0,1\},\quad ∀j∈D, s_j∈S_j, 𝐬_{I(j)}∈𝐒_{I(j)} \tag{2}\]</p><p class="math-container">\[∑_{s_j∈S_j} z(s_j∣𝐬_{I(j)})=1,\quad ∀j∈D, 𝐬_{I(j)}∈𝐒_{I(j)} \tag{3}\]</p><h2 id="Path-Compatibility-Variables"><a class="docs-heading-anchor" href="#Path-Compatibility-Variables">Path Compatibility Variables</a><a id="Path-Compatibility-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Compatibility-Variables" title="Permalink"></a></h2><p><strong>Path compatibility variables</strong> <span>$x(𝐬)$</span> are indicator variables for whether path <span>$𝐬$</span> is compatible with decision strategy <span>$Z$</span> defined by the decision variables <span>$z$</span>. These are continous variables but only assume binary values, so that the compatible paths <span>$𝐬 ∈ 𝐒(Z)$</span> take values <span>$x(𝐬) = 1$</span> and other paths <span>$𝐬 ∈ 𝐒 \setminus 𝐒(Z)$</span> take values <span>$x(𝐬) = 0$</span>. Constraint <span>$(4)$</span> defines the lower and upper bounds for the variables.</p><p class="math-container">\[0≤x(𝐬)≤1,\quad ∀𝐬∈𝐒 \tag{4}\]</p><p>Constraint <span>$(5)$</span> ensures that only the variables associated with locally compatible paths <span>$𝐬 \in 𝐒_{s_j | 𝐬_{I(j)} }$</span> of the decision strategy can take value <span>$x(𝐬) = 1$</span>. The effective locally compatible paths are denoted with <span>$| 𝐒^*_{s_j | 𝐬_{I(j)}}|$</span>. The upper bound of the constraint uses the minimum of the <em>feasible paths</em> upper bound and the <em>theoretical</em> upper bound. The motivation of the feasible paths upper bound is below. For proofs and motivation on the theoretical upper bound see reference <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>.</p><p class="math-container">\[∑_{𝐬 \in 𝐒^*_{s_j | 𝐬_{I(j)}} } x(𝐬) \leq \min ( \ | 𝐒^*_{s_j | 𝐬_{I(j)}}|, \ \frac{| 𝐒_{s_j | 𝐬_{I(j)}}| }{\displaystyle  \prod_{d \in D \setminus \{j, I(j)\}} |𝐒_d|} \ ) \ z(s_j∣𝐬_{I(j)}),\quad \forall j \in D, s_j \in S_j, 𝐬_{I(j)} \in 𝐒_{I(j)} \tag{5}\]</p><p>Constraint <span>$(6)$</span> is called the probability cut constraint and it defines that the sum of the path probabilities of the compatible paths must equal one.</p><p class="math-container">\[∑_{𝐬∈𝐒}x(𝐬) p(𝐬) = 1 \tag{6}\]</p><h3 id="Feasible-paths-upper-bound"><a class="docs-heading-anchor" href="#Feasible-paths-upper-bound">Feasible paths upper bound</a><a id="Feasible-paths-upper-bound-1"></a><a class="docs-heading-anchor-permalink" href="#Feasible-paths-upper-bound" title="Permalink"></a></h3><p>The <em>feasible paths upper bound</em> for the path compatibility variables is</p><p class="math-container">\[∑_{𝐬 \in 𝐒^*_{s_j | 𝐬_{I(j)}} } x(𝐬) \leq  | 𝐒^*_{s_j | 𝐬_{I(j)}}| \ z(s_j∣𝐬_{I(j)}),\quad \forall j \in D, s_j \in S_j, 𝐬_{I(j)} \in 𝐒_{I(j)}\]</p><p>where <span>$𝐒^*_{s_j | s_{I(j)}}$</span> is the set of effective locally compatible paths. This upper bound is motivated by the implementation of the framework in which path compatibility variables <span>$x(𝐬)$</span> are only generated for effective paths <span>$𝐬 \in 𝐒^∗$</span>. The ineffective paths are not generated because they do not influence the objective function and having less variables reduces the size of the model.</p><p>Therefore, if the model has ineffective paths <span>$𝐬 \in 𝐒^′$</span>, then the number of effective paths is less than the number of all paths.</p><p class="math-container">\[|𝐒^*| &lt; |𝐒|\]</p><p>Therefore,</p><p class="math-container">\[|𝐒^*_{s_j | 𝐬_{I(j)}} | &lt; | 𝐒_{s_j | 𝐬_{I(j)}}| .\]</p><p>The feasible paths upper bound is used in conjunction with the <em>theoretical upper bound</em> as follows.</p><p class="math-container">\[∑_{𝐬 \in 𝐒^*_{s_j | 𝐬_{I(j)}} } x(𝐬) \leq \min ( \ | 𝐒^*_{s_j | 𝐬_{I(j)}}|, \ \frac{| 𝐒_{s_j | 𝐬_{I(j)}}| }{\displaystyle  \prod_{d \in D \setminus \{j, I(j)\}} |𝐒_d|} \ ) \ z(s_j∣𝐬_{I(j)}),\quad \forall j \in D, s_j \in S_j, 𝐬_{I(j)} \in 𝐒_{I(j)}\]</p><p>The motivation for using the minimum of these bounds is that it depends on the problem structure which one is tighter. The feasible paths upper bound may be tighter if the set of ineffective paths is large compared to the number of all paths.</p><h2 id="Lazy-Probability-Cut"><a class="docs-heading-anchor" href="#Lazy-Probability-Cut">Lazy Probability Cut</a><a id="Lazy-Probability-Cut-1"></a><a class="docs-heading-anchor-permalink" href="#Lazy-Probability-Cut" title="Permalink"></a></h2><p>Constraint <span>$(6)$</span> is a complicating constraint involving all path compatibility variables <span>$x(s)$</span> and thus adding it directly to the model may slow down the overall solution process. It may be beneficial to instead add it as a <em>lazy constraint</em>. In the solver, a lazy constraint is only generated when an incumbent solution violates it. In some instances, this allows the MILP solver to prune nodes of the branch-and-bound tree more efficiently.</p><h2 id="Single-Policy-Update"><a class="docs-heading-anchor" href="#Single-Policy-Update">Single Policy Update</a><a id="Single-Policy-Update-1"></a><a class="docs-heading-anchor-permalink" href="#Single-Policy-Update" title="Permalink"></a></h2><p>To obtain (hopefully good) starting solutions, the SPU heuristic described in <sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup> can be used. The heuristic finds a locally optimal strategy in the sense that the strategy cannot be improved by changing any single local strategy. With large problems, the heuristic can quickly provide a solution that would otherwise take very long to obtain.</p><h2 id="Expected-Value"><a class="docs-heading-anchor" href="#Expected-Value">Expected Value</a><a id="Expected-Value-1"></a><a class="docs-heading-anchor-permalink" href="#Expected-Value" title="Permalink"></a></h2><p>The <strong>expected value</strong> objective is defined using the path compatibility variables <span>$x(𝐬)$</span> and their associated path probabilities <span>$p(𝐬)$</span> and path utilities <span>$\mathcal{U}(𝐬)$</span>.</p><p class="math-container">\[\operatorname{E}(Z) = ∑_{𝐬∈𝐒} x(𝐬) \ p(𝐬) \ \mathcal{U}(𝐬). \tag{7}\]</p><h2 id="Positive-and-Negative-Path-Utilities"><a class="docs-heading-anchor" href="#Positive-and-Negative-Path-Utilities">Positive and Negative Path Utilities</a><a id="Positive-and-Negative-Path-Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Positive-and-Negative-Path-Utilities" title="Permalink"></a></h2><p>We can omit the probability cut defined in constraint <span>$(6)$</span> from the model if we are maximising expected value of utility and use a <strong>positive path utility</strong> function <span>$\mathcal{U}^+$</span>. Similarly, we can use a <strong>negative path utility</strong> function <span>$\mathcal{U}^-$</span> when minimizing expected value. These functions are affine transformations of the path utility function <span>$\mathcal{U}$</span> which translate all utility values to positive/negative values. As an example of a positive path utility function, we can subtract the minimum of the original utility function and then add one as follows.</p><p class="math-container">\[\mathcal{U}^+(𝐬) = \mathcal{U}(𝐬) - \min_{𝐬∈𝐒} \mathcal{U}(𝐬) + 1. \tag{8}\]</p><p class="math-container">\[\mathcal{U}^-(𝐬) = \mathcal{U}(𝐬) - \max_{𝐬∈𝐒} \mathcal{U}(𝐬) - 1. \tag{9}\]</p><h2 id="Conditional-Value-at-Risk"><a class="docs-heading-anchor" href="#Conditional-Value-at-Risk">Conditional Value-at-Risk</a><a id="Conditional-Value-at-Risk-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-Value-at-Risk" title="Permalink"></a></h2><p>The section <a href="../analyzing-decision-strategies/#Measuring-Risk">Measuring Risk</a> explains and visualizes the relationships between the formulation of expected value, value-at-risk and conditional value-at-risk for discrete probability distribution.</p><p>Given decision strategy <span>$Z,$</span> we define the cumulative distribution of compatible paths&#39; probabilities as</p><p class="math-container">\[F_Z(t) = ∑_{𝐬∈𝐒∣\mathcal{U}(𝐬)≤t} x(𝐬) p(𝐬).\]</p><p>Given a <strong>probability level</strong> <span>$α∈(0, 1],$</span> we define the <strong>value-at-risk</strong> as</p><p class="math-container">\[\operatorname{VaR}_α(Z)=u_α=\sup \{\mathcal{U}(𝐬)∣𝐬∈𝐒, F_Z(\mathcal{U}(𝐬))&lt;α\}.\]</p><p>Then, we have the paths that have path utility less than and equal to the value-at-risk as</p><p class="math-container">\[𝐒_{α}^{&lt;}=\{𝐬∈𝐒∣\mathcal{U}(𝐬)&lt;u_α\},\]</p><p class="math-container">\[𝐒_{α}^{=}=\{𝐬∈𝐒∣\mathcal{U}(𝐬)=u_α\}.\]</p><p>We define <strong>conditional value-at-risk</strong> as</p><p class="math-container">\[\operatorname{CVaR}_α(Z)=\frac{1}{α}\left(∑_{𝐬∈𝐒_α^{&lt;}} x(𝐬) \ p(𝐬) \ \mathcal{U}(𝐬) + \left(α - ∑_{𝐬&#39;∈𝐒_α^{&lt;}} x(𝐬&#39;) \ p(𝐬&#39;) \right) u_α \right).\]</p><p>We can form the conditional value-at-risk as an optimization problem. We have the following pre-computed parameters.</p><p>Lower and upper bound of the value-at-risk</p><p class="math-container">\[\operatorname{VaR}_0(Z)=u^-=\min\{\mathcal{U}(𝐬)∣𝐬∈𝐒\}, \tag{11}\]</p><p class="math-container">\[\operatorname{VaR}_1(Z)=u^+=\max\{\mathcal{U}(𝐬)∣𝐬∈𝐒\}. \tag{12}\]</p><p>A &quot;large number&quot;, specifically the largest difference between path utilities</p><p class="math-container">\[M=u^+-u^-. \tag{13}\]</p><p>A &quot;small number&quot;, specifically half of the smallest positive difference between path utilities</p><p class="math-container">\[ϵ=\frac{1}{2} \min\{|\mathcal{U}(𝐬)-\mathcal{U}(𝐬^′)| \mid |\mathcal{U}(𝐬)-\mathcal{U}(𝐬^′)| &gt; 0, 𝐬, 𝐬^′∈𝐒\}. \tag{14}\]</p><p>The objective is to minimize the variable <span>$η$</span> whose optimal value is equal to the value-at-risk, that is, <span>$\operatorname{VaR}_α(Z)=\min η.$</span></p><p>We define the constraints as follows:</p><p class="math-container">\[η-\mathcal{U}(𝐬)≤M λ(𝐬),\quad ∀𝐬∈𝐒 \tag{14}\]</p><p class="math-container">\[η-\mathcal{U}(𝐬)≥(M+ϵ) λ(𝐬) - M,\quad ∀𝐬∈𝐒 \tag{15}\]</p><p class="math-container">\[η-\mathcal{U}(𝐬)≤(M+ϵ) \bar{λ}(𝐬) - ϵ,\quad ∀𝐬∈𝐒 \tag{16}\]</p><p class="math-container">\[η-\mathcal{U}(𝐬)≥M (\bar{λ}(𝐬) - 1),\quad ∀𝐬∈𝐒 \tag{17}\]</p><p class="math-container">\[\bar{ρ}(𝐬) ≤ \bar{λ}(𝐬),\quad ∀𝐬∈𝐒 \tag{18}\]</p><p class="math-container">\[x(𝐬) \ p(𝐬) - (1 - λ(𝐬)) ≤ ρ(𝐬) ≤ λ(𝐬),\quad ∀𝐬∈𝐒 \tag{19}\]</p><p class="math-container">\[ρ(𝐬) ≤ \bar{ρ}(𝐬) ≤ x(𝐬) \ p(𝐬),\quad ∀𝐬∈𝐒 \tag{20}\]</p><p class="math-container">\[∑_{𝐬∈𝐒}\bar{ρ}(𝐬) = α \tag{21}\]</p><p class="math-container">\[\bar{λ}(𝐬), λ(𝐬)∈\{0, 1\},\quad ∀𝐬∈𝐒 \tag{22}\]</p><p class="math-container">\[\bar{ρ}(𝐬),ρ(𝐬)∈[0, 1],\quad ∀𝐬∈𝐒 \tag{23}\]</p><p class="math-container">\[η∈[u^-, u^+] \tag{24}\]</p><p>We can express the conditional value-at-risk objective as</p><p class="math-container">\[\operatorname{CVaR}_α(Z)=\frac{1}{α}∑_{𝐬∈𝐒}\bar{ρ}(𝐬) \mathcal{U}(𝐬)\tag{25}.\]</p><h2 id="Convex-Combination"><a class="docs-heading-anchor" href="#Convex-Combination">Convex Combination</a><a id="Convex-Combination-1"></a><a class="docs-heading-anchor-permalink" href="#Convex-Combination" title="Permalink"></a></h2><p>We can combine expected value and conditional value-at-risk using a convex combination at a fixed probability level <span>$α∈(0, 1]$</span> as follows</p><p class="math-container">\[w \operatorname{E}(Z) + (1-w) \operatorname{CVaR}_α(Z), \tag{26}\]</p><p>where the parameter <span>$w∈[0, 1]$</span> expresses the decision maker&#39;s <strong>risk tolerance</strong>.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Salo, A., Andelmin, J., &amp; Oliveira, F. (2022). Decision programming for mixed-integer multi-stage optimization under uncertainty. European Journal of Operational Research, 299(2), 550-565.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Hölsä, O. (2020). Decision Programming Framework for Evaluating Testing Costs of Disease-Prone Pigs. Retrieved from <a href="http://urn.fi/URN:NBN:fi:aalto-202009295618">http://urn.fi/URN:NBN:fi:aalto-202009295618</a></li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Hankimaa, H., Herrala, O., Oliveira, F., Tollander de Balsch, J. (2023). DecisionProgramming.jl – A framework for modelling decision problems using mathematical programming. Retrieved from <a href="https://arxiv.org/abs/2307.13299">https://arxiv.org/abs/2307.13299</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../paths/">« Paths</a><a class="docs-footer-nextpage" href="../analyzing-decision-strategies/">Analyzing Decision Strategies »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.6.0 on <span class="colophon-date" title="Wednesday 21 August 2024 12:30">Wednesday 21 August 2024</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

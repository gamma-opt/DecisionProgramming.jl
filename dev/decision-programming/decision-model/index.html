<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Decision Model Â· DecisionProgramming.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DecisionProgramming.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li><a class="tocitem" href="../influence-diagram/">Influence Diagram</a></li><li><a class="tocitem" href="../paths/">Paths</a></li><li class="is-active"><a class="tocitem" href>Decision Model</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Decision-Variables"><span>Decision Variables</span></a></li><li><a class="tocitem" href="#Path-Compatibility-Variables"><span>Path Compatibility Variables</span></a></li><li><a class="tocitem" href="#Lazy-Probability-Cut"><span>Lazy Probability Cut</span></a></li><li><a class="tocitem" href="#Expected-Value"><span>Expected Value</span></a></li><li><a class="tocitem" href="#Positive-and-Negative-Path-Utilities"><span>Positive and Negative Path Utilities</span></a></li><li><a class="tocitem" href="#Conditional-Value-at-Risk"><span>Conditional Value-at-Risk</span></a></li><li><a class="tocitem" href="#Convex-Combination"><span>Convex Combination</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../analyzing-decision-strategies/">Analyzing Decision Strategies</a></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><a class="tocitem" href="../../usage/">Usage</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li><li><a class="tocitem" href="../../examples/CHD_preventative_care/">CHD preventative care allocation</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Decision Model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Decision Model</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/decision-model.md" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="decision-model"><a class="docs-heading-anchor" href="#decision-model">Decision Model</a><a id="decision-model-1"></a><a class="docs-heading-anchor-permalink" href="#decision-model" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p><strong>Decision Programming</strong> aims to find an optimal decision strategy <span>$Z$</span> among all decision strategies <span>$â„¤$</span> by maximizing an objective function <span>$f$</span> on the path distribution of an influence diagram</p><p class="math-container">\[\underset{Zâˆˆâ„¤}{\text{maximize}}\quad f(\{(â„™(X=ğ¬âˆ£Z), \mathcal{U}(ğ¬)) âˆ£ ğ¬âˆˆğ’\}). \tag{1}\]</p><p><strong>Decision model</strong> refers to the mixed-integer linear programming formulation of this optimization problem. This page explains how to express decision strategies, compatible paths, path utilities and the objective of the model as a mixed-integer linear program. We present two standard objective functions, including expected value and conditional value-at-risk. The original decision model formulation was described in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, sections 3 and 5. We base the decision model on an improved formulation described in <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> section 3.3. We recommend reading the references for motivation, details, and proofs of the formulation.</p><h2 id="Decision-Variables"><a class="docs-heading-anchor" href="#Decision-Variables">Decision Variables</a><a id="Decision-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Variables" title="Permalink"></a></h2><p><strong>Decision variables</strong> <span>$z(s_jâˆ£ğ¬_{I(j)})$</span> are equivalent to local decision strategies such that <span>$Z_j(ğ¬_{I(j)})=s_j$</span> if and only if <span>$z(s_jâˆ£ğ¬_{I(j)})=1$</span> and <span>$z(s_{j}^â€²âˆ£ğ¬_{I(j)})=0$</span> for all <span>$s_{j}^â€²âˆˆS_jâˆ–s_j.$</span> Constraint <span>$(2)$</span> defines the decisions to be binary variables and the constraint <span>$(3)$</span> states that only one decision alternative <span>$s_{j}$</span> can be chosen for each information set <span>$s_{I(j)}$</span>.</p><p class="math-container">\[z(s_jâˆ£ğ¬_{I(j)}) âˆˆ \{0,1\},\quad âˆ€jâˆˆD, s_jâˆˆS_j, ğ¬_{I(j)}âˆˆğ’_{I(j)} \tag{2}\]</p><p class="math-container">\[âˆ‘_{s_jâˆˆS_j} z(s_jâˆ£ğ¬_{I(j)})=1,\quad âˆ€jâˆˆD, ğ¬_{I(j)}âˆˆğ’_{I(j)} \tag{3}\]</p><h2 id="Path-Compatibility-Variables"><a class="docs-heading-anchor" href="#Path-Compatibility-Variables">Path Compatibility Variables</a><a id="Path-Compatibility-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Compatibility-Variables" title="Permalink"></a></h2><p><strong>Path compatibility variables</strong> <span>$x(ğ¬)$</span> are indicator variables for whether path <span>$ğ¬$</span> is compatible with decision strategy <span>$Z$</span> defined by the decision variables <span>$z$</span>. These are continous variables but only assume binary values, so that the compatible paths <span>$ğ¬ âˆˆ ğ’(Z)$</span> take values <span>$x(ğ¬) = 1$</span> and other paths <span>$ğ¬ âˆˆ ğ’ \setminus ğ’(Z)$</span> take values <span>$x(ğ¬) = 0$</span>. Constraint <span>$(4)$</span> defines the lower and upper bounds for the variables.</p><p class="math-container">\[0â‰¤x(ğ¬)â‰¤1,\quad âˆ€ğ¬âˆˆğ’ \tag{4}\]</p><p>Constraint <span>$(5)$</span> ensures that only the variables associated with locally compatible paths <span>$ğ¬ \in ğ’_{s_j | ğ¬_{I(j)} }$</span> of the decision strategy can take value <span>$x(ğ¬) = 1$</span>. The effective locally compatible paths are denoted with <span>$| ğ’^*_{s_j | ğ¬_{I(j)}}|$</span>. The upper bound of the constraint uses the minimum of the <em>feasible paths</em> upper bound and the <em>theoretical</em> upper bound. The motivation of the feasible paths upper bound is below. For proofs and motivation on the theoretical upper bound see reference <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>.</p><p class="math-container">\[âˆ‘_{ğ¬ \in ğ’^*_{s_j | ğ¬_{I(j)}} } x(ğ¬) \leq \min ( \ | ğ’^*_{s_j | ğ¬_{I(j)}}|, \ \frac{| ğ’_{s_j | ğ¬_{I(j)}}| }{\displaystyle  \prod_{d \in D \setminus \{j, I(j)\}} |ğ’_d|} \ ) \ z(s_jâˆ£ğ¬_{I(j)}),\quad \forall j \in D, s_j \in S_j, ğ¬_{I(j)} \in ğ’_{I(j)} \tag{5}\]</p><p>Constraint <span>$(6)$</span> is called the probability cut constraint and it defines that the sum of the path probabilities of the compatible paths must equal one.</p><p class="math-container">\[âˆ‘_{ğ¬âˆˆğ’}x(ğ¬) p(ğ¬) = 1 \tag{6}\]</p><h3 id="Feasible-paths-upper-bound"><a class="docs-heading-anchor" href="#Feasible-paths-upper-bound">Feasible paths upper bound</a><a id="Feasible-paths-upper-bound-1"></a><a class="docs-heading-anchor-permalink" href="#Feasible-paths-upper-bound" title="Permalink"></a></h3><p>The <em>feasible paths upper bound</em> for the path compatibility variables is</p><p class="math-container">\[âˆ‘_{ğ¬ \in ğ’^*_{s_j | ğ¬_{I(j)}} } x(ğ¬) \leq  | ğ’^*_{s_j | ğ¬_{I(j)}}| \ z(s_jâˆ£ğ¬_{I(j)}),\quad \forall j \in D, s_j \in S_j, ğ¬_{I(j)} \in ğ’_{I(j)}\]</p><p>where <span>$ğ’^*_{s_j | s_{I(j)}}$</span> is the set of effective locally compatible paths. This upper bound is motivated by the implementation of the framework in which path compatibility variables <span>$x(ğ¬)$</span> are only generated for effective paths <span>$ğ¬ \in ğ’^âˆ—$</span>. The ineffective paths are not generated because they do not influence the objective function and having less variables reduces the size of the model.</p><p>Therefore, if the model has ineffective paths <span>$ğ¬ \in ğ’^â€²$</span>, then the number of effective paths is less than the number of all paths.</p><p class="math-container">\[|ğ’^*| &lt; |ğ’|\]</p><p>Therefore,</p><p class="math-container">\[|ğ’^*_{s_j | ğ¬_{I(j)}} | &lt; | ğ’_{s_j | ğ¬_{I(j)}}| .\]</p><p>The feasible paths upper bound is used in conjunction with the <em>theoretical upper bound</em> as follows.</p><p class="math-container">\[âˆ‘_{ğ¬ \in ğ’^*_{s_j | ğ¬_{I(j)}} } x(ğ¬) \leq \min ( \ | ğ’^*_{s_j | ğ¬_{I(j)}}|, \ \frac{| ğ’_{s_j | ğ¬_{I(j)}}| }{\displaystyle  \prod_{d \in D \setminus \{j, I(j)\}} |ğ’_d|} \ ) \ z(s_jâˆ£ğ¬_{I(j)}),\quad \forall j \in D, s_j \in S_j, ğ¬_{I(j)} \in ğ’_{I(j)}\]</p><p>The motivation for using the minimum of these bounds is that it depends on the problem structure which one is tighter. The feasible paths upper bound may be tighter if the set of ineffective paths is large compared to the number of all paths.</p><h2 id="Lazy-Probability-Cut"><a class="docs-heading-anchor" href="#Lazy-Probability-Cut">Lazy Probability Cut</a><a id="Lazy-Probability-Cut-1"></a><a class="docs-heading-anchor-permalink" href="#Lazy-Probability-Cut" title="Permalink"></a></h2><p>Constraint <span>$(6)$</span> is a complicating constraint involving all path compatibility variables <span>$x(s)$</span> and thus adding it directly to the model may slow down the overall solution process. It may be beneficial to instead add it as a <em>lazy constraint</em>. In the solver, a lazy constraint is only generated when an incumbent solution violates it. In some instances, this allows the MILP solver to prune nodes of the branch-and-bound tree more efficiently.</p><h2 id="Expected-Value"><a class="docs-heading-anchor" href="#Expected-Value">Expected Value</a><a id="Expected-Value-1"></a><a class="docs-heading-anchor-permalink" href="#Expected-Value" title="Permalink"></a></h2><p>The <strong>expected value</strong> objective is defined using the path compatibility variables <span>$x(ğ¬)$</span> and their associated path probabilities <span>$p(ğ¬)$</span> and path utilities <span>$\mathcal{U}(ğ¬)$</span>.</p><p class="math-container">\[\operatorname{E}(Z) = âˆ‘_{ğ¬âˆˆğ’} x(ğ¬) \ p(ğ¬) \ \mathcal{U}(ğ¬). \tag{7}\]</p><h2 id="Positive-and-Negative-Path-Utilities"><a class="docs-heading-anchor" href="#Positive-and-Negative-Path-Utilities">Positive and Negative Path Utilities</a><a id="Positive-and-Negative-Path-Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Positive-and-Negative-Path-Utilities" title="Permalink"></a></h2><p>We can omit the probability cut defined in constraint <span>$(6)$</span> from the model if we are maximising expected value of utility and use a <strong>positive path utility</strong> function <span>$\mathcal{U}^+$</span>. Similarly, we can use a <strong>negative path utility</strong> function <span>$\mathcal{U}^-$</span> when minimizing expected value. These functions are affine transformations of the path utility function <span>$\mathcal{U}$</span> which translate all utility values to positive/negative values. As an example of a positive path utility function, we can subtract the minimum of the original utility function and then add one as follows.</p><p class="math-container">\[\mathcal{U}^+(ğ¬) = \mathcal{U}(ğ¬) - \min_{ğ¬âˆˆğ’} \mathcal{U}(ğ¬) + 1. \tag{8}\]</p><p class="math-container">\[\mathcal{U}^-(ğ¬) = \mathcal{U}(ğ¬) - \max_{ğ¬âˆˆğ’} \mathcal{U}(ğ¬) - 1. \tag{9}\]</p><h2 id="Conditional-Value-at-Risk"><a class="docs-heading-anchor" href="#Conditional-Value-at-Risk">Conditional Value-at-Risk</a><a id="Conditional-Value-at-Risk-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-Value-at-Risk" title="Permalink"></a></h2><p>The section <a href="../analyzing-decision-strategies/#Measuring-Risk">Measuring Risk</a> explains and visualizes the relationships between the formulation of expected value, value-at-risk and conditional value-at-risk for discrete probability distribution.</p><p>Given decision strategy <span>$Z,$</span> we define the cumulative distribution of compatible paths&#39; probabilities as</p><p class="math-container">\[F_Z(t) = âˆ‘_{ğ¬âˆˆğ’âˆ£\mathcal{U}(ğ¬)â‰¤t} x(ğ¬) p(ğ¬).\]</p><p>Given a <strong>probability level</strong> <span>$Î±âˆˆ(0, 1],$</span> we define the <strong>value-at-risk</strong> as</p><p class="math-container">\[\operatorname{VaR}_Î±(Z)=u_Î±=\sup \{\mathcal{U}(ğ¬)âˆ£ğ¬âˆˆğ’, F_Z(\mathcal{U}(ğ¬))&lt;Î±\}.\]</p><p>Then, we have the paths that have path utility less than and equal to the value-at-risk as</p><p class="math-container">\[ğ’_{Î±}^{&lt;}=\{ğ¬âˆˆğ’âˆ£\mathcal{U}(ğ¬)&lt;u_Î±\},\]</p><p class="math-container">\[ğ’_{Î±}^{=}=\{ğ¬âˆˆğ’âˆ£\mathcal{U}(ğ¬)=u_Î±\}.\]</p><p>We define <strong>conditional value-at-risk</strong> as</p><p class="math-container">\[\operatorname{CVaR}_Î±(Z)=\frac{1}{Î±}\left(âˆ‘_{ğ¬âˆˆğ’_Î±^{&lt;}} x(ğ¬) \ p(ğ¬) \ \mathcal{U}(ğ¬) + \left(Î± - âˆ‘_{ğ¬&#39;âˆˆğ’_Î±^{&lt;}} x(ğ¬&#39;) \ p(ğ¬&#39;) \right) u_Î± \right).\]</p><p>We can form the conditional value-at-risk as an optimization problem. We have the following pre-computed parameters.</p><p>Lower and upper bound of the value-at-risk</p><p class="math-container">\[\operatorname{VaR}_0(Z)=u^-=\min\{\mathcal{U}(ğ¬)âˆ£ğ¬âˆˆğ’\}, \tag{11}\]</p><p class="math-container">\[\operatorname{VaR}_1(Z)=u^+=\max\{\mathcal{U}(ğ¬)âˆ£ğ¬âˆˆğ’\}. \tag{12}\]</p><p>A &quot;large number&quot;, specifically the largest difference between path utilities</p><p class="math-container">\[M=u^+-u^-. \tag{13}\]</p><p>A &quot;small number&quot;, specifically half of the smallest positive difference between path utilities</p><p class="math-container">\[Ïµ=\frac{1}{2} \min\{|\mathcal{U}(ğ¬)-\mathcal{U}(ğ¬^â€²)| \mid |\mathcal{U}(ğ¬)-\mathcal{U}(ğ¬^â€²)| &gt; 0, ğ¬, ğ¬^â€²âˆˆğ’\}. \tag{14}\]</p><p>The objective is to minimize the variable <span>$Î·$</span> whose optimal value is equal to the value-at-risk, that is, <span>$\operatorname{VaR}_Î±(Z)=\min Î·.$</span></p><p>We define the constraints as follows:</p><p class="math-container">\[Î·-\mathcal{U}(ğ¬)â‰¤M Î»(ğ¬),\quad âˆ€ğ¬âˆˆğ’ \tag{14}\]</p><p class="math-container">\[Î·-\mathcal{U}(ğ¬)â‰¥(M+Ïµ) Î»(ğ¬) - M,\quad âˆ€ğ¬âˆˆğ’ \tag{15}\]</p><p class="math-container">\[Î·-\mathcal{U}(ğ¬)â‰¤(M+Ïµ) \bar{Î»}(ğ¬) - Ïµ,\quad âˆ€ğ¬âˆˆğ’ \tag{16}\]</p><p class="math-container">\[Î·-\mathcal{U}(ğ¬)â‰¥M (\bar{Î»}(ğ¬) - 1),\quad âˆ€ğ¬âˆˆğ’ \tag{17}\]</p><p class="math-container">\[\bar{Ï}(ğ¬) â‰¤ \bar{Î»}(ğ¬),\quad âˆ€ğ¬âˆˆğ’ \tag{18}\]</p><p class="math-container">\[x(ğ¬) \ p(ğ¬) - (1 - Î»(ğ¬)) â‰¤ Ï(ğ¬) â‰¤ Î»(ğ¬),\quad âˆ€ğ¬âˆˆğ’ \tag{19}\]</p><p class="math-container">\[Ï(ğ¬) â‰¤ \bar{Ï}(ğ¬) â‰¤ x(ğ¬) \ p(ğ¬),\quad âˆ€ğ¬âˆˆğ’ \tag{20}\]</p><p class="math-container">\[âˆ‘_{ğ¬âˆˆğ’}\bar{Ï}(ğ¬) = Î± \tag{21}\]</p><p class="math-container">\[\bar{Î»}(ğ¬), Î»(ğ¬)âˆˆ\{0, 1\},\quad âˆ€ğ¬âˆˆğ’ \tag{22}\]</p><p class="math-container">\[\bar{Ï}(ğ¬),Ï(ğ¬)âˆˆ[0, 1],\quad âˆ€ğ¬âˆˆğ’ \tag{23}\]</p><p class="math-container">\[Î·âˆˆ[u^-, u^+] \tag{24}\]</p><p>We can express the conditional value-at-risk objective as</p><p class="math-container">\[\operatorname{CVaR}_Î±(Z)=\frac{1}{Î±}âˆ‘_{ğ¬âˆˆğ’}\bar{Ï}(ğ¬) \mathcal{U}(ğ¬)\tag{25}.\]</p><h2 id="Convex-Combination"><a class="docs-heading-anchor" href="#Convex-Combination">Convex Combination</a><a id="Convex-Combination-1"></a><a class="docs-heading-anchor-permalink" href="#Convex-Combination" title="Permalink"></a></h2><p>We can combine expected value and conditional value-at-risk using a convex combination at a fixed probability level <span>$Î±âˆˆ(0, 1]$</span> as follows</p><p class="math-container">\[w \operatorname{E}(Z) + (1-w) \operatorname{CVaR}_Î±(Z), \tag{26}\]</p><p>where the parameter <span>$wâˆˆ[0, 1]$</span> expresses the decision maker&#39;s <strong>risk tolerance</strong>.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Salo, A., Andelmin, J., &amp; Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1â€“35. Retrieved from <a href="http://arxiv.org/abs/1910.09196">http://arxiv.org/abs/1910.09196</a></li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>HÃ¶lsÃ¤, O. (2020). Decision Programming Framework for Evaluating Testing Costs of Disease-Prone Pigs. Retrieved from <a href="http://urn.fi/URN:NBN:fi:aalto-202009295618">http://urn.fi/URN:NBN:fi:aalto-202009295618</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../paths/">Â« Paths</a><a class="docs-footer-nextpage" href="../analyzing-decision-strategies/">Analyzing Decision Strategies Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Thursday 3 November 2022 07:32">Thursday 3 November 2022</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

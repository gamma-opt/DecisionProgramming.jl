<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Influence Diagram · DecisionProgramming.jl</title><meta name="title" content="Influence Diagram · DecisionProgramming.jl"/><meta property="og:title" content="Influence Diagram · DecisionProgramming.jl"/><meta property="twitter:title" content="Influence Diagram · DecisionProgramming.jl"/><meta name="description" content="Documentation for DecisionProgramming.jl."/><meta property="og:description" content="Documentation for DecisionProgramming.jl."/><meta property="twitter:description" content="Documentation for DecisionProgramming.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DecisionProgramming.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li class="is-active"><a class="tocitem" href>Influence Diagram</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Definition"><span>Definition</span></a></li><li><a class="tocitem" href="#Root-and-Leaf-Nodes"><span>Root and Leaf Nodes</span></a></li><li><a class="tocitem" href="#Drawing-Nodes-and-Arcs"><span>Drawing Nodes and Arcs</span></a></li><li><a class="tocitem" href="#Drawing-Layered-Graph"><span>Drawing Layered Graph</span></a></li><li><a class="tocitem" href="#Paths"><span>Paths</span></a></li><li><a class="tocitem" href="#Probabilities"><span>Probabilities</span></a></li><li><a class="tocitem" href="#Decision-Strategies"><span>Decision Strategies</span></a></li><li><a class="tocitem" href="#path-probability-doc"><span>Path Probability</span></a></li><li><a class="tocitem" href="#Consequences"><span>Consequences</span></a></li><li><a class="tocitem" href="#Path-Utility"><span>Path Utility</span></a></li><li><a class="tocitem" href="#Path-Distribution"><span>Path Distribution</span></a></li><li><a class="tocitem" href="#Other-Properties"><span>Other Properties</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../paths/">Paths</a></li><li><a class="tocitem" href="../decision-model/">Decision Model</a></li><li><a class="tocitem" href="../analyzing-decision-strategies/">Analyzing Decision Strategies</a></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><a class="tocitem" href="../../usage/">Usage</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li><li><a class="tocitem" href="../../examples/CHD_preventative_care/">CHD preventative care allocation</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Influence Diagram</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Influence Diagram</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/gamma-opt/DecisionProgramming.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/influence-diagram.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="influence-diagram"><a class="docs-heading-anchor" href="#influence-diagram">Influence Diagram</a><a id="influence-diagram-1"></a><a class="docs-heading-anchor-permalink" href="#influence-diagram" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>Decision programming uses influence diagrams, a generalization of Bayesian networks, to model multi-stage decision problems under uncertainty. This section defines the influence diagrams and discusses their properties. It is based on the definitions in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>, and <sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup>.</p><h2 id="Definition"><a class="docs-heading-anchor" href="#Definition">Definition</a><a id="Definition-1"></a><a class="docs-heading-anchor-permalink" href="#Definition" title="Permalink"></a></h2><p><img src="../figures/linear-graph.svg" alt/></p><p>We define the <strong>influence diagram</strong> as a directed, acyclic graph <span>$G=(C,D,V,A,S).$</span> We describe the nodes <span>$N=C∪D∪V$</span> with <span>$C∪D=\{1,...,n\}$</span> and <span>$n=|C|+|D|$</span> as follows:</p><ol><li><strong>Chance nodes</strong> <span>$C⊆\{1,...,n\}$</span> (circles) represent uncertain events associated with random variables.</li><li><strong>Decision nodes</strong> <span>$D⊆\{1,...,n\}$</span> (squares) correspond to decisions among discrete alternatives.</li><li><strong>Value nodes</strong> <span>$V=\{n+1,...,n+|V|\}$</span> (diamonds) represent consequences that result from the realizations of random variables at chance nodes and the decisions made at decision nodes.</li></ol><p>The connections between different nodes (arrows) are called <strong>arcs</strong> <span>$a \in A$</span>. The arcs represent different dependencies between the nodes.</p><p>We define the <strong>information set</strong> <span>$I$</span> of node <span>$j∈N$</span> as the set of predecessors of <span>$j$</span> in the graph:</p><p class="math-container">\[I(j)⊆\{i∈C∪D ∣ (i,j) \in A\, i&lt;j\}\]</p><p>Practically, the information set is a collection of arcs in the reverse direction in the graph. Informally, it tells us which node&#39;s information is available to the current node. The conditions enforce that the graph is acyclic, and there are no arcs from value nodes to other nodes.</p><p>In an influence diagram, each chance and decision node <span>$j∈C∪D$</span> is associates with a finite number of <strong>states</strong> <span>$S_j$</span> that we encode using integers <span>$S_j=\{1,...,|S_j|\}$</span> from one to number of states <span>$|S_j|≥1.$</span> A node <span>$j$</span> is <strong>trivial</strong> if it has only one state, <span>$|S_j|=1.$</span> We refer to the collection of all states <span>$S=\{S_1,...,S_n\}$</span> as the <strong>state space</strong>.</p><h2 id="Root-and-Leaf-Nodes"><a class="docs-heading-anchor" href="#Root-and-Leaf-Nodes">Root and Leaf Nodes</a><a id="Root-and-Leaf-Nodes-1"></a><a class="docs-heading-anchor-permalink" href="#Root-and-Leaf-Nodes" title="Permalink"></a></h2><p>A chance or decision node is a root node if it is not affected by other chance or decision nodes. Formally, node <span>$j∈C∪D$</span> is a <strong>root</strong> node if <span>$I(j)=∅.$</span></p><p>A chance or decision node is a leaf node if it does not affect other chance or decision nodes. Formally, node <span>$j∈C∪D$</span> is a <strong>leaf</strong> node if <span>$j∉I(i)$</span> for all <span>$i∈C∪D.$</span></p><h2 id="Drawing-Nodes-and-Arcs"><a class="docs-heading-anchor" href="#Drawing-Nodes-and-Arcs">Drawing Nodes and Arcs</a><a id="Drawing-Nodes-and-Arcs-1"></a><a class="docs-heading-anchor-permalink" href="#Drawing-Nodes-and-Arcs" title="Permalink"></a></h2><p><img src="../figures/node-types.svg" alt/></p><p>We use a <strong>circle</strong> to represent chance nodes, a <strong>square</strong> to represent decision nodes, and a <strong>diamond</strong> to represent value nodes. The symbol <span>$i$</span> represents the node&#39;s index and symbol <span>$S_i$</span> the states of the chance or decision node. We use the following colors and styling:</p><ul><li>Chance nodes: Fill color <code>F5F5F5</code> and line color <code>666666</code>.</li><li>Decision nodes: Fill color <code>D5E8D4</code> and line color <code>82B366</code></li><li>Value nodes: Fill color <code>FFE6CC</code> and line color <code>D79B00</code></li><li>Linewidth <code>2pt</code> and perimeter <code>2pt</code> (padding around the node).</li></ul><p>We represent directed arcs using arrows from a source node to a target node, colored with the target node&#39;s line color. We recommend <a href="https://www.diagrams.net/">diagrams.net</a> for drawing graphs.</p><h2 id="Drawing-Layered-Graph"><a class="docs-heading-anchor" href="#Drawing-Layered-Graph">Drawing Layered Graph</a><a id="Drawing-Layered-Graph-1"></a><a class="docs-heading-anchor-permalink" href="#Drawing-Layered-Graph" title="Permalink"></a></h2><p><img src="../figures/layered-graph.svg" alt/></p><p>We showed the influence diagram as a linear graph in the <a href="#Definition">Definition</a> section. We can also draw a more concise layered graph, which is better at displaying the influence relationship structure — only nodes at smaller depth influence nodes at greater depth. Also, root and leaf nodes are visible from the layered form.</p><p>We define the <strong>depth</strong> of a node <span>$j∈N$</span> as follows. Root nodes have a depth of one</p><p class="math-container">\[\operatorname{depth}(j)=1,\quad I(j)=∅.\]</p><p>Other nodes have a depth of one greater than the maximum depth of its predecessors</p><p class="math-container">\[\operatorname{depth}(j)=\max_{i∈I(j)} \operatorname{depth}(i) + 1,\quad I(j)≠∅.\]</p><p>We can then draw the layered graph by grouping the nodes by their depth, ordering the groups by increasing depth and increasing indices order within each group.</p><h2 id="Paths"><a class="docs-heading-anchor" href="#Paths">Paths</a><a id="Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Paths" title="Permalink"></a></h2><p><img src="../figures/paths.svg" alt/></p><p>In influence diagrams, paths represent realizations of states for chance and decision nodes. For example, the above tree represents generating all paths with states <span>$S_1=\{1,2\}$</span> and <span>$S_2=\{1,2,3\}.$</span></p><p>Formally, a <strong>path</strong> is a sequence of states</p><p class="math-container">\[𝐬=(s_1, s_2, ...,s_n)∈𝐒,\]</p><p>where a state <span>$s_i∈S_i$</span> is defined for all chance and decision nodes <span>$i∈C∪D.$</span> We denote the set of <strong>paths</strong> as</p><p class="math-container">\[𝐒=∏_{j∈C∪D} S_j=S_1×S_2×...×S_n.\]</p><p>We define a <strong>subpath</strong> of <span>$𝐬$</span> with <span>$A⊆C∪D$</span> as a subsequence</p><p class="math-container">\[𝐬_A=(𝐬_{i}∣i∈A)∈𝐒_A.\]</p><p>We denote the set of <strong>subpaths</strong> as</p><p class="math-container">\[𝐒_A=∏_{i∈A} S_i.\]</p><p>We define the <strong>number of paths</strong> as</p><p class="math-container">\[|𝐒_A|=∏_{i∈A}|S_i|.\]</p><p>As mentioned above, each node <span>$j∈N$</span> has an information set <span>$I(j)$</span>. A subpath, which is formed by the states of the nodes in the information set, is referred to as an <strong>information state</strong>  <span>$𝐬_{I(j)}$</span> of node <span>$j$</span>. The set of these subpaths is called the <strong>information states</strong> <span>$𝐒_{I(j)}$</span> of node <span>$j∈N.$</span></p><p>Also note that <span>$𝐒=𝐒_{C∪D},$</span> and <span>$𝐒_{i}=S_i$</span> and <span>$𝐬_i=s_i$</span> where <span>$i∈C∪D$</span> is an individual node.</p><h2 id="Probabilities"><a class="docs-heading-anchor" href="#Probabilities">Probabilities</a><a id="Probabilities-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilities" title="Permalink"></a></h2><p>Each chance node is associated with a set of discrete probability distributions over its states. Each of the probability distributions corresponds to one of the node&#39;s information states. Formally, for each chance node <span>$j∈C$</span>, we denote the <strong>probability</strong> of state <span>$s_j$</span> given information state <span>$𝐬_{I(j)}$</span> as</p><p class="math-container">\[ℙ(X_j=s_j∣X_{I(j)}=𝐬_{I(j)})∈[0, 1],\]</p><p>with</p><p class="math-container">\[∑_{s_j∈S_j} ℙ(X_j=s_j∣X_{I(j)}=𝐬_{I(j)}) = 1.\]</p><p>A chance state with a given information state is considered <strong>active</strong> if its probability is nonzero</p><p class="math-container">\[ℙ(X_j=s_j∣X_{I(j)}=𝐬_{I(j)})&gt;0.\]</p><p>Otherwise, it is <strong>inactive</strong>.</p><h2 id="Decision-Strategies"><a class="docs-heading-anchor" href="#Decision-Strategies">Decision Strategies</a><a id="Decision-Strategies-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Strategies" title="Permalink"></a></h2><p>Each decision strategy models how the decision maker chooses a state <span>$s_j∈S_j$</span> given an information state <span>$𝐬_{I(j)}$</span> at decision node <span>$j∈D.$</span> A decision node can be seen as a special type of chance node, such that the probability of the chosen state given an information state is fixed to one</p><p class="math-container">\[ℙ(X_j=s_j∣X_{I(j)}=𝐬_{I(j)})=1.\]</p><p>By definition, the probabilities for other states are zero.</p><p>Formally, for each decision node <span>$j∈D,$</span> a <strong>local decision strategy</strong> is a function that maps an information state <span>$𝐬_{I(j)}$</span> to a state <span>$s_j$</span></p><p class="math-container">\[Z_j:𝐒_{I(j)}↦S_j.\]</p><p>A <strong>decision strategy</strong> contains one local decision strategy for each decision node</p><p class="math-container">\[Z=\{Z_j∣j∈D\}.\]</p><p>The set of <strong>all decision strategies</strong> is denoted with <span>$ℤ.$</span></p><h2 id="path-probability-doc"><a class="docs-heading-anchor" href="#path-probability-doc">Path Probability</a><a id="path-probability-doc-1"></a><a class="docs-heading-anchor-permalink" href="#path-probability-doc" title="Permalink"></a></h2><p>The probability distributions at chance and decision nodes define the probability distribution over all paths <span>$𝐬∈𝐒,$</span> which depends on the decision strategy <span>$Z∈ℤ.$</span> We refer to it as the path probability</p><p class="math-container">\[ℙ(X=𝐬∣Z) = ∏_{j∈C∪D} ℙ(X_j=𝐬_j∣X_{I(j)}=𝐬_{I(j)}).\]</p><p>We can decompose the path probability into two parts</p><p class="math-container">\[ℙ(X=𝐬∣Z) = p(𝐬) q(𝐬∣Z).\]</p><p>The first part consists of the probability contributed by the chance nodes. We refer to it as the <strong>upper bound of path probability</strong></p><p class="math-container">\[p(𝐬) = ∏_{j∈C} ℙ(X_j=𝐬_j∣X_{I(j)}=𝐬_{I(j)}).\]</p><p>The second part consists of the probability contributed by the decision nodes.</p><p class="math-container">\[q(𝐬∣Z) = ∏_{j∈D} ℙ(X_j=𝐬_j∣X_{I(j)}=𝐬_{I(j)}).\]</p><p>Because the probabilities of decision nodes are defined as one or zero depending on the decision strategy, we can simplify the second part to an indicator function</p><p class="math-container">\[q(𝐬∣Z)=\begin{cases}
1, &amp; x(𝐬) = 1 \\
0, &amp; \text{otherwise}
\end{cases}.\]</p><p>The binary variable <span>$x(𝐬)$</span> indicates whether a decision stategy is <strong>compatible</strong> with the path <span>$𝐬,$</span> that is, if each local decision strategy chooses a state on the path. Using the indicator function <span>$I(.)$</span> whose value is 1 if the expression inside is <em>true</em> and 0 otherwise, we have</p><p class="math-container">\[x(𝐬) = \prod_{j∈D} I(Z_j(𝐬_{I(j)})=𝐬_j).\]</p><p>Now the <strong>path probability</strong> equals the upper bound if the path is compatible with given decision strategy. Otherwise, the path probability is zero. Formally, we have</p><p class="math-container">\[ℙ(𝐬∣X,Z)=
\begin{cases}
p(𝐬), &amp; x(𝐬) = 1 \\
0, &amp; \text{otherwise}
\end{cases}.\]</p><h2 id="Consequences"><a class="docs-heading-anchor" href="#Consequences">Consequences</a><a id="Consequences-1"></a><a class="docs-heading-anchor-permalink" href="#Consequences" title="Permalink"></a></h2><p>For each value node <span>$j∈V$</span>, we define the <strong>consequence</strong> given information state <span>$𝐬_{I(j)}$</span> as</p><p class="math-container">\[Y_j:𝐒_{I(j)}↦ℂ,\]</p><p>where <span>$ℂ$</span> is the set of real-valued consequences.</p><h2 id="Path-Utility"><a class="docs-heading-anchor" href="#Path-Utility">Path Utility</a><a id="Path-Utility-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Utility" title="Permalink"></a></h2><p>The <strong>utility function</strong> is a function that maps consequences to real-valued utility</p><p class="math-container">\[U:ℂ^{|V|}↦ℝ.\]</p><p>The <strong>path utility</strong> is defined as the utility function acting on the consequences of value nodes given their information states</p><p class="math-container">\[\mathcal{U}(𝐬) = U(\{Y_j(𝐬_{I(j)}) ∣ j∈V\}).\]</p><p>The <strong>default path utility</strong> is the sum of node utilities <span>$U_j$</span></p><p class="math-container">\[\mathcal{U}(𝐬) = ∑_{j∈V} U_j(Y_j(𝐬_{I(j)})).\]</p><p>The utility function affects the objectives discussed on the <a href="../decision-model/#decision-model">Decision Model</a> page. We can choose the utility function such that the path utility function either returns:</p><ul><li>a numerical value, which leads to a mixed-integer linear programming (MILP) formulation or</li><li>a linear function with real and integer-valued variables, which leads to a mixed-integer quadratic programming (MIQP) formulation.</li></ul><p>Different formulations require a solver capable of solving them.</p><h2 id="Path-Distribution"><a class="docs-heading-anchor" href="#Path-Distribution">Path Distribution</a><a id="Path-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Distribution" title="Permalink"></a></h2><p>A <strong>path distribution</strong> is a pair</p><p class="math-container">\[(ℙ(X=𝐬∣Z), \mathcal{U}(𝐬))\]</p><p>that comprises of a path probability function and a path utility function over paths <span>$𝐬∈𝐒$</span> conditional to the decision strategy <span>$Z.$</span></p><h2 id="Other-Properties"><a class="docs-heading-anchor" href="#Other-Properties">Other Properties</a><a id="Other-Properties-1"></a><a class="docs-heading-anchor-permalink" href="#Other-Properties" title="Permalink"></a></h2><p>In this section, we define more properties for influence diagrams.</p><p><strong>Discrete</strong> influence diagram refers to a countable state space. Otherwise, the influence diagram is <strong>continuous</strong>. We can discretize continuous influence diagrams using discrete bins.</p><p>Two nodes are <strong>sequential</strong> if there exists a directed path from one node to the other in the influence diagram. Otherwise, the nodes are <strong>parallel</strong>. Sequential nodes often model a time dimension.</p><p><strong>Repeated subdiagram</strong> refers to a recurring pattern within an influence diagram. Often, influence diagrams do not have a unique structure, but they consist of a repeated pattern due to the underlying problem&#39;s properties.</p><p><strong>Limited-memory</strong> influence diagram refers to an influence diagram where the <em>no-forgetting</em> assumption does not hold. In practice, this means that the decision maker does not necessarily remember all previous information. For example, the treatment decisions in the <a href="../../examples/pig-breeding/#pig-breeding">Pig Breeding</a> example are made without full information about the treatment history.</p><p><strong>Isolated subdiagrams</strong> refer to unconnected diagrams within an influence diagram. That is, there are no undirected connections between the diagrams. Therefore, one isolated subdiagram&#39;s decisions affect decisions on the other isolated subdiagrams only through the utility function.</p><p>A chance or decision node is <strong>redundant</strong> if it is a leaf node and not in any value node&#39;s information set. Formally, if <span>$j∈C∪D$</span> is a leaf node and there does not exist a value node <span>$i∈V$</span> such that <span>$j∈I(i)$</span>, then node <span>$j$</span> is redundant.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Salo, A., Andelmin, J., &amp; Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from <a href="http://arxiv.org/abs/1910.09196">http://arxiv.org/abs/1910.09196</a></li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Howard, R. A., &amp; Matheson, J. E. (2005). Influence diagrams. Decision Analysis, 2(3), 127-143. https://doi.org/10.1287/deca.1050.0020</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Shachter, R. D. (1986). Evaluating influence diagrams. Operations research, 34(6), 871-882. https://doi.org/10.1287/opre.34.6.871</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../paths/">Paths »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Sunday 14 April 2024 07:09">Sunday 14 April 2024</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

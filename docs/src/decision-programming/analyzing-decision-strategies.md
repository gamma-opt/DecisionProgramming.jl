# Analyzing Decision Strategies
## Introduction
We can analyze fixed decision strategies $Z$ on an influence diagram $G$, such as ones resulting from the optimization, by generating the active paths $ğ’^Z.$


## Active Paths
We can generate active paths $ğ¬âˆˆğ’^Z$ as follows.

1) Initialize path $ğ¬$ of length $n$ with undefined values.
2) Fill path with chance states $ğ¬_jâˆˆS_j$ for all $jâˆˆC.$
3) In increasing order of decision nodes $jâˆˆD$, fill decision states by computing decision strategy $ğ¬_j=Z_j(ğ¬_{I(j)}).$

The path probability for all active paths is equal to the upper bound

$$â„™(ğ¬âˆ£Z)=p(ğ¬), \quad âˆ€ğ¬âˆˆğ’^Z.$$

We exclude inactive paths from the analysis because their path probabilities are zero.


## Utility Distribution
We define unique path utility values as

$$\mathcal{U}^âˆ—=\{\mathcal{U}(ğ¬)âˆ£ğ¬âˆˆğ’^Z\}.$$

The probability mass function of the **utility distribution** associates each unique path utility to a probability as follows

$$â„™(X=u)=âˆ‘_{ğ¬âˆˆğ’^Zâˆ£\mathcal{U}(ğ¬)=u} p(ğ¬),\quad âˆ€uâˆˆ\mathcal{U}^âˆ—.$$

From the utility distribution, we can calculate the cumulative distribution, statistics, and risk measures. The relevant statistics are expected value, standard deviation, skewness and kurtosis. Risk measures focus on the conditional value-at-risk (CVaR), also known as, expected shortfall.


## Measuring Risk
![](figures/risk_measures.svg)

We have a discrete probability distribution $f(x)=â„™(X=x)âˆˆ[0, 1]$ over the domain $xâˆˆÎ©$ with $âˆ‘_{xâˆˆÎ©}â„™(X=x)=1$ and its cumulative distribution function $F(x) = âˆ‘_{x^â€²âˆˆÎ©, x^â€²â‰¤x}f(x^â€²).$

We present the concept of conditional value-at-risk, a *risk measure* of the conditional expected value of the tail of a probability distribution for a given threshold of $Î±âˆˆ(0, 1).$

First, we define the **value-at-risk** as

$$\operatorname{VaR}(Î±) = x_Î± = \inf\{xâˆˆÎ© âˆ£ F(x) > Î±\}.$$

Then, we define the **conditional value-at-risk** as

$$\operatorname{CVaR}(Î±)=\left(âˆ‘_{xâ‰¤x_Î±} x â‹… f(x) - \left(âˆ‘_{xâ‰¤x_Î±} f(x) - Î±\right) x_Î± \right) / Î±.$$

In the above figure, we have an example of discrete probability distribution with a positive expected value (*green diamond*) and its cumulative distribution. The *red horizontal line* represents the threshold $Î±$ and the *yellow diamond* marks the value-at-risk $x_Î±$, that is, the smallest value $x$ such that the cumulative probability is above $Î±.$ The *red circles* are the values $x$ below that fall below or equal $x_Î±$ and the *orange diamond* is the conditional value-at-risk.


## State Probabilities
We denote **paths with fixed states** where $Ïµ$ denotes an empty state using a recursive definition.

$$\begin{aligned}
ğ’_{Ïµ} &= ğ’^Z \\
ğ’_{Ïµ,s_i} &= \{ğ¬âˆˆğ’_{Ïµ} âˆ£ ğ¬_i=s_i\} \\
ğ’_{Ïµ,s_i,s_j} &= \{ğ¬âˆˆğ’_{Ïµ,s_i} âˆ£ ğ¬_j=s_j\},\quad jâ‰ i
\end{aligned}$$

The probability of all paths sums to one

$$â„™(Ïµ) = \sum_{ğ¬âˆˆğ’_Ïµ} p(ğ¬) = 1.$$

**State probabilities** for each node $iâˆˆCâˆªD$ and state $s_iâˆˆS_i$ denote how likely the state occurs given all path probabilities

$$â„™(s_iâˆ£Ïµ) = \sum_{ğ¬âˆˆğ’_{Ïµ,s_i}} \frac{p(ğ¬)}{â„™(Ïµ)} = \sum_{ğ¬âˆˆğ’_{Ïµ,s_i}} p(ğ¬)$$

An **active state** is a state with positive state probability $â„™(s_iâˆ£c)>0$ given conditions $c.$

We can **generalize the state probabilities** as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state $s_i$ and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.

$$â„™(s_jâˆ£Ïµ,s_i) = \sum_{ğ¬âˆˆğ’_{Ïµ,s_i,s_j}} \frac{p(ğ¬)}{â„™(s_iâˆ£Ïµ)}$$

We can then repeat this process by choosing an active state from the new conditional state probabilities $s_k$ that is different from previously chosen states $kâ‰ j.$
